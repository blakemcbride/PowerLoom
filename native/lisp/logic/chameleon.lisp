;;; -*- Mode: Lisp; Package: STELLA; Syntax: COMMON-LISP; Base: 10 -*-

;;; chameleon.lisp

#|
 +---------------------------- BEGIN LICENSE BLOCK ---------------------------+
 |                                                                            |
 | Version: MPL 1.1/GPL 2.0/LGPL 2.1                                          |
 |                                                                            |
 | The contents of this file are subject to the Mozilla Public License        |
 | Version 1.1 (the "License"); you may not use this file except in           |
 | compliance with the License. You may obtain a copy of the License at       |
 | http://www.mozilla.org/MPL/                                                |
 |                                                                            |
 | Software distributed under the License is distributed on an "AS IS" basis, |
 | WITHOUT WARRANTY OF ANY KIND, either express or implied. See the License   |
 | for the specific language governing rights and limitations under the       |
 | License.                                                                   |
 |                                                                            |
 | The Original Code is the PowerLoom KR&R System.                            |
 |                                                                            |
 | The Initial Developer of the Original Code is                              |
 | UNIVERSITY OF SOUTHERN CALIFORNIA, INFORMATION SCIENCES INSTITUTE          |
 | 4676 Admiralty Way, Marina Del Rey, California 90292, U.S.A.               |
 |                                                                            |
 | Portions created by the Initial Developer are Copyright (C) 1997-2023      |
 | the Initial Developer. All Rights Reserved.                                |
 |                                                                            |
 | Contributor(s):                                                            |
 |                                                                            |
 | Alternatively, the contents of this file may be used under the terms of    |
 | either the GNU General Public License Version 2 or later (the "GPL"), or   |
 | the GNU Lesser General Public License Version 2.1 or later (the "LGPL"),   |
 | in which case the provisions of the GPL or the LGPL are applicable instead |
 | of those above. If you wish to allow use of your version of this file only |
 | under the terms of either the GPL or the LGPL, and not to allow others to  |
 | use your version of this file under the terms of the MPL, indicate your    |
 | decision by deleting the provisions above and replace them with the notice |
 | and other provisions required by the GPL or the LGPL. If you do not delete |
 | the provisions above, a recipient may use your version of this file under  |
 | the terms of any one of the MPL, the GPL or the LGPL.                      |
 |                                                                            |
 +----------------------------- END LICENSE BLOCK ----------------------------+
|#

(CL:IN-PACKAGE "STELLA")

;;; Auxiliary variables:

(CL:DEFVAR SGT-CHAMELEON-CHAMELEON-TRUTH-VALUE-RELATION NULL)
(CL:DEFVAR SGT-CHAMELEON-CHAMELEON-VECTOR-RELATION NULL)
(CL:DEFVAR SGT-CHAMELEON-CHAMELEON-IGNORED-VALUE-RELATION NULL)
(CL:DEFVAR SGT-CHAMELEON-CHAMELEON-PRIMITIVE-VALUE-RELATION NULL)
(CL:DEFVAR SGT-CHAMELEON-LOGIC-CHAMELEON-PARTIAL-MATCH NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-ARGUMENT-JUSTIFICATIONS NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-ARGUMENT-PROPOSITIONS NULL)
(CL:DEFVAR KWD-CHAMELEON-AND NULL)
(CL:DEFVAR KWD-CHAMELEON-OR NULL)
(CL:DEFVAR KWD-CHAMELEON-ATOMIC-GOAL NULL)
(CL:DEFVAR KWD-CHAMELEON-UP-TRUE NULL)
(CL:DEFVAR KWD-CHAMELEON-UP-FAIL NULL)
(CL:DEFVAR KWD-CHAMELEON-DOWN NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-JUSTIFICATION NULL)
(CL:DEFVAR KWD-CHAMELEON-GOAL-TREE NULL)
(CL:DEFVAR KWD-CHAMELEON-OR-INTRODUCTION NULL)
(CL:DEFVAR KWD-CHAMELEON-FAILURE NULL)
(CL:DEFVAR KWD-CHAMELEON-OTHER NULL)
(CL:DEFVAR KWD-CHAMELEON-VARIANT1 NULL)
(CL:DEFVAR KWD-CHAMELEON-FINAL-SUCCESS NULL)
(CL:DEFVAR KWD-CHAMELEON-VARIANT2 NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-ANTECEDENTS-RULE NULL)
(CL:DEFVAR KWD-CHAMELEON-MULTIPLE-PROOFS NULL)
(CL:DEFVAR KWD-CHAMELEON-TECHNICAL NULL)
(CL:DEFVAR KWD-CHAMELEON-LAY NULL)
(CL:DEFVAR KWD-CHAMELEON-MINIMUM-SCORE NULL)
(CL:DEFVAR KWD-CHAMELEON-MAXIMIZE-SCORE? NULL)
(CL:DEFVAR KWD-CHAMELEON-RECORD-JUSTIFICATIONS? NULL)
(CL:DEFVAR SGT-CHAMELEON-STELLA-BOOLEAN NULL)
(CL:DEFVAR KWD-CHAMELEON-NOISY-OR NULL)
(CL:DEFVAR KWD-CHAMELEON-ORIGINAL NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-NEURAL-NET NULL)
(CL:DEFVAR KWD-CHAMELEON-PROPOSITION NULL)
(CL:DEFVAR KWD-CHAMELEON-CHAMELEON NULL)
(CL:DEFVAR KWD-CHAMELEON-CHAMELEON-BATCH NULL)
(CL:DEFVAR KWD-CHAMELEON-TENSORFLOW NULL)
(CL:DEFVAR KWD-CHAMELEON-TENSORFLOW-BATCH NULL)
(CL:DEFVAR KWD-CHAMELEON-NOT NULL)
(CL:DEFVAR KWD-CHAMELEON-FAIL NULL)
(CL:DEFVAR KWD-CHAMELEON-TRUTH-VALUE NULL)
(CL:DEFVAR KWD-CHAMELEON-IGNORED-VALUE NULL)
(CL:DEFVAR KWD-CHAMELEON-VECTOR NULL)
(CL:DEFVAR SGT-CHAMELEON-LOGIC-PROPOSITION NULL)
(CL:DEFVAR SGT-CHAMELEON-LOGIC-M-NEURAL-NETWORK.TRUTH-VALUE-ARGUMENT-INDEX-MEMO-TABLE-000 NULL)
(CL:DEFVAR KWD-CHAMELEON-QUICKPROP NULL)
(CL:DEFVAR SGT-CHAMELEON-STELLA-CONS NULL)
(CL:DEFVAR SGT-CHAMELEON-STELLA-LIST NULL)
(CL:DEFVAR SGT-CHAMELEON-STELLA-VECTOR NULL)
(CL:DEFVAR SGT-CHAMELEON-STELLA-SEQUENCE NULL)
(CL:DEFVAR SGT-CHAMELEON-STELLA-ITERATOR NULL)
(CL:DEFVAR SGT-CHAMELEON-LOGIC-CHAMELEON-NEURAL-NETWORK NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-PROPOSITION NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-INPUT NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-HIDDEN NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-OUTPUT NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-IH NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-HO NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-INPUT-ERROR NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-HIDDEN-ERROR NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-OUTPUT-ERROR NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-IH-DELTA NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-HO-DELTA NULL)
(CL:DEFVAR SGT-CHAMELEON-STELLA-FLOAT-ARRAY NULL)
(CL:DEFVAR SGT-CHAMELEON-LOGIC-VECTOR-NEURAL-NETWORK NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-N-VECTOR-ARGUMENTS NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-N-VECTOR-ARGUMENT-SPECS NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-N-VECTOR-ARGUMENT-INPUTS NULL)
(CL:DEFVAR SGT-CHAMELEON-LOGIC-M-VECTOR-NEURAL-NETWORK.VECTOR-ARGUMENT-INDEX-MEMO-TABLE-000 NULL)
(CL:DEFVAR SGT-CHAMELEON-CHAMELEON-VECTOR-ARITY NULL)
(CL:DEFVAR SGT-CHAMELEON-CHAMELEON-VECTOR-DIMENSIONS NULL)
(CL:DEFVAR SGT-CHAMELEON-LOGIC-JUSTIFICATION NULL)
(CL:DEFVAR SGT-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-MODEL NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.BUILD-PROPOSITION-NETWORK NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.ALLOCATE-NETWORK-ARRAYS NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.RANDOMIZE-NETWORK-WEIGHTS NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.INITIALIZE-NETWORK-WEIGHTS NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.NUMBER-OF-INPUTS NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.NTH-INPUT NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.NTH-INPUT-ERROR NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.SET-INPUT-VALUES NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.SET-VECTOR-INPUT-VALUES NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.FORWARD-PROPAGATE-INPUTS NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.BACKWARD-PROPAGATE-ERROR NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.UPDATE-NETWORK-WEIGHTS NULL)
(CL:DEFVAR KWD-CHAMELEON-MATCH-MODE NULL)
(CL:DEFVAR KWD-CHAMELEON-WARNING NULL)
(CL:DEFVAR KWD-CHAMELEON-PRIMITIVE-STRATEGY NULL)
(CL:DEFVAR KWD-CHAMELEON-GOAL-COMPLEMENT NULL)
(CL:DEFVAR KWD-CHAMELEON-AND-INTRODUCTION NULL)
(CL:DEFVAR KWD-CHAMELEON-DISPROOF NULL)
(CL:DEFVAR KWD-CHAMELEON-MODUS-PONENS NULL)
(CL:DEFVAR KWD-CHAMELEON-MODUS-TOLLENS NULL)
(CL:DEFVAR KWD-CHAMELEON-SUBSUMPTION-REASONING NULL)
(CL:DEFVAR KWD-CHAMELEON-FAIL-INTRODUCTION NULL)
(CL:DEFVAR KWD-CHAMELEON-MAX NULL)
(CL:DEFVAR SGT-CHAMELEON-LOGIC-CHAMELEON-BATCH-NEURAL-NETWORK NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-INPUT-BATCH NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-KEY-BATCH NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-TARGET-BATCH NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-OUTPUT-BATCH NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-INPUT-ERROR-BATCH NULL)
(CL:DEFVAR SGT-CHAMELEON-LOGIC-2D-LONG-ARRAY NULL)
(CL:DEFVAR SGT-CHAMELEON-LOGIC-TENSORFLOW-BATCH-NEURAL-NETWORK NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-INPUT-MODIFIED? NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-INPUT-BATCH-LENGTH NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-VECTOR-BATCH NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-VECTOR-BATCH-LENGTH NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-TARGET-BATCH-LENGTH NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-TENSORFLOW-BATCH-NEURAL-NETWORK.BATCH-FORWARD-PROPAGATE-INPUTS NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-TENSORFLOW-BATCH-NEURAL-NETWORK.BATCH-BACKWARD-PROPAGATE-ERROR NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-TENSORFLOW-BATCH-NEURAL-NETWORK.BATCH-UPDATE-NETWORK-WEIGHTS NULL)
(CL:DEFVAR SGT-CHAMELEON-LOGIC-NETWORK-PROOF-QUEUE NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-DEPENDENTS NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-PREREQUISITES NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-ACTIVE-NETWORKS NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-MIN-BATCH-SIZE NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-N-QUEUED NULL)
(CL:DEFVAR SGT-CHAMELEON-LOGIC-NETWORK-PROOF-FORWARD-QUEUE NULL)
(CL:DEFVAR SGT-CHAMELEON-LOGIC-NETWORK-PROOF-BACKWARD-QUEUE NULL)
(CL:DEFVAR SGT-CHAMELEON-LOGIC-NETWORK-PROOF-UPDATE-QUEUE NULL)
(CL:DEFVAR KWD-CHAMELEON-MODULE NULL)
(CL:DEFVAR SGT-CHAMELEON-STELLA-MODULE NULL)
(CL:DEFVAR KWD-CHAMELEON-LOCAL? NULL)
(CL:DEFVAR KWD-CHAMELEON-N-TRAIN NULL)
(CL:DEFVAR SGT-CHAMELEON-STELLA-INTEGER NULL)
(CL:DEFVAR SYM-CHAMELEON-CHAMELEON-TRAINING-EXAMPLE NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-?P NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-?S NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-RETRIEVE-TRAINING-EXAMPLES NULL)
(CL:DEFVAR KWD-CHAMELEON-COMMON-LISP NULL)
(CL:DEFVAR KWD-CHAMELEON-FUNCTION NULL)
(CL:DEFVAR KWD-CHAMELEON-SHUFFLE? NULL)
(CL:DEFVAR KWD-CHAMELEON-OPTIONS NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-SELECT-TRAINING-EXAMPLES NULL)
(CL:DEFVAR KWD-CHAMELEON-EPOCHS NULL)
(CL:DEFVAR KWD-CHAMELEON-PRINT-CYCLE NULL)
(CL:DEFVAR KWD-CHAMELEON-ERROR-CUTOFF NULL)
(CL:DEFVAR SGT-CHAMELEON-STELLA-FLOAT NULL)
(CL:DEFVAR KWD-CHAMELEON-BATCH? NULL)
(CL:DEFVAR KWD-CHAMELEON-EXAMPLES NULL)
(CL:DEFVAR SGT-CHAMELEON-STELLA-OBJECT NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-TRAIN-CHAMELEON-NEURAL-NETWORKS NULL)
(CL:DEFVAR SGT-CHAMELEON-LOGIC-SCORED-QUERY-PROOF-ADJUNCT NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-PARTIAL-MATCH-STRATEGY NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-DOWN-FRAME NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-PROOF-ADJUNCT NULL)
(CL:DEFVAR KWD-CHAMELEON-TERMINAL-FAILURE NULL)
(CL:DEFVAR KWD-CHAMELEON-MOVE-DOWN NULL)
(CL:DEFVAR SGT-CHAMELEON-STELLA-NUMBER-WRAPPER NULL)
(CL:DEFVAR KWD-CHAMELEON-SCORED-QUERY NULL)
(CL:DEFVAR KWD-CHAMELEON-CONTINUING-SUCCESS NULL)
(CL:DEFVAR KWD-CHAMELEON-MATCH-SCORE NULL)
(CL:DEFVAR SYM-CHAMELEON-LOGIC-STARTUP-CHAMELEON NULL)
(CL:DEFVAR SYM-CHAMELEON-STELLA-METHOD-STARTUP-CLASSNAME NULL)

;;; Forward declarations:

(CL:DECLAIM
 (CL:SPECIAL *STARTUP-TIME-PHASE* *ERROR-CUTOFF* *TRAINING-EXAMPLES*
  MOST-POSITIVE-INTEGER STANDARD-OUTPUT STANDARD-WARNING EOL
  MOST-NEGATIVE-LONG-INTEGER *LOGIC-MODULE* *MOMENTUM-TERM*
  *LEARNING-RATE* *WEIGHT-RANGE* *NEURAL-NETWORK-TRAINING-METHOD*
  MOST-NEGATIVE-FLOAT *MEMOIZATION-ENABLED?* MEMOIZED-NULL-VALUE
  *MASTER-NEURAL-NETWORK-LIST* *MODULE* FALSE-WRAPPER TRUE-WRAPPER
  *RULE-COMBINATION* *INFERENCELEVEL* NULL-INTEGER
  *RECORD-JUSTIFICATIONS?* FALSE-TRUTH-VALUE DEFAULT-FALSE-TRUTH-VALUE
  TRUE-TRUTH-VALUE UNKNOWN-TRUTH-VALUE *QUERYITERATOR* NIL NULL-FLOAT))

;;; (DEFGLOBAL *CHAMELEON-MODULE* ...)

(CL:DEFVAR *CHAMELEON-MODULE* NULL
  "Namespace module for Chameleon relations")

;;; (DEFUN ENSURE-CHAMELEON-ONTOLOGY ...)

(CL:DEFUN ENSURE-CHAMELEON-ONTOLOGY ()
  "Ensure the chameleon.plm ontology file has been loaded (assumes it exists in the current load path)."
  (CL:WHEN (CL:EQ *CHAMELEON-MODULE* NULL)
   (CL:WHEN
    (CL:EQ
     (%SURROGATE-VALUE SGT-CHAMELEON-CHAMELEON-TRUTH-VALUE-RELATION)
     NULL)
    (%LOAD "chameleon.plm" NIL))
   (CL:SETQ *CHAMELEON-MODULE* (GET-STELLA-MODULE "/CHAMELEON" CL:T))))

;;; (DEFUN (GET-CHAMELEON-MODULE MODULE) ...)

(CL:DEFUN GET-CHAMELEON-MODULE ()
  "Return the namespace module for Chameleon relations"
  (CL:WHEN (CL:EQ *CHAMELEON-MODULE* NULL) (ENSURE-CHAMELEON-ONTOLOGY))
  *CHAMELEON-MODULE*)

;;; (DEFUN (CHAMELEON-VECTOR-RELATION? BOOLEAN) ...)

(CL:DEFUN CHAMELEON-VECTOR-RELATION? (X)
  "Return TRUE if `x' is an explicitly marked vector relation."
  (TEST-PROPERTY? X SGT-CHAMELEON-CHAMELEON-VECTOR-RELATION))

;;; (DEFUN (CHAMELEON-IGNORED-VALUE-RELATION? BOOLEAN) ...)

(CL:DEFUN CHAMELEON-IGNORED-VALUE-RELATION? (X)
  "Return TRUE if `x' is an explicitly marked as ignored or a vector relation
that is not also marked as a truth value relation."
  (CL:OR
   (TEST-PROPERTY? X SGT-CHAMELEON-CHAMELEON-IGNORED-VALUE-RELATION)
   (CL:AND (TEST-PROPERTY? X SGT-CHAMELEON-CHAMELEON-VECTOR-RELATION)
    (CL:NOT
     (TEST-PROPERTY? X SGT-CHAMELEON-CHAMELEON-TRUTH-VALUE-RELATION)))))

;;; (DEFUN (CHAMELEON-TRUTH-VALUE-RELATION? BOOLEAN) ...)

(CL:DEFUN CHAMELEON-TRUTH-VALUE-RELATION? (X)
  "Return TRUE if `x' is an explicitly marked truth value relation or
otherwise not known to be ignored."
  (CL:OR
   (TEST-PROPERTY? X SGT-CHAMELEON-CHAMELEON-TRUTH-VALUE-RELATION)
   (CL:NOT
    (CL:OR
     (TEST-PROPERTY? X SGT-CHAMELEON-CHAMELEON-IGNORED-VALUE-RELATION)
     (CL:AND (TEST-PROPERTY? X SGT-CHAMELEON-CHAMELEON-VECTOR-RELATION)
      (CL:NOT
       (TEST-PROPERTY? X
        SGT-CHAMELEON-CHAMELEON-TRUTH-VALUE-RELATION)))))))

;;; (DEFUN (CHAMELEON-PRIMITIVE-VALUE-RELATION? BOOLEAN) ...)

(CL:DEFUN CHAMELEON-PRIMITIVE-VALUE-RELATION? (X)
  "Return TRUE if `x' is an explicitly marked primitive value relation."
  (TEST-PROPERTY? X SGT-CHAMELEON-CHAMELEON-PRIMITIVE-VALUE-RELATION))

;;; (DEFCLASS CHAMELEON-PARTIAL-MATCH ...)

(CL:DEFCLASS CHAMELEON-PARTIAL-MATCH (INCREMENTAL-PARTIAL-MATCH)
  ((ARGUMENT-JUSTIFICATIONS :DOCUMENTATION
    "Holds justifications for OR arguments and alternative rules."
    :ALLOCATION :INSTANCE :ACCESSOR %ARGUMENT-JUSTIFICATIONS)
   (ARGUMENT-PROPOSITIONS :DOCUMENTATION
    "Holds argument propositions in the order they are associated with scores"
    :ALLOCATION :INSTANCE :ACCESSOR %ARGUMENT-PROPOSITIONS))
  (:DOCUMENTATION
   "Variant of :BASIC partial match strategy to support CHAMELEON queries."))

(CL:DEFUN NEW-CHAMELEON-PARTIAL-MATCH (KIND CONTROL-FRAME)
  (CL:LET* ((SELF NULL))
   (CL:SETQ SELF (CL:MAKE-INSTANCE (CL:QUOTE CHAMELEON-PARTIAL-MATCH)))
   (CL:SETF (%KIND SELF) KIND)
   (CL:SETF (%CONTROL-FRAME SELF) CONTROL-FRAME)
   (CL:SETF (%SUCCESS? SELF) CL:NIL) (CL:SETF (%UNBOUND-VARS SELF) NIL)
   (CL:SETF (%ARGUMENT-WEIGHTS SELF) NIL)
   (CL:SETF (%ARGUMENT-SCORES SELF) NIL)
   (CL:SETF (%DYNAMIC-CUTOFF SELF) NULL-FLOAT)
   (CL:SETF (%MATCH-SCORE SELF) NULL-FLOAT)
   (CL:SETF (%MAXIMUM-SCORE SELF) 0.0d0)
   (CL:SETF (%TOTAL-WEIGHT SELF) NULL-FLOAT)
   (CL:SETF (%ACCUMULATED-WEIGHT SELF) 0.0d0)
   (CL:SETF (%ACCUMULATED-SCORE SELF) 0.0d0)
   (CL:SETF (%CHILD SELF) NULL) (CL:SETF (%PARENT SELF) NULL)
   (CL:SETF (%ARGUMENT-PROPOSITIONS SELF) NIL)
   (CL:SETF (%ARGUMENT-JUSTIFICATIONS SELF) NIL)
   (INITIALIZE-INCREMENTAL-PARTIAL-MATCH SELF) SELF))

(CL:DEFMETHOD PRIMARY-TYPE ((SELF CHAMELEON-PARTIAL-MATCH))
  SGT-CHAMELEON-LOGIC-CHAMELEON-PARTIAL-MATCH)

(CL:DEFUN ACCESS-CHAMELEON-PARTIAL-MATCH-SLOT-VALUE (SELF SLOTNAME VALUE SETVALUE?)
  (CL:COND
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-ARGUMENT-JUSTIFICATIONS)
    (CL:IF SETVALUE? (CL:SETF (%ARGUMENT-JUSTIFICATIONS SELF) VALUE)
     (CL:SETQ VALUE (%ARGUMENT-JUSTIFICATIONS SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-ARGUMENT-PROPOSITIONS)
    (CL:IF SETVALUE? (CL:SETF (%ARGUMENT-PROPOSITIONS SELF) VALUE)
     (CL:SETQ VALUE (%ARGUMENT-PROPOSITIONS SELF))))
   (CL:T
    (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
     (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" SLOTNAME
      "' is not a valid case option")
     (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))
  VALUE)

;;; (DEFGLOBAL *CHAMELEON-DEFAULT-DEFAULT-SCORE* ...)

(CL:DEFVAR *CHAMELEON-DEFAULT-DEFAULT-SCORE* 0.01d0
  "Default weight to use for unknown propositions that don't have a relation-specific value specified.")
(CL:DECLAIM (CL:TYPE CL:DOUBLE-FLOAT *CHAMELEON-DEFAULT-DEFAULT-SCORE*))

;;; (DEFUN (CHAMELEON-PARTIAL-MATCH-MODE? BOOLEAN) ...)

(CL:DEFUN CHAMELEON-PARTIAL-MATCH-MODE? ()
  "Return TRUE if a query is computing Chameleon partial matches."
  (CL:AND
   (CL:AND (CL:NOT (CL:EQ *QUERYITERATOR* NULL))
    (CL:NOT (CL:EQ (%PARTIAL-MATCH-STRATEGY *QUERYITERATOR*) NULL)))
   (ISA? (%PARTIAL-MATCH-STRATEGY *QUERYITERATOR*)
    SGT-CHAMELEON-LOGIC-CHAMELEON-PARTIAL-MATCH)))

;;; (DEFMETHOD (CREATE-PARTIAL-MATCH-FRAME CHAMELEON-PARTIAL-MATCH) ...)

(CL:DEFMETHOD CREATE-PARTIAL-MATCH-FRAME ((SELF CHAMELEON-PARTIAL-MATCH) FRAME KIND)
  (CL:LET*
   ((PMF (NEW-CHAMELEON-PARTIAL-MATCH KIND FRAME))
    (PROP (%PROPOSITION FRAME)))
   (CL:COND
    ((CL:OR (CL:EQ KIND KWD-CHAMELEON-AND)
      (CL:EQ KIND KWD-CHAMELEON-OR))
     (CL:WHEN (CL:EQ (GET-PROPOSITION-NEURAL-NETWORK PROP CL:NIL) NULL)
      (CREATE-AND-LINK-NEURAL-NETWORK PROP)))
    (CL:T))
   (LINK-TO-PARENT-PARTIAL-MATCH-FRAME PMF) PMF))

;;; (DEFMETHOD (COMPUTE-DYNAMIC-CUTOFF PARTIAL-MATCH-SCORE) ...)

(CL:DEFMETHOD COMPUTE-DYNAMIC-CUTOFF ((SELF CHAMELEON-PARTIAL-MATCH))
  (CL:WHEN (CL:NOT (CL:EQ (%PARENT SELF) NULL))
   (CL:LET* ((TEST-VALUE-000 (%KIND SELF)))
    (CL:COND
     ((CL:EQ TEST-VALUE-000 KWD-CHAMELEON-ATOMIC-GOAL)
      (CL:RETURN-FROM COMPUTE-DYNAMIC-CUTOFF
       (%DYNAMIC-CUTOFF (%PARENT SELF))))
     ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-AND)
       (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-OR)))
     (CL:T))))
  0.0d0)

;;; (DEFMETHOD (CUTOFF-PARTIAL-MATCH? BOOLEAN) ...)

(CL:DEFMETHOD CUTOFF-PARTIAL-MATCH? ((SELF CHAMELEON-PARTIAL-MATCH) TRACE?)
  (CL:CALL-NEXT-METHOD SELF TRACE?))

;;; (DEFMETHOD (TRUTH-VALUE-SCORE PARTIAL-MATCH-SCORE) ...)

(CL:DEFMETHOD TRUTH-VALUE-SCORE ((SELF CHAMELEON-PARTIAL-MATCH) TRUTHVALUE)
  (CL:LET* ((SCORE (%MATCH-SCORE TRUTHVALUE)))
   (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT SCORE))
   (CL:WHEN (CL:< SCORE 0.0d0) (CL:SETQ SCORE (CL:+ SCORE 1.0d0)))
   SCORE))

;;; (DEFUN (INVERT-CHAMELEON-MATCH-SCORE PARTIAL-MATCH-SCORE) ...)

(CL:DECLAIM
 (CL:FTYPE (CL:FUNCTION (CL:DOUBLE-FLOAT) CL:DOUBLE-FLOAT)
  INVERT-CHAMELEON-MATCH-SCORE))
(CL:DEFUN INVERT-CHAMELEON-MATCH-SCORE (SCORE)
  (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT SCORE))
  #+MCL
  (CL:CHECK-TYPE SCORE CL:DOUBLE-FLOAT)
  (CL:- 1.0d0 SCORE))

;;; (DEFMETHOD (INVERT-MATCH-SCORE PARTIAL-MATCH-SCORE) ...)

(CL:DEFMETHOD INVERT-MATCH-SCORE ((SELF CHAMELEON-PARTIAL-MATCH) SCORE)
  (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT SCORE))
  #+MCL
  (CL:CHECK-TYPE SCORE CL:DOUBLE-FLOAT)
  (INVERT-CHAMELEON-MATCH-SCORE SCORE))

;;; (DEFMETHOD (PROPOSITION-WEIGHT FLOAT) ...)

(CL:DEFMETHOD PROPOSITION-WEIGHT ((SELF CHAMELEON-PARTIAL-MATCH) PROPOSITION)
  (CL:CALL-NEXT-METHOD SELF PROPOSITION))

;;; (DEFMETHOD PUSH-AND-PARTIAL-MATCH-SCORE ...)

(CL:DEFMETHOD PUSH-AND-PARTIAL-MATCH-SCORE ((SELF CHAMELEON-PARTIAL-MATCH) SCORE WEIGHT)
  (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT SCORE WEIGHT))
  #+MCL
  (CL:CHECK-TYPE SCORE CL:DOUBLE-FLOAT)
  #+MCL
  (CL:CHECK-TYPE WEIGHT CL:DOUBLE-FLOAT)
  (CL:LET* ((ARGPROP (%PROPOSITION (%RESULT (%CONTROL-FRAME SELF)))))
   (CL:CALL-NEXT-METHOD SELF SCORE WEIGHT)
   (CL:SETF (%ARGUMENT-PROPOSITIONS SELF)
    (CONS ARGPROP (%ARGUMENT-PROPOSITIONS SELF)))))

;;; (DEFMETHOD POP-AND-PARTIAL-MATCH-SCORE ...)

(CL:DEFMETHOD POP-AND-PARTIAL-MATCH-SCORE ((SELF CHAMELEON-PARTIAL-MATCH))
  (CL:CALL-NEXT-METHOD SELF)
  (CL:SETF (%ARGUMENT-PROPOSITIONS SELF)
   (%%REST (%ARGUMENT-PROPOSITIONS SELF))))

;;; (DEFMETHOD PUSH-OR-PARTIAL-MATCH-SCORE ...)

(CL:DEFMETHOD PUSH-OR-PARTIAL-MATCH-SCORE ((SELF CHAMELEON-PARTIAL-MATCH) SCORE WEIGHT)
  (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT SCORE WEIGHT))
  #+MCL
  (CL:CHECK-TYPE SCORE CL:DOUBLE-FLOAT)
  #+MCL
  (CL:CHECK-TYPE WEIGHT CL:DOUBLE-FLOAT)
  (CL:CALL-NEXT-METHOD SELF SCORE WEIGHT))

;;; (DEFMETHOD POP-OR-PARTIAL-MATCH-SCORE ...)

(CL:DEFMETHOD POP-OR-PARTIAL-MATCH-SCORE ((SELF CHAMELEON-PARTIAL-MATCH))
  (CL:CALL-NEXT-METHOD SELF))

;;; (DEFMETHOD (ALLOW-UNBOUND-VARIABLES? BOOLEAN) ...)

(CL:DEFMETHOD ALLOW-UNBOUND-VARIABLES? ((SELF CHAMELEON-PARTIAL-MATCH))
  CL:NIL)

;;; (DEFMETHOD (COMPUTE-AND-SCORE PARTIAL-MATCH-SCORE) ...)

(CL:DEFMETHOD COMPUTE-AND-SCORE ((SELF CHAMELEON-PARTIAL-MATCH))
  (CL:LET*
   ((NET
     (GET-PROPOSITION-NEURAL-NETWORK
      (%PROPOSITION (%CONTROL-FRAME SELF)) CL:T))
    (INPUTS (NEW-VECTOR (NUMBER-OF-INPUTS NET)))
    (VECTORARGS
     (CL:IF (HAS-VECTOR-ARGUMENTS? NET)
      (NEW-VECTOR (NUMBER-OF-VECTOR-ARGUMENTS NET NULL)) NULL))
    (INDEX -1))
   (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX))
   (CL:LET*
    ((ARG NULL) (ITER-000 (%ARGUMENT-PROPOSITIONS SELF)) (SCORE NULL)
     (ITER-001 (%ARGUMENT-SCORES SELF)))
    (CL:LOOP WHILE
     (CL:AND (CL:NOT (CL:EQ ITER-000 NIL))
      (CL:NOT (CL:EQ ITER-001 NIL)))
     DO (CL:SETQ ARG (%%VALUE ITER-000))
     (CL:SETQ SCORE (%%VALUE ITER-001))
     (CL:SETQ INDEX (TRUTH-VALUE-ARGUMENT-INDEX NET ARG))
     (CL:WHEN (CL:>= INDEX 0)
      (CL:LET
       ((SELF (%THE-ARRAY INPUTS)) (VALUE SCORE) (POSITION INDEX))
       (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
        (CL:TYPE CL:FIXNUM POSITION))
       (CL:SETF (CL:AREF SELF POSITION) VALUE)))
     (CL:WHEN (CL:NOT (CL:EQ VECTORARGS NULL))
      (CL:SETQ INDEX (VECTOR-ARGUMENT-INDEX NET ARG))
      (CL:WHEN (CL:>= INDEX 0)
       (CL:LET
        ((SELF (%THE-ARRAY VECTORARGS))
         (VALUE (GET-VECTOR-ARGUMENT-SPEC NET ARG)) (POSITION INDEX))
        (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
         (CL:TYPE CL:FIXNUM POSITION))
        (CL:SETF (CL:AREF SELF POSITION) VALUE))))
     (CL:SETQ ITER-000 (%%REST ITER-000))
     (CL:SETQ ITER-001 (%%REST ITER-001))))
   (SET-INPUT-VALUES NET INPUTS)
   (CL:WHEN (CL:NOT (CL:EQ VECTORARGS NULL))
    (SET-VECTOR-INPUT-VALUES NET VECTORARGS))
   (FORWARD-PROPAGATE-INPUTS NET)))

;;; (DEFMETHOD (CONTINUE-PARTIAL-AND-PROOF KEYWORD) ...)

(CL:DEFMETHOD CONTINUE-PARTIAL-AND-PROOF ((SELF CHAMELEON-PARTIAL-MATCH) FRAME LASTMOVE)
  (CL:COND
   ((CL:OR (CL:EQ LASTMOVE KWD-CHAMELEON-UP-TRUE)
     (CL:EQ LASTMOVE KWD-CHAMELEON-UP-FAIL))
    (CL:WHEN
     (CL:AND (FALSE-TRUTH-VALUE? (%TRUTH-VALUE (%RESULT FRAME)))
      (STRICT-TRUTH-VALUE? (%TRUTH-VALUE (%RESULT FRAME))))
     (CL:SETF (%TRUTH-VALUE (%RESULT FRAME)) UNKNOWN-TRUTH-VALUE)))
   (CL:T))
  (CL:CALL-NEXT-METHOD SELF FRAME LASTMOVE))

;;; (DEFMETHOD (COMPUTE-OR-SCORE PARTIAL-MATCH-SCORE) ...)

(CL:DEFMETHOD COMPUTE-OR-SCORE ((SELF CHAMELEON-PARTIAL-MATCH))
  (COMPUTE-AND-SCORE SELF))

;;; (DEFMETHOD (CONTINUE-PARTIAL-OR-PROOF KEYWORD) ...)

(CL:DEFMETHOD CONTINUE-PARTIAL-OR-PROOF ((SELF CHAMELEON-PARTIAL-MATCH) LASTMOVE)
  (CL:LET*
   ((FRAME (%CONTROL-FRAME SELF)) (ORPROPOSITION (%PROPOSITION FRAME))
    (ARGCURSOR (%ARGUMENT-CURSOR FRAME)) (RESULT NULL))
   (CL:DECLARE (CL:TYPE CL:FIXNUM ARGCURSOR))
   (CL:COND
    ((CL:EQ LASTMOVE KWD-CHAMELEON-DOWN)
     (CL:LET*
      ((I NULL-INTEGER) (ITER-000 ARGCURSOR)
       (UPPER-BOUND-000 (CL:1- (LENGTH (%ARGUMENT-SCORES SELF)))))
      (CL:DECLARE (CL:TYPE CL:FIXNUM I ITER-000 UPPER-BOUND-000))
      (CL:LOOP WHILE (CL:<= ITER-000 UPPER-BOUND-000) DO
       (CL:SETQ I ITER-000) (CL:SETQ I I)
       (POP-OR-PARTIAL-MATCH-SCORE SELF)
       (CL:WHEN *RECORD-JUSTIFICATIONS?*
        (CL:SETF (%ARGUMENT-JUSTIFICATIONS SELF)
         (%%REST (%ARGUMENT-JUSTIFICATIONS SELF))))
       (CL:SETQ ITER-000 (CL:1+ ITER-000))))
     (SET-DYNAMIC-CUTOFF SELF))
    ((CL:OR (CL:EQ LASTMOVE KWD-CHAMELEON-UP-TRUE)
      (CL:EQ LASTMOVE KWD-CHAMELEON-UP-FAIL))
     (CL:LET*
      ((SUCESS? (CL:EQ LASTMOVE KWD-CHAMELEON-UP-TRUE))
       (RESULT (%RESULT FRAME)) (DISJUNCTS (%ARGUMENTS ORPROPOSITION))
       (DISJUNCT
        (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY DISJUNCTS))
         ARGCURSOR))
       (SCORE (%MATCH-SCORE (%PARTIAL-MATCH-FRAME RESULT))))
      (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT SCORE))
      (PUSH-OR-PARTIAL-MATCH-SCORE SELF SCORE
       (PROPOSITION-WEIGHT SELF DISJUNCT))
      (CL:SETQ SCORE (COMPUTE-OR-SCORE SELF))
      (SET-FRAME-PARTIAL-TRUTH SELF NULL SCORE CL:NIL)
      (CL:WHEN *RECORD-JUSTIFICATIONS?*
       (CL:SETF (%ARGUMENT-JUSTIFICATIONS SELF)
        (CONS
         (DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS RESULT)
          SYM-CHAMELEON-LOGIC-JUSTIFICATION NULL)
         (%ARGUMENT-JUSTIFICATIONS SELF))))
      (CL:COND
       ((CL:OR (CL:NOT (ALL-ARGUMENTS-BOUND? DISJUNCT))
         (CUTOFF-PARTIAL-MATCH? SELF
          (TRACE-KEYWORD? KWD-CHAMELEON-GOAL-TREE)))
        (POP-OR-PARTIAL-MATCH-SCORE SELF)
        (CL:WHEN *RECORD-JUSTIFICATIONS?*
         (CL:SETF (%ARGUMENT-JUSTIFICATIONS SELF)
          (%%REST (%ARGUMENT-JUSTIFICATIONS SELF))))
        (SET-FRAME-PARTIAL-TRUTH SELF UNKNOWN-TRUTH-VALUE 0.0d0 CL:T)
        (CL:SETQ LASTMOVE KWD-CHAMELEON-UP-FAIL))
       ((CL:AND SUCESS? (CL:= ARGCURSOR (CL:1- (LENGTH DISJUNCTS)))
         (ALL-ARGUMENTS-BOUND? DISJUNCT))
        (CL:SETQ LASTMOVE KWD-CHAMELEON-UP-TRUE))
       (CL:T (CL:SETQ LASTMOVE KWD-CHAMELEON-UP-FAIL)))))
    (CL:T
     (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
      (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" LASTMOVE
       "' is not a valid case option")
      (CL:ERROR
       (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))
   (CL:SETF (%DOWN FRAME) NULL)
   (CL:SETQ RESULT (CONTINUE-OR-PROOF FRAME LASTMOVE))
   (CL:WHEN (CL:>= (LENGTH (%ARGUMENT-JUSTIFICATIONS SELF)) 2)
    (CL:LET* ((SELF-002 (NEW-JUSTIFICATION)))
     (CL:SETF (%INFERENCE-RULE SELF-002) KWD-CHAMELEON-OR-INTRODUCTION)
     (CL:SETF (%ANTECEDENTS SELF-002)
      (REVERSE (%ARGUMENT-JUSTIFICATIONS SELF)))
     (RECORD-GOAL-JUSTIFICATION FRAME SELF-002)))
   RESULT))

;;; (DEFMETHOD (COMPUTE-NOT-SCORE PARTIAL-MATCH-SCORE) ...)

(CL:DEFMETHOD COMPUTE-NOT-SCORE ((SELF CHAMELEON-PARTIAL-MATCH))
  0.0d0)

;;; (DEFMETHOD (CONTINUE-PARTIAL-NOT-PROOF KEYWORD) ...)

(CL:DEFMETHOD CONTINUE-PARTIAL-NOT-PROOF ((SELF CHAMELEON-PARTIAL-MATCH) LASTMOVE)
  (CL:CALL-NEXT-METHOD SELF LASTMOVE))

;;; (DEFMETHOD (CONTINUE-PARTIAL-FAIL-PROOF KEYWORD) ...)

(CL:DEFMETHOD CONTINUE-PARTIAL-FAIL-PROOF ((SELF CHAMELEON-PARTIAL-MATCH) LASTMOVE)
  (CL:CALL-NEXT-METHOD SELF LASTMOVE))

;;; (DEFMETHOD (COMPUTE-GOAL-SCORE PARTIAL-MATCH-SCORE) ...)

(CL:DEFMETHOD COMPUTE-GOAL-SCORE ((SELF CHAMELEON-PARTIAL-MATCH))
  (CL:CALL-NEXT-METHOD SELF))

;;; (DEFMETHOD (CONTINUE-PARTIAL-STRATEGIES-PROOFS KEYWORD) ...)

(CL:DEFMETHOD CONTINUE-PARTIAL-STRATEGIES-PROOFS ((SELF CHAMELEON-PARTIAL-MATCH) LASTMOVE)
  (CL:LET*
   ((FRAME (%CONTROL-FRAME SELF))
    (RESULT (CL:CALL-NEXT-METHOD SELF LASTMOVE)))
   (CL:WHEN
    (CL:AND (CL:EQ RESULT KWD-CHAMELEON-FAILURE)
     (CL:NOT
      (CL:OR (CL:EQ (%TRUTH-VALUE FRAME) UNKNOWN-TRUTH-VALUE)
       (CL:EQ (%TRUTH-VALUE FRAME) NULL)))
     (CL:NOT
      (CL:EQ (%REVERSE-POLARITY? FRAME)
       (CL:OR (CL:EQ (%TRUTH-VALUE FRAME) FALSE-TRUTH-VALUE)
        (CL:EQ (%TRUTH-VALUE FRAME) DEFAULT-FALSE-TRUTH-VALUE)))))
    (CL:COND
     ((CL:EQ KWD-CHAMELEON-OTHER KWD-CHAMELEON-VARIANT1)
      (SET-FRAME-TRUTH-VALUE FRAME UNKNOWN-TRUTH-VALUE)
      (CL:WHEN
       (CL:NOT
        (CL:OR (CL:= (%MATCH-SCORE SELF) 0.0d0)
         (CL:= (%MATCH-SCORE SELF) 1.0d0)))
       (CL:SETQ RESULT KWD-CHAMELEON-FINAL-SUCCESS))
      (CL:WHEN
       (CL:AND *RECORD-JUSTIFICATIONS?*
        (CL:EQ RESULT KWD-CHAMELEON-FINAL-SUCCESS)
        (CL:EQ
         (DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS FRAME)
          SYM-CHAMELEON-LOGIC-JUSTIFICATION NULL)
         NULL))
       (RECORD-PRIMITIVE-JUSTIFICATION FRAME KWD-CHAMELEON-UP-TRUE)))
     ((CL:EQ KWD-CHAMELEON-OTHER KWD-CHAMELEON-VARIANT2)
      (SET-FRAME-TRUTH-VALUE FRAME UNKNOWN-TRUTH-VALUE)
      (SET-FRAME-PARTIAL-TRUTH SELF UNKNOWN-TRUTH-VALUE NULL-FLOAT
       CL:T))
     (CL:T)))
   RESULT))

;;; (DEFMETHOD (CONTINUE-PARTIAL-ANTECEDENTS-PROOF KEYWORD) ...)

(CL:DEFMETHOD CONTINUE-PARTIAL-ANTECEDENTS-PROOF ((SELF CHAMELEON-PARTIAL-MATCH) LASTMOVE)
  (CL:LET*
   ((FRAME (%CONTROL-FRAME SELF))
    (GOAL (EXTRACT-SUBGOAL-OF-FRAME FRAME)) (SCORE NULL-FLOAT)
    (RESULT NULL))
   (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT SCORE))
   (CL:COND
    ((CL:EQ LASTMOVE KWD-CHAMELEON-DOWN) (SET-DYNAMIC-CUTOFF SELF))
    ((CL:OR (CL:EQ LASTMOVE KWD-CHAMELEON-UP-TRUE)
      (CL:EQ LASTMOVE KWD-CHAMELEON-UP-FAIL))
     (CL:LET* ((GOALFRAME (%RESULT FRAME)))
      (CL:SETQ SCORE (%MATCH-SCORE (%PARTIAL-MATCH-FRAME GOALFRAME)))
      (PUSH-OR-PARTIAL-MATCH-SCORE SELF SCORE
       (PROPOSITION-WEIGHT SELF
        (DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS FRAME)
         SYM-CHAMELEON-LOGIC-ANTECEDENTS-RULE NULL)))
      (CL:SETQ SCORE (COMPUTE-GOAL-SCORE SELF))
      (SET-FRAME-PARTIAL-TRUTH SELF NULL SCORE CL:NIL)
      (CL:WHEN
       (CL:AND *RECORD-JUSTIFICATIONS?*
        (CL:NOT
         (CL:EQ
          (DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS GOALFRAME)
           SYM-CHAMELEON-LOGIC-JUSTIFICATION NULL)
          NULL)))
       (RECORD-MODUS-PONENS-JUSTIFICATION FRAME KWD-CHAMELEON-UP-TRUE)
       (CL:SETF (%ARGUMENT-JUSTIFICATIONS SELF)
        (CONS
         (DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS FRAME)
          SYM-CHAMELEON-LOGIC-JUSTIFICATION NULL)
         (%ARGUMENT-JUSTIFICATIONS SELF))))
      (CL:COND
       ((CL:OR (CL:NOT (ALL-ARGUMENTS-BOUND? GOAL))
         (CUTOFF-PARTIAL-MATCH? SELF
          (TRACE-KEYWORD? KWD-CHAMELEON-GOAL-TREE)))
        (POP-OR-PARTIAL-MATCH-SCORE SELF)
        (CL:WHEN *RECORD-JUSTIFICATIONS?*
         (CL:SETF (%ARGUMENT-JUSTIFICATIONS SELF)
          (%%REST (%ARGUMENT-JUSTIFICATIONS SELF))))
        (SET-FRAME-PARTIAL-TRUTH SELF UNKNOWN-TRUTH-VALUE 0.0d0 CL:T)
        (CL:SETQ LASTMOVE KWD-CHAMELEON-UP-FAIL))
       ((CL:AND (CL:NOT (HAS-MORE-ANTECEDENTS? FRAME))
         (ALL-ARGUMENTS-BOUND? GOAL)
         (CL:> (LENGTH (%ARGUMENT-JUSTIFICATIONS SELF)) 0))
        (CL:SETQ LASTMOVE KWD-CHAMELEON-UP-TRUE))
       (CL:T (CL:SETQ LASTMOVE KWD-CHAMELEON-UP-FAIL)))))
    (CL:T
     (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
      (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" LASTMOVE
       "' is not a valid case option")
      (CL:ERROR
       (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))
   (CL:SETF (%DOWN FRAME) NULL)
   (CL:SETQ RESULT (CONTINUE-ANTECEDENTS-PROOF FRAME LASTMOVE))
   (CL:WHEN (CL:EQ LASTMOVE KWD-CHAMELEON-UP-TRUE)
    (CL:WHEN (CL:EQ (%TRUTH-VALUE FRAME) NULL)
     (CL:SETF (%TRUTH-VALUE FRAME) UNKNOWN-TRUTH-VALUE))
    (CL:CASE (LENGTH (%ARGUMENT-JUSTIFICATIONS SELF)) (0)
     (1
      (SET-DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS FRAME)
       SYM-CHAMELEON-LOGIC-JUSTIFICATION
       (%%VALUE (%ARGUMENT-JUSTIFICATIONS SELF)) NULL))
     (CL:OTHERWISE
      (CL:LET* ((SELF-002 (NEW-JUSTIFICATION)))
       (CL:SETF (%INFERENCE-RULE SELF-002)
        KWD-CHAMELEON-MULTIPLE-PROOFS)
       (CL:SETF (%ANTECEDENTS SELF-002)
        (REVERSE (%ARGUMENT-JUSTIFICATIONS SELF)))
       (RECORD-GOAL-JUSTIFICATION FRAME SELF-002)))))
   RESULT))

;;; (DEFMETHOD (COMPUTE-PARTIAL-TRUTH FLOAT) ...)

(CL:DEFMETHOD COMPUTE-PARTIAL-TRUTH ((SELF CHAMELEON-PARTIAL-MATCH) QUERY)
  (CL:LET*
   ((BASEFRAME (%BASE-CONTROL-FRAME QUERY))
    (PARTIALMATCHFRAME (%PARTIAL-MATCH-STRATEGY QUERY))
    (MINIMUMSCORE
     (LOOKUP (%OPTIONS QUERY) KWD-CHAMELEON-MINIMUM-SCORE))
    (MAXIMIZESCORE?
     (CL:NOT
      (EQL? (LOOKUP (%OPTIONS QUERY) KWD-CHAMELEON-MAXIMIZE-SCORE?)
       FALSE-WRAPPER)))
    (RECORDJUSTIFICATIONS?
     (LOOKUP-DEFERRED-QUERY-OPTION QUERY
      KWD-CHAMELEON-RECORD-JUSTIFICATIONS?
      SGT-CHAMELEON-STELLA-BOOLEAN))
    (EPSILON 0.001d0) (INITIALINFERENCELEVEL (CURRENT-INFERENCE-LEVEL))
    (LATESTSCORE 0.0d0) (BESTSCORE 0.0d0) (BESTPROOF NULL))
   (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT EPSILON LATESTSCORE BESTSCORE))
   (CL:WHEN (CL:EQ PARTIALMATCHFRAME NULL)
    (CL:SETQ PARTIALMATCHFRAME SELF)
    (CL:SETF (%PARTIAL-MATCH-STRATEGY QUERY) SELF))
   (CL:SETF (%DYNAMIC-CUTOFF PARTIALMATCHFRAME)
    (CL:IF (CL:NOT (CL:EQ MINIMUMSCORE NULL))
     (%WRAPPER-VALUE MINIMUMSCORE) EPSILON))
   (CL:LET*
    ((*QUERYITERATOR* QUERY) (*GENERATE-ALL-PROOFS?* CL:T)
     (*RECORD-JUSTIFICATIONS?* *RECORD-JUSTIFICATIONS?*)
     (*INFERENCELEVEL* INITIALINFERENCELEVEL)
     (*REVERSEPOLARITY?* CL:NIL))
    (CL:DECLARE
     (CL:SPECIAL *QUERYITERATOR* *GENERATE-ALL-PROOFS?*
      *RECORD-JUSTIFICATIONS?* *INFERENCELEVEL* *REVERSEPOLARITY?*))
    (CL:WHEN (EQL? RECORDJUSTIFICATIONS? TRUE-WRAPPER)
     (CL:SETQ *RECORD-JUSTIFICATIONS?* CL:T))
    (CL:SETQ *RULE-COMBINATION* KWD-CHAMELEON-NOISY-OR)
    (CL:LOOP
     (CL:WHEN (CL:NOT (NEXT? QUERY))
      (CL:WHEN (CL:= (LENGTH (%SOLUTIONS QUERY)) 0)
       (CL:SETQ BESTSCORE (%MATCH-SCORE PARTIALMATCHFRAME)))
      (CL:RETURN))
     (CL:WHEN (CUTOFF-PARTIAL-MATCH? PARTIALMATCHFRAME CL:NIL)
      (CL:RETURN))
     (CL:SETQ LATESTSCORE (%MATCH-SCORE PARTIALMATCHFRAME))
     (CL:WHEN (CL:> LATESTSCORE BESTSCORE)
      (CL:SETQ BESTSCORE LATESTSCORE)
      (CL:SETQ BESTPROOF
       (DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS BASEFRAME)
        SYM-CHAMELEON-LOGIC-JUSTIFICATION NULL))
      (CL:SETF (%DYNAMIC-CUTOFF PARTIALMATCHFRAME)
       (CL:+ BESTSCORE EPSILON)))
     (CL:WHEN (CL:NOT MAXIMIZESCORE?) (CL:RETURN))
     (CL:SETQ *INFERENCELEVEL* INITIALINFERENCELEVEL))
    (SET-DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS BASEFRAME)
     SYM-CHAMELEON-LOGIC-JUSTIFICATION BESTPROOF NULL)
    (CL:SETF (%MATCH-SCORE PARTIALMATCHFRAME) BESTSCORE) BESTSCORE)))

;;; (DEFGLOBAL *ALL-NEURAL-NETWORKS* ...)

(CL:DEFVAR *ALL-NEURAL-NETWORKS* NULL)

;;; (DEFUN REGISTER-NEURAL-NETWORK ...)

(CL:DEFUN REGISTER-NEURAL-NETWORK (SELF)
  "Register the network `self' on the global networks list (assumes `self' has been linked)."
  (CL:LET*
   ((HASHCODE
     (WRAP-INTEGER
      (PROPOSITION-HASH-INDEX (GET-NEURAL-NETWORK-PROPOSITION SELF)
       NULL CL:T)))
    (BUCKET (LOOKUP *ALL-NEURAL-NETWORKS* HASHCODE)))
   (CL:COND
    ((CL:EQ BUCKET NULL)
     (INSERT-AT *ALL-NEURAL-NETWORKS* HASHCODE (CONS SELF NIL)))
    (CL:T
     (CL:SETF (%%REST BUCKET) (CONS (%%VALUE BUCKET) (%%REST BUCKET)))
     (FIRST-SETTER BUCKET SELF)))))

;;; (DEFUN UNREGISTER-NEURAL-NETWORK ...)

(CL:DEFUN UNREGISTER-NEURAL-NETWORK (SELF)
  "Unregister the network `self' on the global networks list."
  (CL:LET*
   ((HASHCODE
     (WRAP-INTEGER
      (PROPOSITION-HASH-INDEX (GET-NEURAL-NETWORK-PROPOSITION SELF)
       NULL CL:T)))
    (BUCKET (LOOKUP *ALL-NEURAL-NETWORKS* HASHCODE)))
   (CL:COND ((CL:EQ BUCKET NULL))
    ((CL:EQ (%%REST BUCKET) NIL)
     (REMOVE-AT *ALL-NEURAL-NETWORKS* HASHCODE))
    (CL:T (REMOVE BUCKET SELF)))))

;;; (DEFUN (LOOKUP-PROPOSITION-NEURAL-NETWORK NEURAL-NETWORK) ...)

(CL:DEFUN LOOKUP-PROPOSITION-NEURAL-NETWORK (PROP)
  "Lookup the neural network for `prop' in the global networks list."
  (CL:LET*
   ((HASHCODE (WRAP-INTEGER (PROPOSITION-HASH-INDEX PROP NULL CL:T)))
    (BUCKET (LOOKUP *ALL-NEURAL-NETWORKS* HASHCODE)))
   (CL:WHEN (CL:NOT (CL:EQ BUCKET NULL))
    (CL:LET* ((NET NULL) (ITER-000 BUCKET))
     (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-000 NIL)) DO
      (CL:SETQ NET (%%VALUE ITER-000))
      (CL:WHEN
       (CL:AND
        (EQUIVALENT-PROPOSITIONS? PROP
         (GET-NEURAL-NETWORK-PROPOSITION NET) NULL)
        (VISIBLE-FROM?
         (%HOME-CONTEXT (GET-NEURAL-NETWORK-PROPOSITION NET))
         *MODULE*))
       (CL:RETURN-FROM LOOKUP-PROPOSITION-NEURAL-NETWORK NET))
      (CL:SETQ ITER-000 (%%REST ITER-000)))))
   NULL))

;;; (DEFUN DELETE-NEURAL-NETWORKS ...)

(CL:DEFUN DELETE-NEURAL-NETWORKS ()
  "Eliminate all neural networks and remove any connections
to propositions and training examples."
  (CL:LET*
   ((BUCKET NULL) (ITER-000 (ALLOCATE-ITERATOR *ALL-NEURAL-NETWORKS*)))
   (CL:LOOP WHILE (NEXT? ITER-000) DO
    (CL:SETQ BUCKET (%VALUE ITER-000))
    (CL:LET* ((NET NULL) (ITER-001 BUCKET))
     (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-001 NIL)) DO
      (CL:SETQ NET (%%VALUE ITER-001)) (DELETE-NEURAL-NETWORK NET)
      (CL:SETQ ITER-001 (%%REST ITER-001))))))
  (INCREMENT-NOW-TIMESTAMP)
  (CLEAR *ALL-NEURAL-NETWORKS*)
  (CL:LET*
   ((NET NULL)
    (ITER-002 (%THE-CONS-LIST *MASTER-NEURAL-NETWORK-LIST*)))
   (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-002 NIL)) DO
    (CL:SETQ NET (%%VALUE ITER-002)) (DELETE-NEURAL-NETWORK NET)
    (CL:SETQ ITER-002 (%%REST ITER-002))))
  (DELETE-ALL-NEURAL-NETWORKS))

;;; (DEFUN RANDOMIZE-NEURAL-NETWORKS ...)

(CL:DEFUN RANDOMIZE-NEURAL-NETWORKS ()
  "Undo all training and randomize weights in all neural networks."
  (CL:LET*
   ((BUCKET NULL) (ITER-000 (ALLOCATE-ITERATOR *ALL-NEURAL-NETWORKS*)))
   (CL:LOOP WHILE (NEXT? ITER-000) DO
    (CL:SETQ BUCKET (%VALUE ITER-000))
    (CL:LET* ((NET NULL) (ITER-001 BUCKET))
     (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-001 NIL)) DO
      (CL:SETQ NET (%%VALUE ITER-001)) (RANDOMIZE-NETWORK-WEIGHTS NET)
      (CL:SETQ ITER-001 (%%REST ITER-001)))))))

;;; (DEFGLOBAL *CHAMELEON-NEURAL-NETWORK-IMPLEMENTATION* ...)

(CL:DEFVAR *CHAMELEON-NEURAL-NETWORK-IMPLEMENTATION* NULL)

;;; (DEFUN CREATE-AND-LINK-NEURAL-NETWORK ...)

(CL:DEFUN CREATE-AND-LINK-NEURAL-NETWORK (PROP)
  (CL:LET* ((NET NULL))
   (CL:COND
    ((CL:EQ *CHAMELEON-NEURAL-NETWORK-IMPLEMENTATION*
      KWD-CHAMELEON-ORIGINAL)
     (SET-DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS PROP)
      SYM-CHAMELEON-LOGIC-NEURAL-NET (CREATE-NEURAL-NETWORK PROP) NULL)
     (CL:RETURN-FROM CREATE-AND-LINK-NEURAL-NETWORK))
    ((CL:EQ *CHAMELEON-NEURAL-NETWORK-IMPLEMENTATION*
      KWD-CHAMELEON-PROPOSITION)
     (CL:SETQ NET (NEW-PROPOSITION-NEURAL-NETWORK)))
    ((CL:EQ *CHAMELEON-NEURAL-NETWORK-IMPLEMENTATION*
      KWD-CHAMELEON-CHAMELEON)
     (ENSURE-CHAMELEON-ONTOLOGY)
     (CL:SETQ NET (NEW-CHAMELEON-NEURAL-NETWORK)))
    ((CL:EQ *CHAMELEON-NEURAL-NETWORK-IMPLEMENTATION*
      KWD-CHAMELEON-CHAMELEON-BATCH)
     (ENSURE-CHAMELEON-ONTOLOGY)
     (CL:SETQ NET (NEW-CHAMELEON-BATCH-NEURAL-NETWORK)))
    ((CL:EQ *CHAMELEON-NEURAL-NETWORK-IMPLEMENTATION*
      KWD-CHAMELEON-TENSORFLOW)
     (ENSURE-CHAMELEON-ONTOLOGY)
     (CL:WHEN (CL:NOT (TENSORFLOW-BACKEND-AVAILABLE?))
      (CL:ERROR
       (NEW-STELLA-EXCEPTION
        "create-and-link-neural-network: TensorFlow backend is not available")))
     (CL:SETQ NET (NEW-TENSORFLOW-NEURAL-NETWORK)))
    ((CL:EQ *CHAMELEON-NEURAL-NETWORK-IMPLEMENTATION*
      KWD-CHAMELEON-TENSORFLOW-BATCH)
     (ENSURE-CHAMELEON-ONTOLOGY)
     (CL:WHEN (CL:NOT (TENSORFLOW-BACKEND-AVAILABLE?))
      (CL:ERROR
       (NEW-STELLA-EXCEPTION
        "create-and-link-neural-network: TensorFlow backend is not available")))
     (CL:SETQ NET (NEW-TENSORFLOW-BATCH-NEURAL-NETWORK)))
    (CL:T
     (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
      (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`"
       *CHAMELEON-NEURAL-NETWORK-IMPLEMENTATION*
       "' is not a valid case option")
      (CL:ERROR
       (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))
   (BUILD-PROPOSITION-NETWORK NET PROP) (REGISTER-NEURAL-NETWORK NET)))

;;; (DEFUN (GET-PROPOSITION-NEURAL-NETWORK NEURAL-NETWORK) ...)

(CL:DEFUN GET-PROPOSITION-NEURAL-NETWORK (PROP ERROR?)
  "Return the neural network associated with `prop'.  If `error?', raise an
exception if it cannot be found, otherwise, simply return NULL."
  (CL:LET*
   ((NET
     (DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS PROP)
      SYM-CHAMELEON-LOGIC-NEURAL-NET NULL)))
   (CL:WHEN (CL:EQ NET NULL)
    (CL:SETQ NET (LOOKUP-PROPOSITION-NEURAL-NETWORK PROP))
    (CL:COND
     ((CL:NOT (CL:EQ NET NULL))
      (SET-DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS PROP)
       SYM-CHAMELEON-LOGIC-NEURAL-NET NET NULL))
     (ERROR?
      (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
       (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
        "Missing neural network for proposition: `" PROP "'")
       (CL:ERROR
        (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))))
   NET))

;;; (DEFUN (GET-JUSTIFICATION-NEURAL-NETWORK NEURAL-NETWORK) ...)

(CL:DEFUN GET-JUSTIFICATION-NEURAL-NETWORK (JUST)
  "Return the neural network associated with an :AND or :OR justification.
Raise an error if the associated proposition is not linked to a neural network."
  (GET-PROPOSITION-NEURAL-NETWORK (%PROPOSITION JUST) CL:T))

;;; (DEFMETHOD LINK-NEURAL-NETWORK ...)

(CL:DEFMETHOD LINK-NEURAL-NETWORK ((SELF NEURAL-NETWORK) PROP)
  "Link the network `self' to its associated proposition `prop'."
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "link-neural-network: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD UNLINK-NEURAL-NETWORK ...)

(CL:DEFMETHOD UNLINK-NEURAL-NETWORK ((SELF NEURAL-NETWORK))
  "Unlink the network `self' from its associated proposition."
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "unlink-neural-network: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD (GET-NEURAL-NETWORK-PROPOSITION PROPOSITION) ...)

(CL:DEFMETHOD GET-NEURAL-NETWORK-PROPOSITION ((SELF NEURAL-NETWORK))
  "Return the proposition linked to `self'."
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "get-proposition: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD DELETE-NEURAL-NETWORK ...)

(CL:DEFMETHOD DELETE-NEURAL-NETWORK ((SELF NEURAL-NETWORK))
  "Unlink the network `self' from its associated proposition and mark it as deleted."
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "delete-neural-network: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD (DELETED? BOOLEAN) ...)

(CL:DEFMETHOD DELETED? ((SELF NEURAL-NETWORK))
  "Return trun if `self' has been deleted."
  CL:NIL)

;;; (DEFMETHOD ALLOCATE-NETWORK-ARRAYS ...)

(CL:DEFMETHOD ALLOCATE-NETWORK-ARRAYS ((SELF NEURAL-NETWORK) NUM-IN NUM-HIDDEN NUM-OUT)
  "Allocates array space for a neural network with given number of input, hidden and output units."
  (CL:DECLARE (CL:TYPE CL:FIXNUM NUM-IN NUM-HIDDEN NUM-OUT))
  #+MCL
  (CL:CHECK-TYPE NUM-IN CL:FIXNUM)
  #+MCL
  (CL:CHECK-TYPE NUM-HIDDEN CL:FIXNUM)
  #+MCL
  (CL:CHECK-TYPE NUM-OUT CL:FIXNUM)
  (CL:PROGN (CL:SETQ NUM-IN NUM-IN) (CL:SETQ NUM-HIDDEN NUM-HIDDEN)
   (CL:SETQ NUM-OUT NUM-OUT))
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "allocate-arrays: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD RANDOMIZE-NETWORK-WEIGHTS ...)

(CL:DEFMETHOD RANDOMIZE-NETWORK-WEIGHTS ((SELF NEURAL-NETWORK))
  "Randomize the weights of the neural network `self'."
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "randomize-network-weights: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD BUILD-PROPOSITION-NETWORK ...)

(CL:DEFMETHOD BUILD-PROPOSITION-NETWORK ((SELF NEURAL-NETWORK) PROP)
  "Build a neural network for the proposition `prop' and link them.  This builds
a two-layer perceptron network whose input nodes are activated by the truth of `prop's arguments
and whose output node computes the truth of `prop'."
  (CL:SETQ PROP PROP)
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "build-proposition-network: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD (NUMBER-OF-INPUTS INTEGER) ...)

(CL:DEFMETHOD NUMBER-OF-INPUTS ((SELF NEURAL-NETWORK))
  "Return the number of input values expected by `self' (ignores bias unit)."
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "number-of-inputs: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFUN (HELP-COMPUTE-ARGUMENT-INDEX INTEGER) ...)

(CL:DECLAIM
 (CL:FTYPE (CL:FUNCTION (CL:T CL:T CL:T) CL:FIXNUM)
  HELP-COMPUTE-ARGUMENT-INDEX))
(CL:DEFUN HELP-COMPUTE-ARGUMENT-INDEX (SELF ARG KIND)
  "Memoizable helper function for `truth-value-argument-index' and friends."
  (CL:LET*
   ((PROPOSITION (GET-NEURAL-NETWORK-PROPOSITION SELF)) (POS -1)
    (MATCH? CL:NIL) (MAPPING NULL))
   (CL:DECLARE (CL:TYPE CL:FIXNUM POS))
   (CL:WHEN
    (CL:OR (CL:EQ (%KIND ARG) KWD-CHAMELEON-NOT)
     (CL:EQ (%KIND ARG) KWD-CHAMELEON-FAIL))
    (CL:SETQ ARG
     (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%ARGUMENTS ARG)))
      0)))
   (CL:LET*
    ((PROPARG NULL) (VECTOR-000 (%ARGUMENTS PROPOSITION)) (INDEX-000 0)
     (LENGTH-000 (LENGTH VECTOR-000)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX-000 LENGTH-000))
    (CL:LOOP WHILE (CL:< INDEX-000 LENGTH-000) DO
     (CL:SETQ PROPARG
      (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY VECTOR-000))
       INDEX-000))
     (CL:COND
      ((SUBTYPE-OF? (SAFE-PRIMARY-TYPE PROPARG)
        SGT-CHAMELEON-LOGIC-PROPOSITION)
       (CL:PROGN
        (CL:WHEN
         (CL:OR (CL:EQ (%KIND PROPARG) KWD-CHAMELEON-NOT)
          (CL:EQ (%KIND PROPARG) KWD-CHAMELEON-FAIL))
         (CL:SETQ PROPARG
          (CL:AREF
           (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%ARGUMENTS PROPARG)))
           0)))
        (CL:COND
         ((CL:OR
           (CL:AND (CL:EQ KIND KWD-CHAMELEON-TRUTH-VALUE)
            (TRUTH-VALUE-ARGUMENT? SELF PROPARG))
           (CL:AND (CL:EQ KIND KWD-CHAMELEON-IGNORED-VALUE)
            (IGNORED-VALUE-ARGUMENT? SELF PROPARG))
           (CL:AND (CL:EQ KIND KWD-CHAMELEON-VECTOR)
            (VECTOR-ARGUMENT? SELF PROPARG)))
          (CL:SETQ POS (CL:1+ POS)) (CL:SETQ MATCH? CL:T))
         (CL:T (CL:SETQ MATCH? CL:NIL)))
        (CL:COND
         ((CL:EQ PROPARG ARG)
          (CL:RETURN-FROM HELP-COMPUTE-ARGUMENT-INDEX
           (CL:IF MATCH? POS -1)))
         ((CL:EQ (%OPERATOR PROPARG) (%OPERATOR ARG))
          (CL:LET*
           ((*UNIFY-PROPOSITIONS?* CL:T) (*QUERYITERATOR* NULL))
           (CL:DECLARE
            (CL:SPECIAL *UNIFY-PROPOSITIONS?* *QUERYITERATOR*))
           (CL:IF (CL:EQ MAPPING NULL)
            (CL:SETQ MAPPING (NEW-KEY-VALUE-MAP)) (CLEAR MAPPING))
           (CL:WHEN (EQUIVALENT-PROPOSITIONS? PROPARG ARG MAPPING)
            (CL:RETURN-FROM HELP-COMPUTE-ARGUMENT-INDEX
             (CL:IF MATCH? POS -1))))))))
      (CL:T))
     (CL:SETQ INDEX-000 (CL:1+ INDEX-000))))
   (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
    (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
     "INTERNAL ERROR: failed to map neural net input argument: `" ARG
     "'`" PROPOSITION "'")
    (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))

;;; (DEFMETHOD (TRUTH-VALUE-ARGUMENT? BOOLEAN) ...)

(CL:DEFMETHOD TRUTH-VALUE-ARGUMENT? ((SELF NEURAL-NETWORK) ARG)
  "Return TRUE if the partial truth value of `arg' will be considered for `self's inputs.
This top-level method only looks at `arg' and ignores `self'."
  (CL:LET* ((ARGREL (%SURROGATE-VALUE (%OPERATOR ARG))))
   (CL:AND (CL:NOT (CL:EQ ARGREL NULL))
    (CL:OR
     (TEST-PROPERTY? ARGREL
      SGT-CHAMELEON-CHAMELEON-TRUTH-VALUE-RELATION)
     (CL:NOT
      (CL:OR
       (TEST-PROPERTY? ARGREL
        SGT-CHAMELEON-CHAMELEON-IGNORED-VALUE-RELATION)
       (CL:AND
        (TEST-PROPERTY? ARGREL SGT-CHAMELEON-CHAMELEON-VECTOR-RELATION)
        (CL:NOT
         (TEST-PROPERTY? ARGREL
          SGT-CHAMELEON-CHAMELEON-TRUTH-VALUE-RELATION)))))))))

;;; (DEFMETHOD (NUMBER-OF-TRUTH-VALUE-ARGUMENTS INTEGER) ...)

(CL:DEFMETHOD NUMBER-OF-TRUTH-VALUE-ARGUMENTS ((SELF NEURAL-NETWORK) PROP)
  "Return the number of arguments of `prop' whose partial truth value will be considered
for `self's inputs.  This top-level method only looks at `prop' and ignores `self'."
  (CL:LET* ((NTRUTH 0)) (CL:DECLARE (CL:TYPE CL:FIXNUM NTRUTH))
   (CL:LET*
    ((ARG NULL) (VECTOR-000 (%ARGUMENTS PROP)) (INDEX-000 0)
     (LENGTH-000 (LENGTH VECTOR-000)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX-000 LENGTH-000))
    (CL:LOOP WHILE (CL:< INDEX-000 LENGTH-000) DO
     (CL:SETQ ARG
      (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY VECTOR-000))
       INDEX-000))
     (CL:WHEN (TRUTH-VALUE-ARGUMENT? SELF ARG)
      (CL:SETQ NTRUTH (CL:1+ NTRUTH)))
     (CL:SETQ INDEX-000 (CL:1+ INDEX-000))))
   NTRUTH))

;;; (DEFMETHOD (TRUTH-VALUE-ARGUMENT-INDEX INTEGER) ...)

(CL:DEFMETHOD TRUTH-VALUE-ARGUMENT-INDEX ((SELF NEURAL-NETWORK) ARG)
  "Return the 0-based input position of truth value argument `arg'.  Ignores bias unit which
is a network-implementation-specific detail.  Generates indices in the order expected by `set-input-values'.
If `arg' is not a truth value argument, returns -1."
  (CL:LET*
   ((MEMO-TABLE-000 NULL) (MEMOIZED-ENTRY-000 NULL)
    (MEMOIZED-VALUE-000 NULL))
   (CL:WHEN *MEMOIZATION-ENABLED?*
    (CL:SETQ MEMO-TABLE-000
     (%SURROGATE-VALUE
      SGT-CHAMELEON-LOGIC-M-NEURAL-NETWORK.TRUTH-VALUE-ARGUMENT-INDEX-MEMO-TABLE-000))
    (CL:WHEN (CL:EQ MEMO-TABLE-000 NULL)
     (INITIALIZE-MEMOIZATION-TABLE
      SGT-CHAMELEON-LOGIC-M-NEURAL-NETWORK.TRUTH-VALUE-ARGUMENT-INDEX-MEMO-TABLE-000
      "(:MAX-VALUES 1000 :TIMESTAMPS (:KB-UPDATE))")
     (CL:SETQ MEMO-TABLE-000
      (%SURROGATE-VALUE
       SGT-CHAMELEON-LOGIC-M-NEURAL-NETWORK.TRUTH-VALUE-ARGUMENT-INDEX-MEMO-TABLE-000)))
    (CL:SETQ MEMOIZED-ENTRY-000
     (LOOKUP-MRU-MEMOIZED-VALUE MEMO-TABLE-000 SELF ARG
      MEMOIZED-NULL-VALUE NULL -1))
    (CL:SETQ MEMOIZED-VALUE-000 (%%VALUE MEMOIZED-ENTRY-000)))
   (CL:COND
    ((CL:NOT (CL:EQ MEMOIZED-VALUE-000 NULL))
     (CL:WHEN (CL:EQ MEMOIZED-VALUE-000 MEMOIZED-NULL-VALUE)
      (CL:SETQ MEMOIZED-VALUE-000 NULL)))
    (CL:T
     (CL:SETQ MEMOIZED-VALUE-000
      (WRAP-INTEGER
       (HELP-COMPUTE-ARGUMENT-INDEX SELF ARG
        KWD-CHAMELEON-TRUTH-VALUE)))
     (CL:WHEN *MEMOIZATION-ENABLED?*
      (CL:SETF (%%VALUE MEMOIZED-ENTRY-000)
       (CL:IF (CL:EQ MEMOIZED-VALUE-000 NULL) MEMOIZED-NULL-VALUE
        MEMOIZED-VALUE-000)))))
   (CL:LET* ((VALUE-000 MEMOIZED-VALUE-000))
    (%WRAPPER-VALUE VALUE-000))))

;;; (DEFMETHOD (IGNORED-VALUE-ARGUMENT? BOOLEAN) ...)

(CL:DEFMETHOD IGNORED-VALUE-ARGUMENT? ((SELF NEURAL-NETWORK) ARG)
  "Return TRUE if the partial truth value of `arg' will be ignored for `self's inputs.
This top-level method only looks at `arg' and ignores `self'."
  (CL:LET* ((ARGREL (%SURROGATE-VALUE (%OPERATOR ARG))))
   (CL:AND (CL:NOT (CL:EQ ARGREL NULL))
    (CL:OR
     (TEST-PROPERTY? ARGREL
      SGT-CHAMELEON-CHAMELEON-IGNORED-VALUE-RELATION)
     (CL:AND
      (TEST-PROPERTY? ARGREL SGT-CHAMELEON-CHAMELEON-VECTOR-RELATION)
      (CL:NOT
       (TEST-PROPERTY? ARGREL
        SGT-CHAMELEON-CHAMELEON-TRUTH-VALUE-RELATION)))))))

;;; (DEFMETHOD (NUMBER-OF-IGNORED-VALUE-ARGUMENTS INTEGER) ...)

(CL:DEFMETHOD NUMBER-OF-IGNORED-VALUE-ARGUMENTS ((SELF NEURAL-NETWORK) PROP)
  "Return the number of arguments of `prop' whose partial truth value will be ignored
for `self's inputs.  This top-level method only looks at `prop' and ignores `self'."
  (CL:LET* ((NIGNORED 0)) (CL:DECLARE (CL:TYPE CL:FIXNUM NIGNORED))
   (CL:LET*
    ((ARG NULL) (VECTOR-000 (%ARGUMENTS PROP)) (INDEX-000 0)
     (LENGTH-000 (LENGTH VECTOR-000)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX-000 LENGTH-000))
    (CL:LOOP WHILE (CL:< INDEX-000 LENGTH-000) DO
     (CL:SETQ ARG
      (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY VECTOR-000))
       INDEX-000))
     (CL:WHEN (IGNORED-VALUE-ARGUMENT? SELF ARG)
      (CL:SETQ NIGNORED (CL:1+ NIGNORED)))
     (CL:SETQ INDEX-000 (CL:1+ INDEX-000))))
   NIGNORED))

;;; (DEFMETHOD (VECTOR-ARGUMENT? BOOLEAN) ...)

(CL:DEFMETHOD VECTOR-ARGUMENT? ((SELF NEURAL-NETWORK) ARG)
  "Return TRUE if `arg' yields one or more vectors for `self's inputs."
  (CL:SETQ ARG ARG)
  CL:NIL)

;;; (DEFMETHOD (HAS-VECTOR-ARGUMENTS? BOOLEAN) ...)

(CL:DEFMETHOD HAS-VECTOR-ARGUMENTS? ((SELF NEURAL-NETWORK))
  "Return TRUE if `self' has at least one vector input argument."
  CL:NIL)

;;; (DEFMETHOD (NUMBER-OF-VECTOR-ARGUMENTS INTEGER) ...)

(CL:DEFMETHOD NUMBER-OF-VECTOR-ARGUMENTS ((SELF NEURAL-NETWORK) PROP)
  "Return the number of arguments of `prop' that yield one or more vectors
for `self's inputs.  `prop' can be NULL in which case the linked proposition will be used."
  (CL:SETQ PROP PROP)
  0)

;;; (DEFMETHOD (VECTOR-ARGUMENT-INDEX INTEGER) ...)

(CL:DEFMETHOD VECTOR-ARGUMENT-INDEX ((SELF NEURAL-NETWORK) ARG)
  "Return the 0-based input position of vector argument `arg'.  Ignores bias unit which
is a network-implementation-specific detail.  If `arg' is not a vector argument, returns -1."
  (CL:SETQ ARG ARG)
  -1)

;;; (DEFMETHOD (NTH-INPUT FLOAT) ...)

(CL:DEFMETHOD NTH-INPUT ((SELF NEURAL-NETWORK) N)
  "Return the 0-based `n'-th proposition input of `self' (ignores bias unit)."
  (CL:DECLARE (CL:TYPE CL:FIXNUM N))
  #+MCL
  (CL:CHECK-TYPE N CL:FIXNUM)
  (CL:SETQ N N)
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "nth-input: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD (NTH-INPUT-ERROR FLOAT) ...)

(CL:DEFMETHOD NTH-INPUT-ERROR ((SELF NEURAL-NETWORK) N)
  "Return the 0-based `n'-th proposition input error of `self' (ignores bias unit)."
  (CL:DECLARE (CL:TYPE CL:FIXNUM N))
  #+MCL
  (CL:CHECK-TYPE N CL:FIXNUM)
  (CL:SETQ N N)
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "nth-input-error: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFGLOBAL *CHAMELEON-DEFAULT-INPUT-VALUE* ...)

(CL:DEFVAR *CHAMELEON-DEFAULT-INPUT-VALUE* 0.0d0)
(CL:DECLAIM (CL:TYPE CL:DOUBLE-FLOAT *CHAMELEON-DEFAULT-INPUT-VALUE*))

;;; (DEFGLOBAL *WRAPPED-CHAMELEON-DEFAULT-INPUT-VALUE* ...)

(CL:DEFVAR *WRAPPED-CHAMELEON-DEFAULT-INPUT-VALUE* NULL)

;;; (DEFMETHOD SET-INPUT-VALUES ...)

(CL:DEFMETHOD SET-INPUT-VALUES ((SELF NEURAL-NETWORK) VALUES)
  "Set the current truth-value inputs of the network `self' to float `values' in sequence.
Missing inputs will be set to 0.0, extra values will be ignored."
  (CL:SETQ VALUES VALUES)
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "set-input-values: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD SET-VECTOR-INPUT-VALUES ...)

(CL:DEFMETHOD SET-VECTOR-INPUT-VALUES ((SELF NEURAL-NETWORK) VECTORSPECS)
  "Set the current vector inputs of the network `self' to the vectors described by `vectorSpecs'.
Each vector spec describes a vector-generating proposition that produces one or more vectors.  How those specs
are translated into actual numeric vectors such as embeddings is specific to the particular neural network type."
  (CL:SETQ VECTORSPECS VECTORSPECS))

;;; (DEFMETHOD (GET-VECTOR-ARGUMENT-SPEC OBJECT) ...)

(CL:DEFMETHOD GET-VECTOR-ARGUMENT-SPEC ((SELF NEURAL-NETWORK) ARG)
  "Generate a single argument spec for `arg' that can be used for `set-vector-input-values'.
`arg' can either be a proposition or justification."
  (CL:SETQ ARG ARG)
  NULL)

;;; (DEFMETHOD (FORWARD-PROPAGATE-INPUTS FLOAT) ...)

(CL:DEFMETHOD FORWARD-PROPAGATE-INPUTS ((SELF NEURAL-NETWORK))
  "Activates the current inputs of the network `self' to compute its output.
Sets `self's `output' slot and returns the computed value.  Reads input activations and
weights and updates hidden and output activations."
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "forward-propagate-inputs: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD BACKWARD-PROPAGATE-ERROR ...)

(CL:DEFMETHOD BACKWARD-PROPAGATE-ERROR ((SELF NEURAL-NETWORK) ERROR)
  "Given a properly forward activated network `self' for the current set of inputs,
and a training `error' between the current output and the goal value, backpropagate the error and
update `self's vector of input errors.  Reads output, hidden activations and weights and updates
hidden errors and input errors."
  (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT ERROR))
  #+MCL
  (CL:CHECK-TYPE ERROR CL:DOUBLE-FLOAT)
  (CL:SETQ ERROR ERROR)
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "backward-propagate-error: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD UPDATE-NETWORK-WEIGHTS ...)

(CL:DEFMETHOD UPDATE-NETWORK-WEIGHTS ((SELF NEURAL-NETWORK) ERROR)
  "Given a properly forward activated and backpropagated network `self' for the current
inputs and training `error', update the network's weights according to current gradients, learning rate
and momentum terms to reduce the error for the given inputs.  Reads output, hidden and input activations,
hidden error, weights and weight deltas, and updates weights and weight deltas."
  (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT ERROR))
  #+MCL
  (CL:CHECK-TYPE ERROR CL:DOUBLE-FLOAT)
  (CL:SETQ ERROR ERROR)
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "update-network-weights: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD LINK-NEURAL-NETWORK ...)

(CL:DEFMETHOD LINK-NEURAL-NETWORK ((SELF PROPOSITION-NEURAL-NETWORK) PROP)
  "Link the network `self' to its associated proposition `prop'."
  (CL:SETF (%PROPOSITION SELF) PROP)
  (SET-DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS PROP)
   SYM-CHAMELEON-LOGIC-NEURAL-NET SELF NULL))

;;; (DEFMETHOD UNLINK-NEURAL-NETWORK ...)

(CL:DEFMETHOD UNLINK-NEURAL-NETWORK ((SELF PROPOSITION-NEURAL-NETWORK))
  "Unlink the network `self' from its associated proposition."
  (CL:LET* ((PROP (%PROPOSITION SELF)))
   (CL:SETF (%PROPOSITION SELF) NULL)
   (CL:WHEN (CL:NOT (CL:EQ PROP NULL))
    (SET-DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS PROP)
     SYM-CHAMELEON-LOGIC-NEURAL-NET NULL NULL))))

;;; (DEFMETHOD (GET-NEURAL-NETWORK-PROPOSITION PROPOSITION) ...)

(CL:DEFMETHOD GET-NEURAL-NETWORK-PROPOSITION ((SELF PROPOSITION-NEURAL-NETWORK))
  "Return the proposition linked to `self'."
  (%PROPOSITION SELF))

;;; (DEFMETHOD DELETE-NEURAL-NETWORK ...)

(CL:DEFMETHOD DELETE-NEURAL-NETWORK ((SELF PROPOSITION-NEURAL-NETWORK))
  "Unlink the network `self' from its associated proposition and mark it as deleted."
  (UNLINK-NEURAL-NETWORK SELF)
  (CL:SETF (%OUTPUT SELF) MOST-NEGATIVE-FLOAT))

;;; (DEFMETHOD (DELETED? BOOLEAN) ...)

(CL:DEFMETHOD DELETED? ((SELF PROPOSITION-NEURAL-NETWORK))
  "Return trun if `self' has been deleted."
  (CL:= (%OUTPUT SELF) MOST-NEGATIVE-FLOAT))

;;; (DEFMETHOD ALLOCATE-NETWORK-ARRAYS ...)

(CL:DEFMETHOD ALLOCATE-NETWORK-ARRAYS ((SELF PROPOSITION-NEURAL-NETWORK) NUM-IN NUM-HIDDEN NUM-OUT)
  "Allocates array space for a neural network with given number of input, hidden and output units."
  (CL:DECLARE (CL:TYPE CL:FIXNUM NUM-IN NUM-HIDDEN NUM-OUT))
  #+MCL
  (CL:CHECK-TYPE NUM-IN CL:FIXNUM)
  #+MCL
  (CL:CHECK-TYPE NUM-HIDDEN CL:FIXNUM)
  #+MCL
  (CL:CHECK-TYPE NUM-OUT CL:FIXNUM)
  (CL:SETQ NUM-OUT NUM-OUT)
  (CL:SETF (%INPUT SELF) (NEW-VECTOR NUM-IN))
  (CL:SETF (%HIDDEN SELF) (NEW-VECTOR NUM-HIDDEN))
  (CL:SETF (%IH SELF) (NEW-2_D_ARRAY NUM-IN NUM-HIDDEN))
  (CL:SETF (%IH-DELTA SELF) (NEW-2_D_ARRAY NUM-IN NUM-HIDDEN))
  (CL:SETF (%INPUT-ERROR SELF) (NEW-VECTOR NUM-IN))
  (CL:SETF (%HIDDEN-ERROR SELF) (NEW-VECTOR NUM-HIDDEN))
  (CL:SETF (%HO SELF) (NEW-VECTOR NUM-HIDDEN))
  (CL:SETF (%HO-DELTA SELF) (NEW-VECTOR NUM-HIDDEN))
  (CL:WHEN
   (CL:EQ *NEURAL-NETWORK-TRAINING-METHOD* KWD-CHAMELEON-QUICKPROP)
   (CL:SETF (%IH-SLOPE SELF) (NEW-2_D_ARRAY NUM-IN NUM-HIDDEN))
   (CL:SETF (%IH-PREV-SLOPE SELF) (NEW-2_D_ARRAY NUM-IN NUM-HIDDEN))
   (CL:SETF (%HO-SLOPE SELF) (NEW-VECTOR NUM-HIDDEN))
   (CL:SETF (%HO-PREV-SLOPE SELF) (NEW-VECTOR NUM-HIDDEN))))

;;; (DEFMETHOD RANDOMIZE-NETWORK-WEIGHTS ...)

(CL:DEFMETHOD RANDOMIZE-NETWORK-WEIGHTS ((SELF PROPOSITION-NEURAL-NETWORK))
  "Randomize the weights of the neural network `self'."
  (CL:LET*
   ((NUM-IN (LENGTH (%INPUT SELF)))
    (NUM-HIDDEN (LENGTH (%HIDDEN SELF))))
   (CL:DECLARE (CL:TYPE CL:FIXNUM NUM-IN NUM-HIDDEN))
   (CL:LET*
    ((H NULL-INTEGER) (ITER-000 0)
     (UPPER-BOUND-000 (CL:1- NUM-HIDDEN)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM H ITER-000 UPPER-BOUND-000))
    (CL:LOOP WHILE (CL:<= ITER-000 UPPER-BOUND-000) DO
     (CL:SETQ H ITER-000)
     (CL:LET
      ((SELF (%THE-ARRAY (%HO-DELTA SELF))) (VALUE (WRAP-FLOAT 0.0d0))
       (POSITION H))
      (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
       (CL:TYPE CL:FIXNUM POSITION))
      (CL:SETF (CL:AREF SELF POSITION) VALUE))
     (CL:LET*
      ((I NULL-INTEGER) (ITER-001 0) (UPPER-BOUND-001 (CL:1- NUM-IN)))
      (CL:DECLARE (CL:TYPE CL:FIXNUM I ITER-001 UPPER-BOUND-001))
      (CL:LOOP WHILE (CL:<= ITER-001 UPPER-BOUND-001) DO
       (CL:SETQ I ITER-001)
       (CL:LET
        ((SELF (%THE-ARRAY (%IH-DELTA SELF)))
         (VALUE (WRAP-FLOAT 0.0d0))
         (POSITION (CL:+ (CL:* I (%NOF-COLUMNS (%IH-DELTA SELF))) H)))
        (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
         (CL:TYPE CL:FIXNUM POSITION))
        (CL:SETF (CL:AREF SELF POSITION) VALUE))
       (CL:SETQ ITER-001 (CL:1+ ITER-001))))
     (CL:SETQ ITER-000 (CL:1+ ITER-000))))
   (CL:LET*
    ((I NULL-INTEGER) (ITER-002 0)
     (UPPER-BOUND-002 (CL:1- NUM-HIDDEN)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM I ITER-002 UPPER-BOUND-002))
    (CL:LOOP WHILE (CL:<= ITER-002 UPPER-BOUND-002) DO
     (CL:SETQ I ITER-002)
     (CL:LET*
      ((J NULL-INTEGER) (ITER-003 0) (UPPER-BOUND-003 (CL:1- NUM-IN)))
      (CL:DECLARE (CL:TYPE CL:FIXNUM J ITER-003 UPPER-BOUND-003))
      (CL:LOOP WHILE (CL:<= ITER-003 UPPER-BOUND-003) DO
       (CL:SETQ J ITER-003)
       (CL:LET
        ((SELF (%THE-ARRAY (%IH SELF)))
         (VALUE (WRAP-FLOAT (RANDOM-WEIGHT *WEIGHT-RANGE*)))
         (POSITION (CL:+ (CL:* J (%NOF-COLUMNS (%IH SELF))) I)))
        (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
         (CL:TYPE CL:FIXNUM POSITION))
        (CL:SETF (CL:AREF SELF POSITION) VALUE))
       (CL:SETQ ITER-003 (CL:1+ ITER-003))))
     (CL:LET
      ((SELF (%THE-ARRAY (%HO SELF)))
       (VALUE (WRAP-FLOAT (RANDOM-WEIGHT *WEIGHT-RANGE*)))
       (POSITION I))
      (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
       (CL:TYPE CL:FIXNUM POSITION))
      (CL:SETF (CL:AREF SELF POSITION) VALUE))
     (CL:SETQ ITER-002 (CL:1+ ITER-002))))))

;;; (DEFMETHOD BUILD-PROPOSITION-NETWORK ...)

(CL:DEFMETHOD BUILD-PROPOSITION-NETWORK ((SELF PROPOSITION-NEURAL-NETWORK) PROP)
  "Build a neural network for the proposition `prop'.  This builds a two-layer
perceptron network whose input nodes are activated by the truth of `prop's arguments and whose
output node computes the truth of `prop'."
  (CL:LET*
   ((NUM-IN
     (CL:1+
      (CL:- (LENGTH (%ARGUMENTS PROP))
       (NUMBER-OF-IGNORED-VALUE-ARGUMENTS SELF PROP))))
    (NUM-HIDDEN (MIN (CL:+ NUM-IN 0) 20)))
   (CL:DECLARE (CL:TYPE CL:FIXNUM NUM-IN NUM-HIDDEN))
   (CL:WHEN (CL:> NUM-IN 100)
    (CL:SETQ NUM-HIDDEN (CL:+ (FLOOR (CL:/ NUM-IN 10.0d0)) 10)))
   (ALLOCATE-NETWORK-ARRAYS SELF NUM-IN NUM-HIDDEN 1)
   (CL:LET* ((TEST-VALUE-000 (%KIND PROP)))
    (CL:COND
     ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-AND)
       (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-OR))
      (RANDOMIZE-NETWORK-WEIGHTS SELF))
     (CL:T (RANDOMIZE-NETWORK-WEIGHTS SELF))))
   (LINK-NEURAL-NETWORK SELF PROP)))

;;; (DEFMETHOD (NUMBER-OF-INPUTS INTEGER) ...)

(CL:DEFMETHOD NUMBER-OF-INPUTS ((SELF PROPOSITION-NEURAL-NETWORK))
  "Return the number of input values expected by `self' (ignores bias unit)."
  (CL:1- (LENGTH (%INPUT SELF))))

;;; (DEFMETHOD (NTH-INPUT FLOAT) ...)

(CL:DEFMETHOD NTH-INPUT ((SELF PROPOSITION-NEURAL-NETWORK) N)
  "Return the 0-based `n'-th proposition input of `self' (ignores bias unit)."
  (CL:DECLARE (CL:TYPE CL:FIXNUM N))
  #+MCL
  (CL:CHECK-TYPE N CL:FIXNUM)
  (%WRAPPER-VALUE
   (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%INPUT SELF)))
    (CL:THE CL:FIXNUM (CL:1+ N)))))

;;; (DEFMETHOD (NTH-INPUT-ERROR FLOAT) ...)

(CL:DEFMETHOD NTH-INPUT-ERROR ((SELF PROPOSITION-NEURAL-NETWORK) N)
  "Return the 0-based `n'-th proposition input error of `self' (ignores bias unit)."
  (CL:DECLARE (CL:TYPE CL:FIXNUM N))
  #+MCL
  (CL:CHECK-TYPE N CL:FIXNUM)
  (%WRAPPER-VALUE
   (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%INPUT-ERROR SELF)))
    (CL:THE CL:FIXNUM (CL:1+ N)))))

;;; (DEFMETHOD SET-INPUT-VALUES ...)

(CL:DEFMETHOD SET-INPUT-VALUES ((SELF PROPOSITION-NEURAL-NETWORK) VALUES)
  "Set the current truth-value inputs of the network `self' to float `values' in sequence.
Missing inputs will be set to 0.0, extra values will be ignored."
  (CL:LET* ((INPUT (%INPUT SELF)) (NUM-IN (LENGTH INPUT)) (CURSOR 1))
   (CL:DECLARE (CL:TYPE CL:FIXNUM NUM-IN CURSOR))
   (CL:LET
    ((SELF (%THE-ARRAY INPUT)) (VALUE (WRAP-FLOAT 1.0d0)) (POSITION 0))
    (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
     (CL:TYPE CL:FIXNUM POSITION))
    (CL:SETF (CL:AREF SELF POSITION) VALUE))
   (CL:LET* ((TEST-VALUE-000 (SAFE-PRIMARY-TYPE VALUES)))
    (CL:COND
     ((CL:EQ TEST-VALUE-000 SGT-CHAMELEON-STELLA-CONS)
      (CL:PROGN
       (CL:LET* ((VAL NULL) (ITER-000 VALUES))
        (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-000 NIL)) DO
         (CL:SETQ VAL (%%VALUE ITER-000))
         (CL:WHEN (CL:< CURSOR NUM-IN)
          (CL:WHEN (CL:EQ VAL NULL)
           (CL:SETQ VAL *WRAPPED-CHAMELEON-DEFAULT-INPUT-VALUE*))
          (CL:LET
           ((SELF (%THE-ARRAY INPUT)) (VALUE VAL) (POSITION CURSOR))
           (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
            (CL:TYPE CL:FIXNUM POSITION))
           (CL:SETF (CL:AREF SELF POSITION) VALUE))
          (CL:SETQ CURSOR (CL:1+ CURSOR)))
         (CL:SETQ ITER-000 (%%REST ITER-000))))))
     ((SUBTYPE-OF? TEST-VALUE-000 SGT-CHAMELEON-STELLA-LIST)
      (CL:PROGN
       (CL:LET* ((VAL NULL) (ITER-001 (%THE-CONS-LIST VALUES)))
        (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-001 NIL)) DO
         (CL:SETQ VAL (%%VALUE ITER-001))
         (CL:WHEN (CL:< CURSOR NUM-IN)
          (CL:WHEN (CL:EQ VAL NULL)
           (CL:SETQ VAL *WRAPPED-CHAMELEON-DEFAULT-INPUT-VALUE*))
          (CL:LET
           ((SELF (%THE-ARRAY INPUT)) (VALUE VAL) (POSITION CURSOR))
           (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
            (CL:TYPE CL:FIXNUM POSITION))
           (CL:SETF (CL:AREF SELF POSITION) VALUE))
          (CL:SETQ CURSOR (CL:1+ CURSOR)))
         (CL:SETQ ITER-001 (%%REST ITER-001))))))
     ((SUBTYPE-OF? TEST-VALUE-000 SGT-CHAMELEON-STELLA-VECTOR)
      (CL:PROGN
       (CL:LET*
        ((VAL NULL) (VECTOR-000 VALUES) (INDEX-000 0)
         (LENGTH-000 (LENGTH VECTOR-000)))
        (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX-000 LENGTH-000))
        (CL:LOOP WHILE (CL:< INDEX-000 LENGTH-000) DO
         (CL:SETQ VAL
          (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY VECTOR-000))
           INDEX-000))
         (CL:WHEN (CL:< CURSOR NUM-IN)
          (CL:WHEN (CL:EQ VAL NULL)
           (CL:SETQ VAL *WRAPPED-CHAMELEON-DEFAULT-INPUT-VALUE*))
          (CL:LET
           ((SELF (%THE-ARRAY INPUT)) (VALUE VAL) (POSITION CURSOR))
           (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
            (CL:TYPE CL:FIXNUM POSITION))
           (CL:SETF (CL:AREF SELF POSITION) VALUE))
          (CL:SETQ CURSOR (CL:1+ CURSOR)))
         (CL:SETQ INDEX-000 (CL:1+ INDEX-000))))))
     ((SUBTYPE-OF? TEST-VALUE-000 SGT-CHAMELEON-STELLA-SEQUENCE)
      (CL:PROGN
       (CL:LET* ((VAL NULL) (ITER-002 (ALLOCATE-ITERATOR VALUES)))
        (CL:LOOP WHILE (NEXT? ITER-002) DO
         (CL:SETQ VAL (%VALUE ITER-002))
         (CL:WHEN (CL:< CURSOR NUM-IN)
          (CL:WHEN (CL:EQ VAL NULL)
           (CL:SETQ VAL *WRAPPED-CHAMELEON-DEFAULT-INPUT-VALUE*))
          (CL:LET
           ((SELF (%THE-ARRAY INPUT)) (VALUE VAL) (POSITION CURSOR))
           (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
            (CL:TYPE CL:FIXNUM POSITION))
           (CL:SETF (CL:AREF SELF POSITION) VALUE))
          (CL:SETQ CURSOR (CL:1+ CURSOR)))))))
     ((SUBTYPE-OF? TEST-VALUE-000 SGT-CHAMELEON-STELLA-ITERATOR)
      (CL:PROGN
       (CL:LET* ((VAL NULL) (ITER-003 VALUES))
        (CL:LOOP WHILE (NEXT? ITER-003) DO
         (CL:SETQ VAL (%VALUE ITER-003))
         (CL:WHEN (CL:< CURSOR NUM-IN)
          (CL:WHEN (CL:EQ VAL NULL)
           (CL:SETQ VAL *WRAPPED-CHAMELEON-DEFAULT-INPUT-VALUE*))
          (CL:LET
           ((SELF (%THE-ARRAY INPUT)) (VALUE VAL) (POSITION CURSOR))
           (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
            (CL:TYPE CL:FIXNUM POSITION))
           (CL:SETF (CL:AREF SELF POSITION) VALUE))
          (CL:SETQ CURSOR (CL:1+ CURSOR)))))))
     (CL:T
      (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
       (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" TEST-VALUE-000
        "' is not a valid case option")
       (CL:ERROR
        (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))))
   (CL:LOOP WHILE (CL:< CURSOR NUM-IN) DO
    (CL:LET
     ((SELF (%THE-ARRAY INPUT)) (VALUE (WRAP-FLOAT 0.0d0))
      (POSITION CURSOR))
     (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
      (CL:TYPE CL:FIXNUM POSITION))
     (CL:SETF (CL:AREF SELF POSITION) VALUE))
    (CL:SETQ CURSOR (CL:1+ CURSOR)))))

;;; (DEFMETHOD (FORWARD-PROPAGATE-INPUTS FLOAT) ...)

(CL:DEFMETHOD FORWARD-PROPAGATE-INPUTS ((SELF PROPOSITION-NEURAL-NETWORK))
  "Activates the current inputs of the network `self' to compute its output.
Sets `self's `output' slot and returns the computed value.  Reads input activations and
weights and updates hidden and output activations."
  (CL:LET*
   ((INPUT (%INPUT SELF)) (HIDDEN (%HIDDEN SELF))
    (NUM-IN (LENGTH INPUT)) (NUM-HIDDEN (LENGTH HIDDEN))
    (IH (%IH SELF)) (HO (%HO SELF)) (SCORE 0.0d0) (SUM 0.0d0))
   (CL:DECLARE (CL:TYPE CL:FIXNUM NUM-IN NUM-HIDDEN)
    (CL:TYPE CL:DOUBLE-FLOAT SCORE SUM))
   (CL:LET
    ((SELF (%THE-ARRAY INPUT)) (VALUE (WRAP-FLOAT 1.0d0)) (POSITION 0))
    (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
     (CL:TYPE CL:FIXNUM POSITION))
    (CL:SETF (CL:AREF SELF POSITION) VALUE))
   (CL:LET*
    ((I NULL-INTEGER) (ITER-000 0)
     (UPPER-BOUND-000 (CL:1- NUM-HIDDEN)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM I ITER-000 UPPER-BOUND-000))
    (CL:LOOP WHILE (CL:<= ITER-000 UPPER-BOUND-000) DO
     (CL:SETQ I ITER-000)
     (CL:LET*
      ((J NULL-INTEGER) (ITER-001 0) (UPPER-BOUND-001 (CL:1- NUM-IN)))
      (CL:DECLARE (CL:TYPE CL:FIXNUM J ITER-001 UPPER-BOUND-001))
      (CL:LOOP WHILE (CL:<= ITER-001 UPPER-BOUND-001) DO
       (CL:SETQ J ITER-001)
       (CL:SETQ SUM
        (CL:+ SUM
         (CL:*
          (%WRAPPER-VALUE
           (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY INPUT)) J))
          (%WRAPPER-VALUE
           (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY IH))
            (CL:THE CL:FIXNUM (CL:+ (CL:* J (%NOF-COLUMNS IH)) I)))))))
       (CL:SETQ ITER-001 (CL:1+ ITER-001))))
     (CL:LET
      ((SELF (%THE-ARRAY HIDDEN))
       (VALUE
        (WRAP-FLOAT
         (CL:/ 1.0d0
          (CL:+ 1.0d0
           (CL:THE CL:DOUBLE-FLOAT
            (CL:EXP (CL:THE CL:DOUBLE-FLOAT (CL:- 0 SUM))))))))
       (POSITION I))
      (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
       (CL:TYPE CL:FIXNUM POSITION))
      (CL:SETF (CL:AREF SELF POSITION) VALUE))
     (CL:SETQ SCORE
      (CL:+ SCORE
       (CL:*
        (%WRAPPER-VALUE
         (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY HIDDEN)) I))
        (%WRAPPER-VALUE
         (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY HO)) I)))))
     (CL:SETQ ITER-000 (CL:1+ ITER-000))))
   (CL:SETF (%OUTPUT SELF)
    (CL:/ 1.0d0
     (CL:+ 1.0d0
      (CL:THE CL:DOUBLE-FLOAT
       (CL:EXP (CL:THE CL:DOUBLE-FLOAT (CL:- 0 SCORE)))))))
   (%OUTPUT SELF)))

;;; (DEFMETHOD BACKWARD-PROPAGATE-ERROR ...)

(CL:DEFMETHOD BACKWARD-PROPAGATE-ERROR ((SELF PROPOSITION-NEURAL-NETWORK) ERROR)
  "Given a properly forward activated network `self' for the current set of inputs,
and a training `error' between the current output and the goal value, backpropagate the error and
update `self's vector of input errors.  Reads output, hidden activations and weights and updates
hidden errors and input errors."
  (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT ERROR))
  #+MCL
  (CL:CHECK-TYPE ERROR CL:DOUBLE-FLOAT)
  (CL:LET*
   ((LAST-INPUT (CL:1- (LENGTH (%INPUT SELF))))
    (INPUT-ERROR (%INPUT-ERROR SELF)) (IH (%IH SELF))
    (HIDDEN (%HIDDEN SELF)) (LAST-HIDDEN (CL:1- (LENGTH HIDDEN)))
    (HIDDEN-ERROR (%HIDDEN-ERROR SELF)) (HO (%HO SELF))
    (OUTPUT (%OUTPUT SELF)))
   (CL:DECLARE (CL:TYPE CL:FIXNUM LAST-INPUT LAST-HIDDEN)
    (CL:TYPE CL:DOUBLE-FLOAT OUTPUT))
   (CL:SETQ ERROR (CL:* ERROR OUTPUT (CL:- 1.0d0 OUTPUT)))
   (CL:LET*
    ((H NULL-INTEGER) (ITER-000 0) (UPPER-BOUND-000 LAST-HIDDEN)
     (UNBOUNDED?-000 (CL:= UPPER-BOUND-000 NULL-INTEGER)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM H ITER-000 UPPER-BOUND-000))
    (CL:LOOP WHILE
     (CL:OR UNBOUNDED?-000 (CL:<= ITER-000 UPPER-BOUND-000)) DO
     (CL:SETQ H ITER-000)
     (CL:LET
      ((SELF (%THE-ARRAY HIDDEN-ERROR))
       (VALUE
        (WRAP-FLOAT
         (CL:* ERROR
          (%WRAPPER-VALUE
           (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY HO)) H)))))
       (POSITION H))
      (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
       (CL:TYPE CL:FIXNUM POSITION))
      (CL:SETF (CL:AREF SELF POSITION) VALUE))
     (CL:LET
      ((SELF (%THE-ARRAY HIDDEN-ERROR))
       (VALUE
        (WRAP-FLOAT
         (CL:*
          (%WRAPPER-VALUE
           (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY HIDDEN-ERROR))
            H))
          (%WRAPPER-VALUE
           (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY HIDDEN)) H))
          (CL:- 1.0d0
           (%WRAPPER-VALUE
            (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY HIDDEN))
             H))))))
       (POSITION H))
      (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
       (CL:TYPE CL:FIXNUM POSITION))
      (CL:SETF (CL:AREF SELF POSITION) VALUE))
     (CL:SETQ ITER-000 (CL:1+ ITER-000))))
   (CL:LET*
    ((I NULL-INTEGER) (ITER-001 0) (UPPER-BOUND-001 LAST-INPUT)
     (UNBOUNDED?-001 (CL:= UPPER-BOUND-001 NULL-INTEGER)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM I ITER-001 UPPER-BOUND-001))
    (CL:LOOP WHILE
     (CL:OR UNBOUNDED?-001 (CL:<= ITER-001 UPPER-BOUND-001)) DO
     (CL:SETQ I ITER-001)
     (CL:LET
      ((SELF (%THE-ARRAY INPUT-ERROR)) (VALUE (WRAP-FLOAT 0.0d0))
       (POSITION I))
      (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
       (CL:TYPE CL:FIXNUM POSITION))
      (CL:SETF (CL:AREF SELF POSITION) VALUE))
     (CL:LET*
      ((H NULL-INTEGER) (ITER-002 0) (UPPER-BOUND-002 LAST-HIDDEN)
       (UNBOUNDED?-002 (CL:= UPPER-BOUND-002 NULL-INTEGER)))
      (CL:DECLARE (CL:TYPE CL:FIXNUM H ITER-002 UPPER-BOUND-002))
      (CL:LOOP WHILE
       (CL:OR UNBOUNDED?-002 (CL:<= ITER-002 UPPER-BOUND-002)) DO
       (CL:SETQ H ITER-002)
       (CL:LET
        ((SELF (%THE-ARRAY INPUT-ERROR))
         (VALUE
          (WRAP-FLOAT
           (CL:+
            (%WRAPPER-VALUE
             (CL:AREF
              (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY INPUT-ERROR)) I))
            (CL:*
             (%WRAPPER-VALUE
              (CL:AREF
               (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY HIDDEN-ERROR)) H))
             (%WRAPPER-VALUE
              (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY IH))
               (CL:THE CL:FIXNUM
                (CL:+ (CL:* I (%NOF-COLUMNS IH)) H))))))))
         (POSITION I))
        (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
         (CL:TYPE CL:FIXNUM POSITION))
        (CL:SETF (CL:AREF SELF POSITION) VALUE))
       (CL:SETQ ITER-002 (CL:1+ ITER-002))))
     (CL:SETQ ITER-001 (CL:1+ ITER-001))))))

;;; (DEFMETHOD UPDATE-NETWORK-WEIGHTS ...)

(CL:DEFMETHOD UPDATE-NETWORK-WEIGHTS ((SELF PROPOSITION-NEURAL-NETWORK) ERROR)
  "Given a properly forward activated and backpropagated network `self' for the current
inputs and training `error', update the network's weights according to current gradients, learning rate
and momentum terms to reduce the error for the given inputs.  Reads output, hidden and input activations,
hidden error, weights and weight deltas, and updates weights and weight deltas."
  (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT ERROR))
  #+MCL
  (CL:CHECK-TYPE ERROR CL:DOUBLE-FLOAT)
  (CL:LET*
   ((INPUT (%INPUT SELF)) (LAST-INPUT (CL:1- (LENGTH INPUT)))
    (IH (%IH SELF)) (IH-DELTA (%IH-DELTA SELF)) (HIDDEN (%HIDDEN SELF))
    (LAST-HIDDEN (CL:1- (LENGTH HIDDEN)))
    (HIDDEN-ERROR (%HIDDEN-ERROR SELF)) (HO (%HO SELF))
    (HO-DELTA (%HO-DELTA SELF)) (OUTPUT (%OUTPUT SELF)) (DELTA 0.0d0))
   (CL:DECLARE (CL:TYPE CL:FIXNUM LAST-INPUT LAST-HIDDEN)
    (CL:TYPE CL:DOUBLE-FLOAT OUTPUT DELTA))
   (CL:SETQ ERROR (CL:* ERROR OUTPUT (CL:- 1.0d0 OUTPUT)))
   (CL:LET*
    ((H NULL-INTEGER) (ITER-000 0) (UPPER-BOUND-000 LAST-HIDDEN)
     (UNBOUNDED?-000 (CL:= UPPER-BOUND-000 NULL-INTEGER)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM H ITER-000 UPPER-BOUND-000))
    (CL:LOOP WHILE
     (CL:OR UNBOUNDED?-000 (CL:<= ITER-000 UPPER-BOUND-000)) DO
     (CL:SETQ H ITER-000)
     (CL:SETQ DELTA
      (CL:+
       (CL:* *MOMENTUM-TERM*
        (%WRAPPER-VALUE
         (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY HO-DELTA)) H)))
       (CL:* *LEARNING-RATE* ERROR
        (%WRAPPER-VALUE
         (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY HIDDEN)) H)))))
     (CL:LET
      ((SELF (%THE-ARRAY HO))
       (VALUE
        (WRAP-FLOAT
         (CL:+
          (%WRAPPER-VALUE
           (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY HO)) H))
          DELTA)))
       (POSITION H))
      (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
       (CL:TYPE CL:FIXNUM POSITION))
      (CL:SETF (CL:AREF SELF POSITION) VALUE))
     (CL:LET
      ((SELF (%THE-ARRAY HO-DELTA)) (VALUE (WRAP-FLOAT DELTA))
       (POSITION H))
      (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
       (CL:TYPE CL:FIXNUM POSITION))
      (CL:SETF (CL:AREF SELF POSITION) VALUE))
     (CL:LET*
      ((I NULL-INTEGER) (ITER-001 0) (UPPER-BOUND-001 LAST-INPUT)
       (UNBOUNDED?-001 (CL:= UPPER-BOUND-001 NULL-INTEGER)))
      (CL:DECLARE (CL:TYPE CL:FIXNUM I ITER-001 UPPER-BOUND-001))
      (CL:LOOP WHILE
       (CL:OR UNBOUNDED?-001 (CL:<= ITER-001 UPPER-BOUND-001)) DO
       (CL:SETQ I ITER-001)
       (CL:SETQ DELTA
        (CL:+
         (CL:* *MOMENTUM-TERM*
          (%WRAPPER-VALUE
           (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY IH-DELTA))
            (CL:THE CL:FIXNUM
             (CL:+ (CL:* I (%NOF-COLUMNS IH-DELTA)) H)))))
         (CL:* *LEARNING-RATE*
          (%WRAPPER-VALUE
           (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY HIDDEN-ERROR))
            H))
          (%WRAPPER-VALUE
           (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY INPUT)) I)))))
       (CL:LET
        ((SELF (%THE-ARRAY IH))
         (VALUE
          (WRAP-FLOAT
           (CL:+
            (%WRAPPER-VALUE
             (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY IH))
              (CL:THE CL:FIXNUM (CL:+ (CL:* I (%NOF-COLUMNS IH)) H))))
            DELTA)))
         (POSITION (CL:+ (CL:* I (%NOF-COLUMNS IH)) H)))
        (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
         (CL:TYPE CL:FIXNUM POSITION))
        (CL:SETF (CL:AREF SELF POSITION) VALUE))
       (CL:LET
        ((SELF (%THE-ARRAY IH-DELTA)) (VALUE (WRAP-FLOAT DELTA))
         (POSITION (CL:+ (CL:* I (%NOF-COLUMNS IH-DELTA)) H)))
        (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
         (CL:TYPE CL:FIXNUM POSITION))
        (CL:SETF (CL:AREF SELF POSITION) VALUE))
       (CL:SETQ ITER-001 (CL:1+ ITER-001))))
     (CL:SETQ ITER-000 (CL:1+ ITER-000))))))

;;; (DEFCLASS CHAMELEON-NEURAL-NETWORK ...)

(CL:DEFCLASS CHAMELEON-NEURAL-NETWORK (NEURAL-NETWORK)
  ((PROPOSITION :ALLOCATION :INSTANCE :ACCESSOR %PROPOSITION)
   (INPUT :ALLOCATION :INSTANCE :ACCESSOR %INPUT)
   (HIDDEN :ALLOCATION :INSTANCE :ACCESSOR %HIDDEN)
   (OUTPUT :TYPE CL:DOUBLE-FLOAT :INITFORM NULL-FLOAT :ALLOCATION
    :INSTANCE :ACCESSOR %OUTPUT)
   (IH :ALLOCATION :INSTANCE :ACCESSOR %IH)
   (HO :ALLOCATION :INSTANCE :ACCESSOR %HO)
   (INPUT-ERROR :ALLOCATION :INSTANCE :ACCESSOR %INPUT-ERROR)
   (HIDDEN-ERROR :ALLOCATION :INSTANCE :ACCESSOR %HIDDEN-ERROR)
   (OUTPUT-ERROR :TYPE CL:DOUBLE-FLOAT :INITFORM NULL-FLOAT :ALLOCATION
    :INSTANCE :ACCESSOR %OUTPUT-ERROR)
   (IH-DELTA :ALLOCATION :INSTANCE :ACCESSOR %IH-DELTA)
   (HO-DELTA :ALLOCATION :INSTANCE :ACCESSOR %HO-DELTA))
  (:DOCUMENTATION
   "Stream-lined neural network structure that doesn't require float wrapping."))

(CL:DEFUN NEW-CHAMELEON-NEURAL-NETWORK ()
  (CL:LET* ((SELF NULL))
   (CL:SETQ SELF
    (CL:MAKE-INSTANCE (CL:QUOTE CHAMELEON-NEURAL-NETWORK)))
   (CL:SETF (%HO-DELTA SELF) NULL) (CL:SETF (%IH-DELTA SELF) NULL)
   (CL:SETF (%OUTPUT-ERROR SELF) NULL-FLOAT)
   (CL:SETF (%HIDDEN-ERROR SELF) NULL)
   (CL:SETF (%INPUT-ERROR SELF) NULL) (CL:SETF (%HO SELF) NULL)
   (CL:SETF (%IH SELF) NULL) (CL:SETF (%OUTPUT SELF) NULL-FLOAT)
   (CL:SETF (%HIDDEN SELF) NULL) (CL:SETF (%INPUT SELF) NULL)
   (CL:SETF (%PROPOSITION SELF) NULL) SELF))

(CL:DEFMETHOD PRIMARY-TYPE ((SELF CHAMELEON-NEURAL-NETWORK))
  SGT-CHAMELEON-LOGIC-CHAMELEON-NEURAL-NETWORK)

(CL:DEFUN ACCESS-CHAMELEON-NEURAL-NETWORK-SLOT-VALUE (SELF SLOTNAME VALUE SETVALUE?)
  (CL:COND
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-PROPOSITION)
    (CL:IF SETVALUE? (CL:SETF (%PROPOSITION SELF) VALUE)
     (CL:SETQ VALUE (%PROPOSITION SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-INPUT)
    (CL:IF SETVALUE? (CL:SETF (%INPUT SELF) VALUE)
     (CL:SETQ VALUE (%INPUT SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-HIDDEN)
    (CL:IF SETVALUE? (CL:SETF (%HIDDEN SELF) VALUE)
     (CL:SETQ VALUE (%HIDDEN SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-OUTPUT)
    (CL:IF SETVALUE? (CL:SETF (%OUTPUT SELF) (%WRAPPER-VALUE VALUE))
     (CL:SETQ VALUE (WRAP-FLOAT (%OUTPUT SELF)))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-IH)
    (CL:IF SETVALUE? (CL:SETF (%IH SELF) VALUE)
     (CL:SETQ VALUE (%IH SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-HO)
    (CL:IF SETVALUE? (CL:SETF (%HO SELF) VALUE)
     (CL:SETQ VALUE (%HO SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-INPUT-ERROR)
    (CL:IF SETVALUE? (CL:SETF (%INPUT-ERROR SELF) VALUE)
     (CL:SETQ VALUE (%INPUT-ERROR SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-HIDDEN-ERROR)
    (CL:IF SETVALUE? (CL:SETF (%HIDDEN-ERROR SELF) VALUE)
     (CL:SETQ VALUE (%HIDDEN-ERROR SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-OUTPUT-ERROR)
    (CL:IF SETVALUE?
     (CL:SETF (%OUTPUT-ERROR SELF) (%WRAPPER-VALUE VALUE))
     (CL:SETQ VALUE (WRAP-FLOAT (%OUTPUT-ERROR SELF)))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-IH-DELTA)
    (CL:IF SETVALUE? (CL:SETF (%IH-DELTA SELF) VALUE)
     (CL:SETQ VALUE (%IH-DELTA SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-HO-DELTA)
    (CL:IF SETVALUE? (CL:SETF (%HO-DELTA SELF) VALUE)
     (CL:SETQ VALUE (%HO-DELTA SELF))))
   (CL:T
    (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
     (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" SLOTNAME
      "' is not a valid case option")
     (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))
  VALUE)

;;; (DEFMETHOD LINK-NEURAL-NETWORK ...)

(CL:DEFMETHOD LINK-NEURAL-NETWORK ((SELF CHAMELEON-NEURAL-NETWORK) PROP)
  "Link the network `self' to its associated proposition `prop'."
  (CL:SETF (%PROPOSITION SELF) PROP)
  (SET-DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS PROP)
   SYM-CHAMELEON-LOGIC-NEURAL-NET SELF NULL))

;;; (DEFMETHOD UNLINK-NEURAL-NETWORK ...)

(CL:DEFMETHOD UNLINK-NEURAL-NETWORK ((SELF CHAMELEON-NEURAL-NETWORK))
  "Unlink the network `self' from its associated proposition."
  (CL:LET* ((PROP (%PROPOSITION SELF)))
   (CL:SETF (%PROPOSITION SELF) NULL)
   (CL:WHEN (CL:NOT (CL:EQ PROP NULL))
    (SET-DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS PROP)
     SYM-CHAMELEON-LOGIC-NEURAL-NET NULL NULL))))

;;; (DEFMETHOD (GET-NEURAL-NETWORK-PROPOSITION PROPOSITION) ...)

(CL:DEFMETHOD GET-NEURAL-NETWORK-PROPOSITION ((SELF CHAMELEON-NEURAL-NETWORK))
  "Return the proposition linked to `self'."
  (%PROPOSITION SELF))

;;; (DEFMETHOD DELETE-NEURAL-NETWORK ...)

(CL:DEFMETHOD DELETE-NEURAL-NETWORK ((SELF CHAMELEON-NEURAL-NETWORK))
  "Unlink the network `self' from its associated proposition and mark it as deleted."
  (UNLINK-NEURAL-NETWORK SELF)
  (CL:SETF (%OUTPUT SELF) MOST-NEGATIVE-FLOAT))

;;; (DEFMETHOD (DELETED? BOOLEAN) ...)

(CL:DEFMETHOD DELETED? ((SELF CHAMELEON-NEURAL-NETWORK))
  "Return trun if `self' has been deleted."
  (CL:= (%OUTPUT SELF) MOST-NEGATIVE-FLOAT))

;;; (DEFMETHOD ALLOCATE-NETWORK-ARRAYS ...)

(CL:DEFMETHOD ALLOCATE-NETWORK-ARRAYS ((SELF CHAMELEON-NEURAL-NETWORK) NUM-IN NUM-HIDDEN NUM-OUT)
  "Allocates array space for a neural network with given number of input, hidden and output units."
  (CL:DECLARE (CL:TYPE CL:FIXNUM NUM-IN NUM-HIDDEN NUM-OUT))
  #+MCL
  (CL:CHECK-TYPE NUM-IN CL:FIXNUM)
  #+MCL
  (CL:CHECK-TYPE NUM-HIDDEN CL:FIXNUM)
  #+MCL
  (CL:CHECK-TYPE NUM-OUT CL:FIXNUM)
  (CL:SETQ NUM-OUT NUM-OUT)
  (CL:SETF (%INPUT SELF) (NEW-1D-FLOAT-ARRAY NUM-IN))
  (CL:SETF (%HIDDEN SELF) (NEW-1D-FLOAT-ARRAY NUM-HIDDEN))
  (CL:SETF (%IH SELF) (NEW-2D-FLOAT-ARRAY NUM-HIDDEN NUM-IN))
  (CL:SETF (%IH-DELTA SELF) (NEW-2D-FLOAT-ARRAY NUM-HIDDEN NUM-IN))
  (CL:SETF (%INPUT-ERROR SELF) (NEW-1D-FLOAT-ARRAY NUM-IN))
  (CL:SETF (%HIDDEN-ERROR SELF) (NEW-1D-FLOAT-ARRAY NUM-HIDDEN))
  (CL:SETF (%HO SELF) (NEW-1D-FLOAT-ARRAY NUM-HIDDEN))
  (CL:SETF (%HO-DELTA SELF) (NEW-1D-FLOAT-ARRAY NUM-HIDDEN)))

;;; (DEFMETHOD RANDOMIZE-NETWORK-WEIGHTS ...)

(CL:DEFMETHOD RANDOMIZE-NETWORK-WEIGHTS ((SELF CHAMELEON-NEURAL-NETWORK))
  "Randomize the weights of the neural network `self'."
  (CL:LET*
   ((NUM-IN (%DIM1 (%INPUT SELF))) (NUM-HIDDEN (%DIM1 (%HIDDEN SELF)))
    (HO-DELTA-ARRAY (%THE-ARRAY (%HO-DELTA SELF)))
    (IH-DELTA (%IH-DELTA SELF)) (IH (%IH SELF))
    (HO-ARRAY (%THE-ARRAY (%HO SELF))))
   (CL:DECLARE (CL:TYPE CL:FIXNUM NUM-IN NUM-HIDDEN)
    (CL:TYPE CL:SIMPLE-VECTOR HO-DELTA-ARRAY HO-ARRAY))
   (CL:LET*
    ((H NULL-INTEGER) (ITER-000 0)
     (UPPER-BOUND-000 (CL:1- NUM-HIDDEN)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM H ITER-000 UPPER-BOUND-000))
    (CL:LOOP WHILE (CL:<= ITER-000 UPPER-BOUND-000) DO
     (CL:SETQ H ITER-000) (CL:SETF (CL:AREF HO-DELTA-ARRAY H) 0.0d0)
     (CL:LET*
      ((I NULL-INTEGER) (ITER-001 0) (UPPER-BOUND-001 (CL:1- NUM-IN)))
      (CL:DECLARE (CL:TYPE CL:FIXNUM I ITER-001 UPPER-BOUND-001))
      (CL:LOOP WHILE (CL:<= ITER-001 UPPER-BOUND-001) DO
       (CL:SETQ I ITER-001)
       (CL:SETF
        (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY IH-DELTA))
         (CL:THE CL:FIXNUM (CL:+ (CL:* I (%DIM2 IH-DELTA)) H)))
        0.0d0)
       (CL:SETQ ITER-001 (CL:1+ ITER-001))))
     (CL:SETQ ITER-000 (CL:1+ ITER-000))))
   (CL:LET*
    ((I NULL-INTEGER) (ITER-002 0)
     (UPPER-BOUND-002 (CL:1- NUM-HIDDEN)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM I ITER-002 UPPER-BOUND-002))
    (CL:LOOP WHILE (CL:<= ITER-002 UPPER-BOUND-002) DO
     (CL:SETQ I ITER-002)
     (CL:LET*
      ((J NULL-INTEGER) (ITER-003 0) (UPPER-BOUND-003 (CL:1- NUM-IN)))
      (CL:DECLARE (CL:TYPE CL:FIXNUM J ITER-003 UPPER-BOUND-003))
      (CL:LOOP WHILE (CL:<= ITER-003 UPPER-BOUND-003) DO
       (CL:SETQ J ITER-003)
       (CL:SETF
        (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY IH))
         (CL:THE CL:FIXNUM (CL:+ (CL:* J (%DIM2 IH)) I)))
        (RANDOM-WEIGHT *WEIGHT-RANGE*))
       (CL:SETQ ITER-003 (CL:1+ ITER-003))))
     (CL:SETF (CL:AREF HO-ARRAY I) (RANDOM-WEIGHT *WEIGHT-RANGE*))
     (CL:SETQ ITER-002 (CL:1+ ITER-002))))))

;;; (DEFMETHOD BUILD-PROPOSITION-NETWORK ...)

(CL:DEFMETHOD BUILD-PROPOSITION-NETWORK ((SELF CHAMELEON-NEURAL-NETWORK) PROP)
  "Build a neural network for the proposition `prop'.  This builds a two-layer
perceptron network whose input nodes are activated by the truth of `prop's arguments and whose
output node computes the truth of `prop'."
  (CL:LET*
   ((NUM-IN
     (CL:1+
      (CL:- (LENGTH (%ARGUMENTS PROP))
       (NUMBER-OF-IGNORED-VALUE-ARGUMENTS SELF PROP))))
    (NUM-HIDDEN (MIN (CL:+ NUM-IN 0) 20)))
   (CL:DECLARE (CL:TYPE CL:FIXNUM NUM-IN NUM-HIDDEN))
   (CL:WHEN (CL:> NUM-IN 100)
    (CL:SETQ NUM-HIDDEN (CL:+ (FLOOR (CL:/ NUM-IN 10.0d0)) 10)))
   (ALLOCATE-NETWORK-ARRAYS SELF NUM-IN NUM-HIDDEN 1)
   (CL:LET* ((TEST-VALUE-000 (%KIND PROP)))
    (CL:COND
     ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-AND)
       (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-OR))
      (RANDOMIZE-NETWORK-WEIGHTS SELF))
     (CL:T (RANDOMIZE-NETWORK-WEIGHTS SELF))))
   (LINK-NEURAL-NETWORK SELF PROP)))

;;; (DEFMETHOD (NUMBER-OF-INPUTS INTEGER) ...)

(CL:DEFMETHOD NUMBER-OF-INPUTS ((SELF CHAMELEON-NEURAL-NETWORK))
  "Return the number of input values expected by `self' (ignores bias unit)."
  (CL:1- (%DIM1 (%INPUT SELF))))

;;; (DEFMETHOD (NTH-INPUT FLOAT) ...)

(CL:DEFMETHOD NTH-INPUT ((SELF CHAMELEON-NEURAL-NETWORK) N)
  "Return the 0-based `n'-th proposition input of `self' (ignores bias unit)."
  (CL:DECLARE (CL:TYPE CL:FIXNUM N))
  #+MCL
  (CL:CHECK-TYPE N CL:FIXNUM)
  (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%INPUT SELF)))
   (CL:THE CL:FIXNUM (CL:1+ N))))

;;; (DEFMETHOD (NTH-INPUT-ERROR FLOAT) ...)

(CL:DEFMETHOD NTH-INPUT-ERROR ((SELF CHAMELEON-NEURAL-NETWORK) N)
  "Return the 0-based `n'-th proposition input error of `self' (ignores bias unit)."
  (CL:DECLARE (CL:TYPE CL:FIXNUM N))
  #+MCL
  (CL:CHECK-TYPE N CL:FIXNUM)
  (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%INPUT-ERROR SELF)))
   (CL:THE CL:FIXNUM (CL:1+ N))))

;;; (DEFUN COPY-FLOAT-VALUES-TO-BUFFER ...)

(CL:DEFUN COPY-FLOAT-VALUES-TO-BUFFER (VALUES BUFFER START END)
  "Copy the float `values' in sequence to `buffer' between `start' and `end'.
Missing values will be set to 0.0, extra values will be ignored."
  (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR BUFFER)
   (CL:TYPE CL:FIXNUM START END))
  #+MCL
  (CL:CHECK-TYPE BUFFER CL:SIMPLE-VECTOR)
  #+MCL
  (CL:CHECK-TYPE START CL:FIXNUM)
  #+MCL
  (CL:CHECK-TYPE END CL:FIXNUM)
  (CL:LET* ((CURSOR START)) (CL:DECLARE (CL:TYPE CL:FIXNUM CURSOR))
   (CL:LET* ((TEST-VALUE-000 (SAFE-PRIMARY-TYPE VALUES)))
    (CL:COND
     ((SUBTYPE-OF? TEST-VALUE-000 SGT-CHAMELEON-STELLA-VECTOR)
      (CL:PROGN
       (CL:LET*
        ((VAL NULL) (VECTOR-000 VALUES) (INDEX-000 0)
         (LENGTH-000 (LENGTH VECTOR-000)))
        (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX-000 LENGTH-000))
        (CL:LOOP WHILE (CL:< INDEX-000 LENGTH-000) DO
         (CL:SETQ VAL
          (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY VECTOR-000))
           INDEX-000))
         (CL:WHEN (CL:< CURSOR END)
          (CL:WHEN (CL:EQ VAL NULL)
           (CL:SETQ VAL *WRAPPED-CHAMELEON-DEFAULT-INPUT-VALUE*))
          (CL:SETF (CL:AREF BUFFER CURSOR) (%WRAPPER-VALUE VAL))
          (CL:SETQ CURSOR (CL:1+ CURSOR)))
         (CL:SETQ INDEX-000 (CL:1+ INDEX-000))))))
     ((CL:EQ TEST-VALUE-000 SGT-CHAMELEON-STELLA-CONS)
      (CL:PROGN
       (CL:LET* ((VAL NULL) (ITER-000 VALUES))
        (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-000 NIL)) DO
         (CL:SETQ VAL (%%VALUE ITER-000))
         (CL:WHEN (CL:< CURSOR END)
          (CL:WHEN (CL:EQ VAL NULL)
           (CL:SETQ VAL *WRAPPED-CHAMELEON-DEFAULT-INPUT-VALUE*))
          (CL:SETF (CL:AREF BUFFER CURSOR) (%WRAPPER-VALUE VAL))
          (CL:SETQ CURSOR (CL:1+ CURSOR)))
         (CL:SETQ ITER-000 (%%REST ITER-000))))))
     ((SUBTYPE-OF? TEST-VALUE-000 SGT-CHAMELEON-STELLA-LIST)
      (CL:PROGN
       (CL:LET* ((VAL NULL) (ITER-001 (%THE-CONS-LIST VALUES)))
        (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-001 NIL)) DO
         (CL:SETQ VAL (%%VALUE ITER-001))
         (CL:WHEN (CL:< CURSOR END)
          (CL:WHEN (CL:EQ VAL NULL)
           (CL:SETQ VAL *WRAPPED-CHAMELEON-DEFAULT-INPUT-VALUE*))
          (CL:SETF (CL:AREF BUFFER CURSOR) (%WRAPPER-VALUE VAL))
          (CL:SETQ CURSOR (CL:1+ CURSOR)))
         (CL:SETQ ITER-001 (%%REST ITER-001))))))
     ((SUBTYPE-OF? TEST-VALUE-000 SGT-CHAMELEON-STELLA-SEQUENCE)
      (CL:PROGN
       (CL:LET* ((VAL NULL) (ITER-002 (ALLOCATE-ITERATOR VALUES)))
        (CL:LOOP WHILE (NEXT? ITER-002) DO
         (CL:SETQ VAL (%VALUE ITER-002))
         (CL:WHEN (CL:< CURSOR END)
          (CL:WHEN (CL:EQ VAL NULL)
           (CL:SETQ VAL *WRAPPED-CHAMELEON-DEFAULT-INPUT-VALUE*))
          (CL:SETF (CL:AREF BUFFER CURSOR) (%WRAPPER-VALUE VAL))
          (CL:SETQ CURSOR (CL:1+ CURSOR)))))))
     ((SUBTYPE-OF? TEST-VALUE-000 SGT-CHAMELEON-STELLA-ITERATOR)
      (CL:PROGN
       (CL:LET* ((VAL NULL) (ITER-003 VALUES))
        (CL:LOOP WHILE (NEXT? ITER-003) DO
         (CL:SETQ VAL (%VALUE ITER-003))
         (CL:WHEN (CL:< CURSOR END)
          (CL:WHEN (CL:EQ VAL NULL)
           (CL:SETQ VAL *WRAPPED-CHAMELEON-DEFAULT-INPUT-VALUE*))
          (CL:SETF (CL:AREF BUFFER CURSOR) (%WRAPPER-VALUE VAL))
          (CL:SETQ CURSOR (CL:1+ CURSOR)))))))
     ((SUBTYPE-OF? TEST-VALUE-000 SGT-CHAMELEON-STELLA-FLOAT-ARRAY)
      (CL:PROGN
       (CL:LET* ((VALUESARRAY (%THE-ARRAY VALUES)))
        (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR VALUESARRAY))
        (CL:LET*
         ((I NULL-INTEGER) (ITER-004 0)
          (UPPER-BOUND-000 (CL:1- (%DIM1 VALUES))))
         (CL:DECLARE (CL:TYPE CL:FIXNUM I ITER-004 UPPER-BOUND-000))
         (CL:LOOP WHILE (CL:<= ITER-004 UPPER-BOUND-000) DO
          (CL:SETQ I ITER-004)
          (CL:WHEN (CL:< CURSOR END)
           (CL:SETF (CL:AREF BUFFER CURSOR) (CL:AREF VALUESARRAY I))
           (CL:SETQ CURSOR (CL:1+ CURSOR)))
          (CL:SETQ ITER-004 (CL:1+ ITER-004)))))))
     (CL:T
      (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
       (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" TEST-VALUE-000
        "' is not a valid case option")
       (CL:ERROR
        (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))))
   (CL:LOOP WHILE (CL:< CURSOR END) DO
    (CL:SETF (CL:AREF BUFFER CURSOR) 0.0d0)
    (CL:SETQ CURSOR (CL:1+ CURSOR)))))

;;; (DEFMETHOD SET-INPUT-VALUES ...)

(CL:DEFMETHOD SET-INPUT-VALUES ((SELF CHAMELEON-NEURAL-NETWORK) VALUES)
  "Set the current truth-value inputs of the network `self' to float `values' in sequence.
Missing inputs will be set to 0.0, extra values will be ignored."
  (CL:LET* ((INPUT (%INPUT SELF)) (INPUTARRAY (%THE-ARRAY INPUT)))
   (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR INPUTARRAY))
   (CL:SETF (CL:AREF INPUTARRAY 0) 1.0d0)
   (COPY-FLOAT-VALUES-TO-BUFFER VALUES INPUTARRAY 1 (%DIM1 INPUT))))

;;; (DEFMETHOD SET-VECTOR-INPUT-VALUES ...)

(CL:DEFMETHOD SET-VECTOR-INPUT-VALUES ((SELF CHAMELEON-NEURAL-NETWORK) VECTORSPECS)
  "Set the current vector inputs of the network `self' to the vectors described by `vectorSpecs'.
Each vector spec describes a vector-generating proposition that produces one or more vectors.  How those specs
are translated into actual numeric vectors such as embeddings is specific to the particular neural network type."
  (CL:SETQ VECTORSPECS VECTORSPECS)
  (CL:WHEN
   (CL:NOT (ISA? SELF SGT-CHAMELEON-LOGIC-VECTOR-NEURAL-NETWORK))
   (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
    (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
     "set-vector-input-values: Not defined on `" SELF "'")
    (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))

;;; (DEFMETHOD (FORWARD-PROPAGATE-INPUTS FLOAT) ...)

(CL:DEFMETHOD FORWARD-PROPAGATE-INPUTS ((SELF CHAMELEON-NEURAL-NETWORK))
  "Activates the current inputs of the network `self' to compute its output.
Sets `self's `output' slot and returns the computed value.  Reads input activations and
weights and updates hidden and output activations."
  (CL:LET*
   ((INPUT (%INPUT SELF)) (HIDDEN (%HIDDEN SELF))
    (NUM-IN (%DIM1 INPUT)) (NUM-HIDDEN (%DIM1 HIDDEN))
    (INPUT-ARRAY (%THE-ARRAY INPUT)) (HIDDEN-ARRAY (%THE-ARRAY HIDDEN))
    (IH (%IH SELF)) (HO (%HO SELF)) (HO-ARRAY (%THE-ARRAY HO))
    (SCORE 0.0d0) (SUM 0.0d0))
   (CL:DECLARE (CL:TYPE CL:FIXNUM NUM-IN NUM-HIDDEN)
    (CL:TYPE CL:SIMPLE-VECTOR INPUT-ARRAY HIDDEN-ARRAY HO-ARRAY)
    (CL:TYPE CL:DOUBLE-FLOAT SCORE SUM))
   (CL:SETF (CL:AREF INPUT-ARRAY 0) 1.0d0)
   (CL:LET*
    ((I NULL-INTEGER) (ITER-000 0)
     (UPPER-BOUND-000 (CL:1- NUM-HIDDEN)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM I ITER-000 UPPER-BOUND-000))
    (CL:LOOP WHILE (CL:<= ITER-000 UPPER-BOUND-000) DO
     (CL:SETQ I ITER-000) (CL:SETQ SUM 0.0d0)
     (CL:LET*
      ((J NULL-INTEGER) (ITER-001 0) (UPPER-BOUND-001 (CL:1- NUM-IN)))
      (CL:DECLARE (CL:TYPE CL:FIXNUM J ITER-001 UPPER-BOUND-001))
      (CL:LOOP WHILE (CL:<= ITER-001 UPPER-BOUND-001) DO
       (CL:SETQ J ITER-001)
       (CL:SETQ SUM
        (CL:+ SUM
         (CL:* (CL:AREF INPUT-ARRAY J)
          (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY IH))
           (CL:THE CL:FIXNUM (CL:+ (CL:* J (%DIM2 IH)) I))))))
       (CL:SETQ ITER-001 (CL:1+ ITER-001))))
     (CL:SETF (CL:AREF HIDDEN-ARRAY I)
      (CL:/ 1.0d0
       (CL:+ 1.0d0
        (CL:THE CL:DOUBLE-FLOAT
         (CL:EXP (CL:THE CL:DOUBLE-FLOAT (CL:- 0 SUM)))))))
     (CL:SETQ SCORE
      (CL:+ SCORE
       (CL:* (CL:AREF HIDDEN-ARRAY I) (CL:AREF HO-ARRAY I))))
     (CL:SETQ ITER-000 (CL:1+ ITER-000))))
   (CL:SETF (%OUTPUT SELF)
    (CL:/ 1.0d0
     (CL:+ 1.0d0
      (CL:THE CL:DOUBLE-FLOAT
       (CL:EXP (CL:THE CL:DOUBLE-FLOAT (CL:- 0 SCORE)))))))
   (%OUTPUT SELF)))

;;; (DEFMETHOD BACKWARD-PROPAGATE-ERROR ...)

(CL:DEFMETHOD BACKWARD-PROPAGATE-ERROR ((SELF CHAMELEON-NEURAL-NETWORK) ERROR)
  "Given a properly forward activated network `self' for the current set of inputs,
and a training `error' between the current output and the goal value, backpropagate the error and
update `self's vector of input errors.  Reads output, hidden activations and weights and updates
hidden errors and input errors."
  (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT ERROR))
  #+MCL
  (CL:CHECK-TYPE ERROR CL:DOUBLE-FLOAT)
  (CL:LET*
   ((LAST-INPUT (CL:1- (%DIM1 (%INPUT SELF))))
    (INPUT-ERROR (%INPUT-ERROR SELF))
    (INPUT-ERROR-ARRAY (%THE-ARRAY INPUT-ERROR)) (IH (%IH SELF))
    (HIDDEN (%HIDDEN SELF)) (HIDDEN-ARRAY (%THE-ARRAY HIDDEN))
    (LAST-HIDDEN (CL:1- (%DIM1 HIDDEN)))
    (HIDDEN-ERROR (%HIDDEN-ERROR SELF))
    (HIDDEN-ERROR-ARRAY (%THE-ARRAY HIDDEN-ERROR)) (HO (%HO SELF))
    (HO-ARRAY (%THE-ARRAY HO)) (OUTPUT (%OUTPUT SELF)))
   (CL:DECLARE (CL:TYPE CL:FIXNUM LAST-INPUT LAST-HIDDEN)
    (CL:TYPE CL:SIMPLE-VECTOR INPUT-ERROR-ARRAY HIDDEN-ARRAY
     HIDDEN-ERROR-ARRAY HO-ARRAY)
    (CL:TYPE CL:DOUBLE-FLOAT OUTPUT))
   (CL:SETQ ERROR (CL:* ERROR OUTPUT (CL:- 1.0d0 OUTPUT)))
   (CL:LET*
    ((H NULL-INTEGER) (ITER-000 0) (UPPER-BOUND-000 LAST-HIDDEN)
     (UNBOUNDED?-000 (CL:= UPPER-BOUND-000 NULL-INTEGER)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM H ITER-000 UPPER-BOUND-000))
    (CL:LOOP WHILE
     (CL:OR UNBOUNDED?-000 (CL:<= ITER-000 UPPER-BOUND-000)) DO
     (CL:SETQ H ITER-000)
     (CL:SETF (CL:AREF HIDDEN-ERROR-ARRAY H)
      (CL:* ERROR (CL:AREF HO-ARRAY H)))
     (CL:SETF (CL:AREF HIDDEN-ERROR-ARRAY H)
      (CL:* (CL:AREF HIDDEN-ERROR-ARRAY H) (CL:AREF HIDDEN-ARRAY H)
       (CL:- 1.0d0 (CL:AREF HIDDEN-ARRAY H))))
     (CL:SETQ ITER-000 (CL:1+ ITER-000))))
   (CL:LET*
    ((I NULL-INTEGER) (ITER-001 0) (UPPER-BOUND-001 LAST-INPUT)
     (UNBOUNDED?-001 (CL:= UPPER-BOUND-001 NULL-INTEGER)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM I ITER-001 UPPER-BOUND-001))
    (CL:LOOP WHILE
     (CL:OR UNBOUNDED?-001 (CL:<= ITER-001 UPPER-BOUND-001)) DO
     (CL:SETQ I ITER-001) (CL:SETF (CL:AREF INPUT-ERROR-ARRAY I) 0.0d0)
     (CL:LET*
      ((H NULL-INTEGER) (ITER-002 0) (UPPER-BOUND-002 LAST-HIDDEN)
       (UNBOUNDED?-002 (CL:= UPPER-BOUND-002 NULL-INTEGER)))
      (CL:DECLARE (CL:TYPE CL:FIXNUM H ITER-002 UPPER-BOUND-002))
      (CL:LOOP WHILE
       (CL:OR UNBOUNDED?-002 (CL:<= ITER-002 UPPER-BOUND-002)) DO
       (CL:SETQ H ITER-002)
       (CL:SETF (CL:AREF INPUT-ERROR-ARRAY I)
        (CL:+ (CL:AREF INPUT-ERROR-ARRAY I)
         (CL:* (CL:AREF HIDDEN-ERROR-ARRAY H)
          (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY IH))
           (CL:THE CL:FIXNUM (CL:+ (CL:* I (%DIM2 IH)) H))))))
       (CL:SETQ ITER-002 (CL:1+ ITER-002))))
     (CL:SETQ ITER-001 (CL:1+ ITER-001))))))

;;; (DEFMETHOD UPDATE-NETWORK-WEIGHTS ...)

(CL:DEFMETHOD UPDATE-NETWORK-WEIGHTS ((SELF CHAMELEON-NEURAL-NETWORK) ERROR)
  "Given a properly forward activated and backpropagated network `self' for the current
inputs and training `error', update the network's weights according to current gradients, learning rate
and momentum terms to reduce the error for the given inputs.  Reads output, hidden and input activations,
hidden error, weights and weight deltas, and updates weights and weight deltas."
  (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT ERROR))
  #+MCL
  (CL:CHECK-TYPE ERROR CL:DOUBLE-FLOAT)
  (CL:LET*
   ((INPUT (%INPUT SELF)) (LAST-INPUT (CL:1- (%DIM1 INPUT)))
    (INPUT-ARRAY (%THE-ARRAY INPUT)) (IH (%IH SELF))
    (IH-DELTA (%IH-DELTA SELF)) (HIDDEN (%HIDDEN SELF))
    (LAST-HIDDEN (CL:1- (%DIM1 HIDDEN)))
    (HIDDEN-ARRAY (%THE-ARRAY HIDDEN))
    (HIDDEN-ERROR (%HIDDEN-ERROR SELF))
    (HIDDEN-ERROR-ARRAY (%THE-ARRAY HIDDEN-ERROR)) (HO (%HO SELF))
    (HO-ARRAY (%THE-ARRAY HO)) (HO-DELTA (%HO-DELTA SELF))
    (HO-DELTA-ARRAY (%THE-ARRAY HO-DELTA)) (OUTPUT (%OUTPUT SELF))
    (DELTA 0.0d0))
   (CL:DECLARE (CL:TYPE CL:FIXNUM LAST-INPUT LAST-HIDDEN)
    (CL:TYPE CL:SIMPLE-VECTOR INPUT-ARRAY HIDDEN-ARRAY
     HIDDEN-ERROR-ARRAY HO-ARRAY HO-DELTA-ARRAY)
    (CL:TYPE CL:DOUBLE-FLOAT OUTPUT DELTA))
   (CL:SETQ ERROR (CL:* ERROR OUTPUT (CL:- 1.0d0 OUTPUT)))
   (CL:LET*
    ((H NULL-INTEGER) (ITER-000 0) (UPPER-BOUND-000 LAST-HIDDEN)
     (UNBOUNDED?-000 (CL:= UPPER-BOUND-000 NULL-INTEGER)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM H ITER-000 UPPER-BOUND-000))
    (CL:LOOP WHILE
     (CL:OR UNBOUNDED?-000 (CL:<= ITER-000 UPPER-BOUND-000)) DO
     (CL:SETQ H ITER-000)
     (CL:SETQ DELTA
      (CL:+ (CL:* *MOMENTUM-TERM* (CL:AREF HO-DELTA-ARRAY H))
       (CL:* *LEARNING-RATE* ERROR (CL:AREF HIDDEN-ARRAY H))))
     (CL:SETF (CL:AREF HO-ARRAY H) (CL:+ (CL:AREF HO-ARRAY H) DELTA))
     (CL:SETF (CL:AREF HO-DELTA-ARRAY H) DELTA)
     (CL:LET*
      ((I NULL-INTEGER) (ITER-001 0) (UPPER-BOUND-001 LAST-INPUT)
       (UNBOUNDED?-001 (CL:= UPPER-BOUND-001 NULL-INTEGER)))
      (CL:DECLARE (CL:TYPE CL:FIXNUM I ITER-001 UPPER-BOUND-001))
      (CL:LOOP WHILE
       (CL:OR UNBOUNDED?-001 (CL:<= ITER-001 UPPER-BOUND-001)) DO
       (CL:SETQ I ITER-001)
       (CL:SETQ DELTA
        (CL:+
         (CL:* *MOMENTUM-TERM*
          (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY IH-DELTA))
           (CL:THE CL:FIXNUM (CL:+ (CL:* I (%DIM2 IH-DELTA)) H))))
         (CL:* *LEARNING-RATE* (CL:AREF HIDDEN-ERROR-ARRAY H)
          (CL:AREF INPUT-ARRAY I))))
       (CL:SETF
        (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY IH))
         (CL:THE CL:FIXNUM (CL:+ (CL:* I (%DIM2 IH)) H)))
        (CL:+
         (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY IH))
          (CL:THE CL:FIXNUM (CL:+ (CL:* I (%DIM2 IH)) H)))
         DELTA))
       (CL:SETF
        (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY IH-DELTA))
         (CL:THE CL:FIXNUM (CL:+ (CL:* I (%DIM2 IH-DELTA)) H)))
        DELTA)
       (CL:SETQ ITER-001 (CL:1+ ITER-001))))
     (CL:SETQ ITER-000 (CL:1+ ITER-000))))))

;;; (DEFCLASS VECTOR-NEURAL-NETWORK ...)

(CL:DEFCLASS VECTOR-NEURAL-NETWORK (NEURAL-NETWORK)
  ((N-VECTOR-ARGUMENTS :TYPE CL:FIXNUM :INITFORM NULL-INTEGER
    :ALLOCATION :INSTANCE :ACCESSOR %N-VECTOR-ARGUMENTS)
   (N-VECTOR-ARGUMENT-SPECS :TYPE CL:FIXNUM :INITFORM NULL-INTEGER
    :ALLOCATION :INSTANCE :ACCESSOR %N-VECTOR-ARGUMENT-SPECS)
   (N-VECTOR-ARGUMENT-INPUTS :TYPE CL:FIXNUM :INITFORM NULL-INTEGER
    :ALLOCATION :INSTANCE :ACCESSOR %N-VECTOR-ARGUMENT-INPUTS))
  (:DOCUMENTATION
   "Neural network that supports vector input arguments."))

(CL:DEFUN NEW-VECTOR-NEURAL-NETWORK ()
  (CL:LET* ((SELF NULL))
   (CL:SETQ SELF (CL:MAKE-INSTANCE (CL:QUOTE VECTOR-NEURAL-NETWORK)))
   (CL:SETF (%N-VECTOR-ARGUMENT-INPUTS SELF) -1)
   (CL:SETF (%N-VECTOR-ARGUMENT-SPECS SELF) -1)
   (CL:SETF (%N-VECTOR-ARGUMENTS SELF) -1) SELF))

(CL:DEFMETHOD PRIMARY-TYPE ((SELF VECTOR-NEURAL-NETWORK))
  SGT-CHAMELEON-LOGIC-VECTOR-NEURAL-NETWORK)

(CL:DEFUN ACCESS-VECTOR-NEURAL-NETWORK-SLOT-VALUE (SELF SLOTNAME VALUE SETVALUE?)
  (CL:COND
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-N-VECTOR-ARGUMENTS)
    (CL:IF SETVALUE?
     (CL:SETF (%N-VECTOR-ARGUMENTS SELF) (%WRAPPER-VALUE VALUE))
     (CL:SETQ VALUE (WRAP-INTEGER (%N-VECTOR-ARGUMENTS SELF)))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-N-VECTOR-ARGUMENT-SPECS)
    (CL:IF SETVALUE?
     (CL:SETF (%N-VECTOR-ARGUMENT-SPECS SELF) (%WRAPPER-VALUE VALUE))
     (CL:SETQ VALUE (WRAP-INTEGER (%N-VECTOR-ARGUMENT-SPECS SELF)))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-N-VECTOR-ARGUMENT-INPUTS)
    (CL:IF SETVALUE?
     (CL:SETF (%N-VECTOR-ARGUMENT-INPUTS SELF) (%WRAPPER-VALUE VALUE))
     (CL:SETQ VALUE (WRAP-INTEGER (%N-VECTOR-ARGUMENT-INPUTS SELF)))))
   (CL:T
    (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
     (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" SLOTNAME
      "' is not a valid case option")
     (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))
  VALUE)

;;; (DEFMETHOD (VECTOR-ARGUMENT? BOOLEAN) ...)

(CL:DEFMETHOD VECTOR-ARGUMENT? ((SELF VECTOR-NEURAL-NETWORK) ARG)
  "Return TRUE if `arg' yields one or more vectors for `self's inputs."
  (CL:LET* ((ARGREL (%SURROGATE-VALUE (%OPERATOR ARG))))
   (CL:AND (CL:NOT (CL:EQ ARGREL NULL))
    (TEST-PROPERTY? ARGREL SGT-CHAMELEON-CHAMELEON-VECTOR-RELATION))))

;;; (DEFMETHOD (HAS-VECTOR-ARGUMENTS? BOOLEAN) ...)

(CL:DEFMETHOD HAS-VECTOR-ARGUMENTS? ((SELF VECTOR-NEURAL-NETWORK))
  "Return TRUE if `self' has at least one vector input argument."
  (CL:LET* ((NARGS (%N-VECTOR-ARGUMENTS SELF)))
   (CL:DECLARE (CL:TYPE CL:FIXNUM NARGS))
   (CL:WHEN (CL:< NARGS 0)
    (CL:SETQ NARGS (NUMBER-OF-VECTOR-ARGUMENTS SELF NULL)))
   (> NARGS 0)))

;;; (DEFMETHOD (NUMBER-OF-VECTOR-ARGUMENTS INTEGER) ...)

(CL:DEFMETHOD NUMBER-OF-VECTOR-ARGUMENTS ((SELF VECTOR-NEURAL-NETWORK) PROP)
  "Return the number of arguments of `prop' that yield one or more vectors
for `self's inputs.  `prop' can be NULL in which case the linked proposition will be used."
  (CL:LET* ((NARGS (%N-VECTOR-ARGUMENTS SELF)))
   (CL:DECLARE (CL:TYPE CL:FIXNUM NARGS))
   (CL:WHEN (CL:< NARGS 0)
    (CL:WHEN (CL:EQ PROP NULL)
     (CL:SETQ PROP (GET-NEURAL-NETWORK-PROPOSITION SELF)))
    (CL:SETQ NARGS 0)
    (CL:LET*
     ((ARG NULL) (VECTOR-000 (%ARGUMENTS PROP)) (INDEX-000 0)
      (LENGTH-000 (LENGTH VECTOR-000)))
     (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX-000 LENGTH-000))
     (CL:LOOP WHILE (CL:< INDEX-000 LENGTH-000) DO
      (CL:SETQ ARG
       (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY VECTOR-000))
        INDEX-000))
      (CL:WHEN (VECTOR-ARGUMENT? SELF ARG)
       (CL:SETQ NARGS (CL:1+ NARGS)))
      (CL:SETQ INDEX-000 (CL:1+ INDEX-000))))
    (CL:SETF (%N-VECTOR-ARGUMENTS SELF) NARGS))
   NARGS))

;;; (DEFMETHOD (VECTOR-ARGUMENT-INDEX INTEGER) ...)

(CL:DEFMETHOD VECTOR-ARGUMENT-INDEX ((SELF VECTOR-NEURAL-NETWORK) ARG)
  "Return the 0-based input position of vector argument `arg'.  Ignores bias unit which
is a network-implementation-specific detail.  If `arg' is not a vector argument, returns -1."
  (CL:LET*
   ((MEMO-TABLE-000 NULL) (MEMOIZED-ENTRY-000 NULL)
    (MEMOIZED-VALUE-000 NULL))
   (CL:WHEN *MEMOIZATION-ENABLED?*
    (CL:SETQ MEMO-TABLE-000
     (%SURROGATE-VALUE
      SGT-CHAMELEON-LOGIC-M-VECTOR-NEURAL-NETWORK.VECTOR-ARGUMENT-INDEX-MEMO-TABLE-000))
    (CL:WHEN (CL:EQ MEMO-TABLE-000 NULL)
     (INITIALIZE-MEMOIZATION-TABLE
      SGT-CHAMELEON-LOGIC-M-VECTOR-NEURAL-NETWORK.VECTOR-ARGUMENT-INDEX-MEMO-TABLE-000
      "(:MAX-VALUES 1000 :TIMESTAMPS (:KB-UPDATE))")
     (CL:SETQ MEMO-TABLE-000
      (%SURROGATE-VALUE
       SGT-CHAMELEON-LOGIC-M-VECTOR-NEURAL-NETWORK.VECTOR-ARGUMENT-INDEX-MEMO-TABLE-000)))
    (CL:SETQ MEMOIZED-ENTRY-000
     (LOOKUP-MRU-MEMOIZED-VALUE MEMO-TABLE-000 SELF ARG
      MEMOIZED-NULL-VALUE NULL -1))
    (CL:SETQ MEMOIZED-VALUE-000 (%%VALUE MEMOIZED-ENTRY-000)))
   (CL:COND
    ((CL:NOT (CL:EQ MEMOIZED-VALUE-000 NULL))
     (CL:WHEN (CL:EQ MEMOIZED-VALUE-000 MEMOIZED-NULL-VALUE)
      (CL:SETQ MEMOIZED-VALUE-000 NULL)))
    (CL:T
     (CL:SETQ MEMOIZED-VALUE-000
      (WRAP-INTEGER
       (HELP-COMPUTE-ARGUMENT-INDEX SELF ARG KWD-CHAMELEON-VECTOR)))
     (CL:WHEN *MEMOIZATION-ENABLED?*
      (CL:SETF (%%VALUE MEMOIZED-ENTRY-000)
       (CL:IF (CL:EQ MEMOIZED-VALUE-000 NULL) MEMOIZED-NULL-VALUE
        MEMOIZED-VALUE-000)))))
   (CL:LET* ((VALUE-000 MEMOIZED-VALUE-000))
    (%WRAPPER-VALUE VALUE-000))))

;;; (DEFMETHOD (NUMBER-OF-VECTOR-ARGUMENT-SPECS INTEGER) ...)

(CL:DEFMETHOD NUMBER-OF-VECTOR-ARGUMENT-SPECS ((SELF VECTOR-NEURAL-NETWORK) PROP)
  "Return the total number of argument specs generated by vector arguments of `prop'.
This is only different than `number-of-vector-arguments' if at least one of `prop's vector argument
relations has arity > 1.  `prop' can be NULL in which case the linked proposition will be used."
  (CL:LET* ((NINPS (%N-VECTOR-ARGUMENT-SPECS SELF)))
   (CL:DECLARE (CL:TYPE CL:FIXNUM NINPS))
   (CL:WHEN (CL:< NINPS 0)
    (CL:WHEN (CL:EQ PROP NULL)
     (CL:SETQ PROP (GET-NEURAL-NETWORK-PROPOSITION SELF)))
    (CL:SETQ NINPS 0)
    (CL:LET*
     ((ARG NULL) (VECTOR-000 (%ARGUMENTS PROP)) (INDEX-000 0)
      (LENGTH-000 (LENGTH VECTOR-000)))
     (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX-000 LENGTH-000))
     (CL:LOOP WHILE (CL:< INDEX-000 LENGTH-000) DO
      (CL:SETQ ARG
       (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY VECTOR-000))
        INDEX-000))
      (CL:WHEN (VECTOR-ARGUMENT? SELF ARG)
       (CL:LET*
        ((REL (%SURROGATE-VALUE (%OPERATOR ARG)))
         (ARITY
          (ACCESS-BINARY-VALUE REL
           SGT-CHAMELEON-CHAMELEON-VECTOR-ARITY)))
        (CL:WHEN (CL:NOT (INTEGER? ARITY))
         (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
          (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
           "number-of-vector-argument-specs: Missing or incorrect arity specifications for `"
           REL "'")
          (CL:ERROR
           (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))
        (CL:SETQ NINPS
         (CL:TRUNCATE (CL:+ NINPS (NUMBER-WRAPPER-TO-FLOAT ARITY))))))
      (CL:SETQ INDEX-000 (CL:1+ INDEX-000))))
    (CL:SETF (%N-VECTOR-ARGUMENT-SPECS SELF) NINPS))
   NINPS))

;;; (DEFMETHOD (NUMBER-OF-VECTOR-ARGUMENT-INPUTS INTEGER) ...)

(CL:DEFMETHOD NUMBER-OF-VECTOR-ARGUMENT-INPUTS ((SELF VECTOR-NEURAL-NETWORK) PROP)
  "Return the total number of input positions to store all elements of all vector
arguments of `prop'.  `prop' can be NULL in which case the linked proposition will be used."
  (CL:LET* ((NINPS (%N-VECTOR-ARGUMENT-INPUTS SELF)))
   (CL:DECLARE (CL:TYPE CL:FIXNUM NINPS))
   (CL:WHEN (CL:< NINPS 0)
    (CL:WHEN (CL:EQ PROP NULL)
     (CL:SETQ PROP (GET-NEURAL-NETWORK-PROPOSITION SELF)))
    (CL:SETQ NINPS 0)
    (CL:LET*
     ((ARG NULL) (VECTOR-000 (%ARGUMENTS PROP)) (INDEX-000 0)
      (LENGTH-000 (LENGTH VECTOR-000)))
     (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX-000 LENGTH-000))
     (CL:LOOP WHILE (CL:< INDEX-000 LENGTH-000) DO
      (CL:SETQ ARG
       (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY VECTOR-000))
        INDEX-000))
      (CL:WHEN (VECTOR-ARGUMENT? SELF ARG)
       (CL:LET*
        ((REL (%SURROGATE-VALUE (%OPERATOR ARG)))
         (ARITY
          (ACCESS-BINARY-VALUE REL
           SGT-CHAMELEON-CHAMELEON-VECTOR-ARITY))
         (DIMS
          (ACCESS-BINARY-VALUE REL
           SGT-CHAMELEON-CHAMELEON-VECTOR-DIMENSIONS)))
        (CL:WHEN (CL:NOT (CL:AND (INTEGER? ARITY) (INTEGER? DIMS)))
         (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
          (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
           "number-of-vector-argument-inputs: Missing or incorrect arity/dimension specifications for `"
           REL "'")
          (CL:ERROR
           (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))
        (CL:SETQ NINPS
         (CL:TRUNCATE
          (CL:+ NINPS
           (CL:* (NUMBER-WRAPPER-TO-FLOAT ARITY)
            (NUMBER-WRAPPER-TO-FLOAT DIMS)))))))
      (CL:SETQ INDEX-000 (CL:1+ INDEX-000))))
    (CL:SETF (%N-VECTOR-ARGUMENT-INPUTS SELF) NINPS))
   NINPS))

;;; (DEFMETHOD SET-VECTOR-INPUT-VALUES ...)

(CL:DEFMETHOD SET-VECTOR-INPUT-VALUES ((SELF VECTOR-NEURAL-NETWORK) VECTORSPECS)
  "Set the current vector inputs of the network `self' to the vectors described by `vectorSpecs'.
Each vector spec describes a vector-generating proposition that produces one or more vectors.  How those specs
are translated into actual numeric vectors such as embeddings is specific to the particular neural network type."
  (CL:SETQ VECTORSPECS VECTORSPECS)
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "set-vector-input-values: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD (GET-VECTOR-ARGUMENT-SPEC OBJECT) ...)

(CL:DEFMETHOD GET-VECTOR-ARGUMENT-SPEC ((SELF VECTOR-NEURAL-NETWORK) ARG)
  "Generate a single argument spec for `arg' that can be used for `set-vector-input-values'.
`arg' can either be a proposition or justification."
  (CL:LET* ((TEST-VALUE-000 (SAFE-PRIMARY-TYPE ARG)))
   (CL:COND
    ((SUBTYPE-OF? TEST-VALUE-000 SGT-CHAMELEON-LOGIC-JUSTIFICATION)
     (CL:PROGN
      (CL:LET* ((*CURRENTJUSTIFICATION* ARG))
       (CL:DECLARE (CL:SPECIAL *CURRENTJUSTIFICATION*))
       (GENERATE-PROPOSITION (%PROPOSITION ARG)))))
    ((SUBTYPE-OF? TEST-VALUE-000 SGT-CHAMELEON-LOGIC-PROPOSITION)
     (CL:PROGN (GENERATE-PROPOSITION ARG)))
    (CL:T
     (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
      (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" TEST-VALUE-000
       "' is not a valid case option")
      (CL:ERROR
       (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))))

;;; (DEFCLASS TENSORFLOW-NEURAL-NETWORK ...)

(CL:DEFCLASS TENSORFLOW-NEURAL-NETWORK (VECTOR-NEURAL-NETWORK)
  ((PROPOSITION :ALLOCATION :INSTANCE :ACCESSOR %PROPOSITION)
   (MODEL :ALLOCATION :INSTANCE :ACCESSOR %MODEL))
  (:DOCUMENTATION
   "Neural network that is implemented by callbacks to TensorFlow."))

(CL:DEFUN NEW-TENSORFLOW-NEURAL-NETWORK ()
  (CL:LET* ((SELF NULL))
   (CL:SETQ SELF
    (CL:MAKE-INSTANCE (CL:QUOTE TENSORFLOW-NEURAL-NETWORK)))
   (CL:SETF (%N-VECTOR-ARGUMENT-INPUTS SELF) -1)
   (CL:SETF (%N-VECTOR-ARGUMENT-SPECS SELF) -1)
   (CL:SETF (%N-VECTOR-ARGUMENTS SELF) -1) (CL:SETF (%MODEL SELF) NULL)
   (CL:SETF (%PROPOSITION SELF) NULL) SELF))

(CL:DEFMETHOD PRIMARY-TYPE ((SELF TENSORFLOW-NEURAL-NETWORK))
  SGT-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK)

(CL:DEFUN ACCESS-TENSORFLOW-NEURAL-NETWORK-SLOT-VALUE (SELF SLOTNAME VALUE SETVALUE?)
  (CL:COND
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-PROPOSITION)
    (CL:IF SETVALUE? (CL:SETF (%PROPOSITION SELF) VALUE)
     (CL:SETQ VALUE (%PROPOSITION SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-MODEL)
    (CL:IF SETVALUE? (CL:SETF (%MODEL SELF) VALUE)
     (CL:SETQ VALUE (%MODEL SELF))))
   (CL:T
    (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
     (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" SLOTNAME
      "' is not a valid case option")
     (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))
  VALUE)

;;; (DEFUN REGISTER-TENSORFLOW-CALLBACK ...)

(CL:DEFUN REGISTER-TENSORFLOW-CALLBACK (NAME CODE)
  "Special-purpose callback support that registers `code' under the logic symbol with `name',
which by convention we make the qualified method name of the method we are using this for.  This is a
special-purpose hack which eventually we might want to generalize so others can use it too."
  (CL:DECLARE (CL:TYPE CL:SIMPLE-STRING NAME))
  #+MCL
  (CL:CHECK-TYPE NAME CL:SIMPLE-STRING)
  (SYMBOL-VALUE-SETTER
   (INTERN-SYMBOL-IN-MODULE (STRING-UPCASE NAME) *LOGIC-MODULE* CL:NIL)
   (WRAP-FUNCTION-CODE CODE)))

;;; (DEFUN (GET-TENSORFLOW-CALLBACK FUNCTION-CODE) ...)

(CL:DEFUN GET-TENSORFLOW-CALLBACK (NAME)
  "Access the TensorFlow callback code registered under `name'."
  (%WRAPPER-VALUE (%%VALUE (%SYMBOL-VALUE-AND-PLIST NAME))))

;;; (DEFUN (TENSORFLOW-BACKEND-AVAILABLE? BOOLEAN) ...)

(CL:DEFUN TENSORFLOW-BACKEND-AVAILABLE? ()
  "Return TRUE if TensorFlow callbacks have been properly registered."
  (CL:NOT
   (CL:EQ
    (%%VALUE
     (%SYMBOL-VALUE-AND-PLIST
      SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.BUILD-PROPOSITION-NETWORK))
    NULL)))

;;; (DEFMETHOD LINK-NEURAL-NETWORK ...)

(CL:DEFMETHOD LINK-NEURAL-NETWORK ((SELF TENSORFLOW-NEURAL-NETWORK) PROP)
  "Link the network `self' to its associated proposition `prop'."
  (CL:SETF (%PROPOSITION SELF) PROP)
  (SET-DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS PROP)
   SYM-CHAMELEON-LOGIC-NEURAL-NET SELF NULL))

;;; (DEFMETHOD UNLINK-NEURAL-NETWORK ...)

(CL:DEFMETHOD UNLINK-NEURAL-NETWORK ((SELF TENSORFLOW-NEURAL-NETWORK))
  "Unlink the network `self' from its associated proposition."
  (CL:LET* ((PROP (%PROPOSITION SELF)))
   (CL:SETF (%PROPOSITION SELF) NULL)
   (CL:WHEN (CL:NOT (CL:EQ PROP NULL))
    (SET-DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS PROP)
     SYM-CHAMELEON-LOGIC-NEURAL-NET NULL NULL))))

;;; (DEFMETHOD (GET-NEURAL-NETWORK-PROPOSITION PROPOSITION) ...)

(CL:DEFMETHOD GET-NEURAL-NETWORK-PROPOSITION ((SELF TENSORFLOW-NEURAL-NETWORK))
  "Return the proposition linked to `self'."
  (%PROPOSITION SELF))

;;; (DEFMETHOD DELETE-NEURAL-NETWORK ...)

(CL:DEFMETHOD DELETE-NEURAL-NETWORK ((SELF TENSORFLOW-NEURAL-NETWORK))
  "Unlink the network `self' from its associated proposition and mark it as deleted."
  (UNLINK-NEURAL-NETWORK SELF)
  (CL:SETF (%MODEL SELF) (WRAP-LONG-INTEGER MOST-NEGATIVE-LONG-INTEGER)))

;;; (DEFMETHOD (DELETED? BOOLEAN) ...)

(CL:DEFMETHOD DELETED? ((SELF TENSORFLOW-NEURAL-NETWORK))
  "Return trun if `self' has been deleted."
  (EQL-TO-LONG-INTEGER? (%MODEL SELF) MOST-NEGATIVE-LONG-INTEGER))

;;; (DEFMETHOD ALLOCATE-NETWORK-ARRAYS ...)

(CL:DEFMETHOD ALLOCATE-NETWORK-ARRAYS ((SELF TENSORFLOW-NEURAL-NETWORK) NUM-IN NUM-HIDDEN NUM-OUT)
  "Allocates array space for a neural network with given number of input, hidden and output units."
  (CL:DECLARE (CL:TYPE CL:FIXNUM NUM-IN NUM-HIDDEN NUM-OUT))
  #+MCL
  (CL:CHECK-TYPE NUM-IN CL:FIXNUM)
  #+MCL
  (CL:CHECK-TYPE NUM-HIDDEN CL:FIXNUM)
  #+MCL
  (CL:CHECK-TYPE NUM-OUT CL:FIXNUM)
  (CL:FUNCALL
   (%WRAPPER-VALUE
    (%%VALUE
     (%SYMBOL-VALUE-AND-PLIST
      SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.ALLOCATE-NETWORK-ARRAYS)))
   SELF NUM-IN NUM-HIDDEN NUM-OUT))

;;; (DEFMETHOD RANDOMIZE-NETWORK-WEIGHTS ...)

(CL:DEFMETHOD RANDOMIZE-NETWORK-WEIGHTS ((SELF TENSORFLOW-NEURAL-NETWORK))
  "Randomize the weights of the neural network `self'."
  (CL:FUNCALL
   (%WRAPPER-VALUE
    (%%VALUE
     (%SYMBOL-VALUE-AND-PLIST
      SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.RANDOMIZE-NETWORK-WEIGHTS)))
   SELF))

;;; (DEFMETHOD INITIALIZE-NETWORK-WEIGHTS ...)

(CL:DEFMETHOD INITIALIZE-NETWORK-WEIGHTS ((SELF TENSORFLOW-NEURAL-NETWORK))
  "Initialize the weights of the neural network `self' - eiher randomly or from a saved state."
  (CL:FUNCALL
   (%WRAPPER-VALUE
    (%%VALUE
     (%SYMBOL-VALUE-AND-PLIST
      SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.INITIALIZE-NETWORK-WEIGHTS)))
   SELF))

;;; (DEFMETHOD BUILD-PROPOSITION-NETWORK ...)

(CL:DEFMETHOD BUILD-PROPOSITION-NETWORK ((SELF TENSORFLOW-NEURAL-NETWORK) PROP)
  "Build a neural network for the proposition `prop'.  This builds a two-layer
perceptron network whose input nodes are activated by the truth of `prop's arguments and whose
output node computes the truth of `prop'."
  (CL:FUNCALL
   (%WRAPPER-VALUE
    (%%VALUE
     (%SYMBOL-VALUE-AND-PLIST
      SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.BUILD-PROPOSITION-NETWORK)))
   SELF PROP)
  (LINK-NEURAL-NETWORK SELF PROP))

;;; (DEFMETHOD (NUMBER-OF-INPUTS INTEGER) ...)

(CL:DEFMETHOD NUMBER-OF-INPUTS ((SELF TENSORFLOW-NEURAL-NETWORK))
  "Return the number of input values expected by `self' (ignores bias unit)."
  (CL:FUNCALL
   (%WRAPPER-VALUE
    (%%VALUE
     (%SYMBOL-VALUE-AND-PLIST
      SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.NUMBER-OF-INPUTS)))
   SELF))

;;; (DEFMETHOD (NTH-INPUT FLOAT) ...)

(CL:DEFMETHOD NTH-INPUT ((SELF TENSORFLOW-NEURAL-NETWORK) N)
  "Return the 0-based `n'-th proposition input of `self' (ignores bias unit)."
  (CL:DECLARE (CL:TYPE CL:FIXNUM N))
  #+MCL
  (CL:CHECK-TYPE N CL:FIXNUM)
  (CL:FUNCALL
   (%WRAPPER-VALUE
    (%%VALUE
     (%SYMBOL-VALUE-AND-PLIST
      SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.NTH-INPUT)))
   SELF N))

;;; (DEFMETHOD (NTH-INPUT-ERROR FLOAT) ...)

(CL:DEFMETHOD NTH-INPUT-ERROR ((SELF TENSORFLOW-NEURAL-NETWORK) N)
  "Return the 0-based `n'-th proposition input error of `self' (ignores bias unit)."
  (CL:DECLARE (CL:TYPE CL:FIXNUM N))
  #+MCL
  (CL:CHECK-TYPE N CL:FIXNUM)
  (CL:FUNCALL
   (%WRAPPER-VALUE
    (%%VALUE
     (%SYMBOL-VALUE-AND-PLIST
      SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.NTH-INPUT-ERROR)))
   SELF N))

;;; (DEFMETHOD SET-INPUT-VALUES ...)

(CL:DEFMETHOD SET-INPUT-VALUES ((SELF TENSORFLOW-NEURAL-NETWORK) VALUES)
  "Set the current truth-value inputs of the network `self' to float `values' in sequence.
Missing inputs will be set to 0.0, extra values will be ignored."
  (CL:FUNCALL
   (%WRAPPER-VALUE
    (%%VALUE
     (%SYMBOL-VALUE-AND-PLIST
      SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.SET-INPUT-VALUES)))
   SELF (CONSIFY VALUES)))

;;; (DEFMETHOD (GET-VECTOR-ARGUMENT-SPEC OBJECT) ...)

(CL:DEFMETHOD GET-VECTOR-ARGUMENT-SPEC ((SELF TENSORFLOW-NEURAL-NETWORK) ARG)
  "Generate a single argument spec for `arg' that can be used for `set-vector-input-values'.
`arg' can either be a proposition or justification."
  (CL:LET* ((SPEC (CL:CALL-NEXT-METHOD SELF ARG)) (EVALARGS NIL))
   (CL:COND
    ((CL:EQ (SAFE-PRIMARY-TYPE SPEC) SGT-CHAMELEON-STELLA-CONS)
     (CL:PROGN
      (CL:LET* ((ELT NULL) (ITER-000 SPEC) (COLLECT-000 NULL))
       (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-000 NIL)) DO
        (CL:SETQ ELT (%%VALUE ITER-000))
        (CL:WHEN (CL:OR (LONG-INTEGER? ELT) (STRING? ELT))
         (CL:IF (CL:EQ COLLECT-000 NULL)
          (CL:PROGN (CL:SETQ COLLECT-000 (CONS ELT NIL))
           (CL:IF (CL:EQ EVALARGS NIL) (CL:SETQ EVALARGS COLLECT-000)
            (ADD-CONS-TO-END-OF-CONS-LIST EVALARGS COLLECT-000)))
          (CL:PROGN (CL:SETF (%%REST COLLECT-000) (CONS ELT NIL))
           (CL:SETQ COLLECT-000 (%%REST COLLECT-000)))))
        (CL:SETQ ITER-000 (%%REST ITER-000))))))
    (CL:T))
   (CL:IF (CL:NOT (CL:EQ EVALARGS NIL)) EVALARGS SPEC)))

;;; (DEFMETHOD SET-VECTOR-INPUT-VALUES ...)

(CL:DEFMETHOD SET-VECTOR-INPUT-VALUES ((SELF TENSORFLOW-NEURAL-NETWORK) VECTORSPECS)
  "Set the current vector inputs of the network `self' to the vectors described by `vectorSpecs'.
Each vector spec describes a vector-generating proposition that produces one or more vectors.  How those specs
are translated into actual numeric vectors such as embeddings is specific to the particular neural network type."
  (CL:FUNCALL
   (%WRAPPER-VALUE
    (%%VALUE
     (%SYMBOL-VALUE-AND-PLIST
      SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.SET-VECTOR-INPUT-VALUES)))
   SELF (CONSIFY VECTORSPECS)))

;;; (DEFMETHOD (FORWARD-PROPAGATE-INPUTS FLOAT) ...)

(CL:DEFMETHOD FORWARD-PROPAGATE-INPUTS ((SELF TENSORFLOW-NEURAL-NETWORK))
  "Activates the current inputs of the network `self' to compute its output.
Sets `self's `output' slot and returns the computed value.  Reads input activations and
weights and updates hidden and output activations."
  (CL:FUNCALL
   (%WRAPPER-VALUE
    (%%VALUE
     (%SYMBOL-VALUE-AND-PLIST
      SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.FORWARD-PROPAGATE-INPUTS)))
   SELF))

;;; (DEFMETHOD BACKWARD-PROPAGATE-ERROR ...)

(CL:DEFMETHOD BACKWARD-PROPAGATE-ERROR ((SELF TENSORFLOW-NEURAL-NETWORK) ERROR)
  "Given a properly forward activated network `self' for the current set of inputs,
and a training `error' between the current output and the goal value, backpropagate the error and
update `self's vector of input errors.  Reads output, hidden activations and weights and updates
hidden errors and input errors."
  (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT ERROR))
  #+MCL
  (CL:CHECK-TYPE ERROR CL:DOUBLE-FLOAT)
  (CL:FUNCALL
   (%WRAPPER-VALUE
    (%%VALUE
     (%SYMBOL-VALUE-AND-PLIST
      SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.BACKWARD-PROPAGATE-ERROR)))
   SELF ERROR))

;;; (DEFMETHOD UPDATE-NETWORK-WEIGHTS ...)

(CL:DEFMETHOD UPDATE-NETWORK-WEIGHTS ((SELF TENSORFLOW-NEURAL-NETWORK) ERROR)
  "Given a properly forward activated and backpropagated network `self' for the current
inputs and training `error', update the network's weights according to current gradients, learning rate
and momentum terms to reduce the error for the given inputs.  Reads output, hidden and input activations,
hidden error, weights and weight deltas, and updates weights and weight deltas."
  (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT ERROR))
  #+MCL
  (CL:CHECK-TYPE ERROR CL:DOUBLE-FLOAT)
  (CL:FUNCALL
   (%WRAPPER-VALUE
    (%%VALUE
     (%SYMBOL-VALUE-AND-PLIST
      SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.UPDATE-NETWORK-WEIGHTS)))
   SELF ERROR))

;;; (DEFUN (GET-CACHED-NETWORK-PROOF JUSTIFICATION) ...)

(CL:DEFUN GET-CACHED-NETWORK-PROOF (EXAMPLE)
  "Variant of `create-cached-network' that takes a training `example',
runs its cons query, and stores a compacted version of the associated proof tree
as the `example's cached solution which will also be returned.  If a cached and
up-to-date solution already exists, it will be returned instead."
  (CL:COND
   ((CL:AND (CL:NOT (CL:EQ (%CACHED-SOLUTION EXAMPLE) NULL))
     (CL:= (%TIMESTAMP EXAMPLE) (GET-NOW-TIMESTAMP)))
    (%CACHED-SOLUTION EXAMPLE))
   (CL:T
    (CL:LET* ((TEMP-000 (%MODULE EXAMPLE)))
     (CL:LET*
      ((MODULE
        (CL:IF (CL:NOT (CL:EQ TEMP-000 NULL)) TEMP-000 *MODULE*)))
      (CL:LET* ((*MODULE* MODULE) (*CONTEXT* *MODULE*))
       (CL:DECLARE (CL:SPECIAL *MODULE* *CONTEXT*))
       (CL:LET*
        ((QUERYITER
          (CREATE-ASK-QUERY
           (CONS-LIST (%QUERY EXAMPLE)
            KWD-CHAMELEON-RECORD-JUSTIFICATIONS? TRUE-WRAPPER
            KWD-CHAMELEON-MATCH-MODE KWD-CHAMELEON-CHAMELEON))))
        (CALL-ASK-PARTIAL QUERYITER)
        (CL:SETF (%CACHED-SOLUTION EXAMPLE)
         (DYNAMIC-SLOT-VALUE
          (%DYNAMIC-SLOTS (%BASE-CONTROL-FRAME QUERYITER))
          SYM-CHAMELEON-LOGIC-JUSTIFICATION NULL))
        (CL:WHEN (CL:EQ (%CACHED-SOLUTION EXAMPLE) NULL)
         (CL:LET* ((*PRINTREADABLY?* CL:T))
          (CL:DECLARE (CL:SPECIAL *PRINTREADABLY?*))
          (%%PRINT-STREAM (%NATIVE-STREAM STANDARD-WARNING)
           "WARNING: get-cached-network-proof: training example query failed: "
           (%QUERY EXAMPLE) EOL)
          (HELP-SIGNAL-PROPOSITION-ERROR STANDARD-WARNING
           KWD-CHAMELEON-WARNING))
         (RECORD-FAIL-JUSTIFICATION (%BASE-CONTROL-FRAME QUERYITER)
          KWD-CHAMELEON-UP-FAIL)
         (CL:SETF (%CACHED-SOLUTION EXAMPLE)
          (DYNAMIC-SLOT-VALUE
           (%DYNAMIC-SLOTS (%BASE-CONTROL-FRAME QUERYITER))
           SYM-CHAMELEON-LOGIC-JUSTIFICATION NULL)))
        (CL:SETF (%CACHED-SOLUTION EXAMPLE)
         (COMPACT-PARTIAL-PROOF-TO-NETWORK-PROOF
          (%CACHED-SOLUTION EXAMPLE)))
        (CL:SETF (%TIMESTAMP EXAMPLE) (GET-NOW-TIMESTAMP))
        (%CACHED-SOLUTION EXAMPLE))))))))

;;; (DEFUN (COMPACT-PARTIAL-PROOF-TO-NETWORK-PROOF JUSTIFICATION) ...)

(CL:DEFUN COMPACT-PARTIAL-PROOF-TO-NETWORK-PROOF (PROOF)
  "Convert `proof' into a compacted network tree form that only contains
:AND, :OR, :MULTI and :PRIMITIVE nodes (some of which such as `instance-of' might contain
further antecedents if they were computed by specialists, for example)."
  (CL:LET* ((TEST-VALUE-000 (%INFERENCE-RULE PROOF)))
   (CL:COND
    ((CL:EQ TEST-VALUE-000 KWD-CHAMELEON-PRIMITIVE-STRATEGY)
     (CL:COND
      ((CL:EQ (%STRATEGY PROOF) KWD-CHAMELEON-GOAL-COMPLEMENT)
       (CL:SETQ PROOF (SHALLOW-COPY PROOF))
       (CL:SETF (%INFERENCE-RULE PROOF) KWD-CHAMELEON-GOAL-COMPLEMENT)
       (COMPACT-PARTIAL-PROOF-TO-NETWORK-PROOF PROOF))
      ((CL:EQ (%ANTECEDENTS PROOF) NIL) PROOF)
      (CL:T
       (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
        (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
         "INTERNAL ERROR: unexpected primitive justifications with antecedents for: `"
         (%PROPOSITION PROOF) "'")
        (CL:ERROR
         (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))))
    ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-AND-INTRODUCTION)
      (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-OR-INTRODUCTION)
      (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-MULTIPLE-PROOFS)
      (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-DISPROOF)
      (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-GOAL-COMPLEMENT))
     (CL:SETQ PROOF (SHALLOW-COPY PROOF))
     (CL:LET* ((VALUE-000 NIL))
      (CL:LET*
       ((ANT NULL) (ITER-000 (%ANTECEDENTS PROOF)) (COLLECT-000 NULL))
       (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-000 NIL)) DO
        (CL:SETQ ANT (%%VALUE ITER-000))
        (CL:IF (CL:EQ COLLECT-000 NULL)
         (CL:PROGN
          (CL:SETQ COLLECT-000
           (CONS (COMPACT-PARTIAL-PROOF-TO-NETWORK-PROOF ANT) NIL))
          (CL:IF (CL:EQ VALUE-000 NIL) (CL:SETQ VALUE-000 COLLECT-000)
           (ADD-CONS-TO-END-OF-CONS-LIST VALUE-000 COLLECT-000)))
         (CL:PROGN
          (CL:SETF (%%REST COLLECT-000)
           (CONS (COMPACT-PARTIAL-PROOF-TO-NETWORK-PROOF ANT) NIL))
          (CL:SETQ COLLECT-000 (%%REST COLLECT-000))))
        (CL:SETQ ITER-000 (%%REST ITER-000))))
      (CL:SETF (%ANTECEDENTS PROOF) VALUE-000))
     PROOF)
    ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-MODUS-PONENS)
      (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-MODUS-TOLLENS))
     (CL:LET*
      ((RELATION (%SURROGATE-VALUE (%OPERATOR (%PROPOSITION PROOF)))))
      (CL:COND
       ((CL:AND (CL:NOT (CL:EQ RELATION NULL))
         (CL:OR
          (TEST-PROPERTY? RELATION
           SGT-CHAMELEON-CHAMELEON-TRUTH-VALUE-RELATION)
          (CL:NOT
           (CL:OR
            (TEST-PROPERTY? RELATION
             SGT-CHAMELEON-CHAMELEON-IGNORED-VALUE-RELATION)
            (CL:AND
             (TEST-PROPERTY? RELATION
              SGT-CHAMELEON-CHAMELEON-VECTOR-RELATION)
             (CL:NOT
              (TEST-PROPERTY? RELATION
               SGT-CHAMELEON-CHAMELEON-TRUTH-VALUE-RELATION)))))))
        (CL:SETQ PROOF (SHALLOW-COPY PROOF))
        (CL:SETF (%INFERENCE-RULE PROOF) KWD-CHAMELEON-MULTIPLE-PROOFS)
        (CL:SETF (%ANTECEDENTS PROOF)
         (CONS
          (COMPACT-PARTIAL-PROOF-TO-NETWORK-PROOF
           (%%VALUE (%%REST (%ANTECEDENTS PROOF))))
          NIL))
        PROOF)
       (CL:T (CL:SETQ PROOF (SHALLOW-COPY PROOF))
        (CL:SETF (%INFERENCE-RULE PROOF)
         KWD-CHAMELEON-PRIMITIVE-STRATEGY)
        (CL:SETF (%ANTECEDENTS PROOF) NIL) PROOF))))
    ((CL:EQ TEST-VALUE-000 KWD-CHAMELEON-SUBSUMPTION-REASONING)
     (CL:SETQ PROOF (SHALLOW-COPY PROOF))
     (CL:SETF (%INFERENCE-RULE PROOF) KWD-CHAMELEON-PRIMITIVE-STRATEGY)
     (CL:SETF (%ANTECEDENTS PROOF) NIL) PROOF)
    ((CL:EQ TEST-VALUE-000 KWD-CHAMELEON-FAIL-INTRODUCTION)
     (CL:SETQ PROOF (SHALLOW-COPY PROOF))
     (CL:SETF (%INFERENCE-RULE PROOF) KWD-CHAMELEON-PRIMITIVE-STRATEGY)
     (CL:SETF (%ANTECEDENTS PROOF) NIL) PROOF)
    (CL:T
     (CL:LET*
      ((RELATION (%SURROGATE-VALUE (%OPERATOR (%PROPOSITION PROOF)))))
      (CL:COND
       ((CL:AND (CL:NOT (CL:EQ RELATION NULL))
         (TEST-PROPERTY? RELATION
          SGT-CHAMELEON-CHAMELEON-PRIMITIVE-VALUE-RELATION))
        (CL:SETQ PROOF (SHALLOW-COPY PROOF))
        (CL:SETF (%INFERENCE-RULE PROOF)
         KWD-CHAMELEON-PRIMITIVE-STRATEGY)
        (CL:SETF (%ANTECEDENTS PROOF) NIL) PROOF)
       (CL:T
        (CL:CASE (LENGTH (%ANTECEDENTS PROOF)) (0 PROOF)
         (1
          (COMPACT-PARTIAL-PROOF-TO-NETWORK-PROOF
           (%%VALUE (%ANTECEDENTS PROOF))))
         (CL:OTHERWISE
          (CL:LET* ((STREAM-001 (NEW-OUTPUT-STRING-STREAM)))
           (%%PRINT-STREAM (%NATIVE-STREAM STREAM-001)
            "Unhandled network proof justification with multiple antecedents: `"
            (%INFERENCE-RULE PROOF) "'")
           (CL:ERROR
            (NEW-STELLA-EXCEPTION
             (THE-STRING-READER STREAM-001)))))))))))))

;;; (DEFUN (COMBINE-MULTIPLE-MATCH-SCORES FLOAT) ...)

(CL:DECLAIM
 (CL:FTYPE (CL:FUNCTION (CL:T) CL:DOUBLE-FLOAT)
  COMBINE-MULTIPLE-MATCH-SCORES))
(CL:DEFUN COMBINE-MULTIPLE-MATCH-SCORES (SCORES)
  "Combine partial match scores from alternative :multiple-proofs `scores'
according to the current `*rule-combination*' strategy."
  (CL:COND
   ((CL:EQ *RULE-COMBINATION* KWD-CHAMELEON-MAX)
    (CL:LET* ((MAX 0.0d0)) (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT MAX))
     (CL:LET* ((SCORE NULL) (ITER-000 SCORES))
      (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-000 NIL)) DO
       (CL:SETQ SCORE (%%VALUE ITER-000))
       (CL:WHEN (CL:> (%WRAPPER-VALUE SCORE) MAX)
        (CL:SETQ MAX (%WRAPPER-VALUE SCORE)))
       (CL:SETQ ITER-000 (%%REST ITER-000))))
     MAX))
   ((CL:EQ *RULE-COMBINATION* KWD-CHAMELEON-NOISY-OR)
    (CL:CASE (LENGTH SCORES) (0 0.0d0)
     (1 (%WRAPPER-VALUE (%%VALUE SCORES)))
     (2
      (PROBABILISTIC-SUM (%WRAPPER-VALUE (%%VALUE SCORES))
       (%WRAPPER-VALUE (%%VALUE (%%REST SCORES)))))
     (CL:OTHERWISE (PROBABILISTIC-SUM-N SCORES))))
   (CL:T
    (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
     (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" *RULE-COMBINATION*
      "' is not a valid case option")
     (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))))

;;; (DEFUN (FORWARD-PROPAGATE-CACHED-NETWORK-PROOF FLOAT) ...)

(CL:DECLAIM
 (CL:FTYPE (CL:FUNCTION (CL:T) CL:DOUBLE-FLOAT)
  FORWARD-PROPAGATE-CACHED-NETWORK-PROOF))
(CL:DEFUN FORWARD-PROPAGATE-CACHED-NETWORK-PROOF (PROOF)
  "Compute the same partial match score as the call to `compute-partial-truth'
that generated `proof' (which is assumed to have been compacted with a call to
`compact-partial-proof-to-network-proof'.  The score will only be identical of course, if
the various networks and their weights have not yet been updated during learning."
  (CL:LET* ((SCORE 0.0d0)) (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT SCORE))
   (CL:LET* ((TEST-VALUE-000 (%INFERENCE-RULE PROOF)))
    (CL:COND
     ((CL:EQ TEST-VALUE-000 KWD-CHAMELEON-PRIMITIVE-STRATEGY)
      (%MATCH-SCORE PROOF))
     ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-AND-INTRODUCTION)
       (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-OR-INTRODUCTION))
      (CL:LET*
       ((NET (GET-JUSTIFICATION-NEURAL-NETWORK PROOF))
        (INPUTS (NEW-VECTOR (NUMBER-OF-INPUTS NET)))
        (VECTORARGS
         (CL:IF (HAS-VECTOR-ARGUMENTS? NET)
          (NEW-VECTOR (NUMBER-OF-VECTOR-ARGUMENTS NET NULL)) NULL))
        (INDEX -1))
       (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX))
       (CL:LET* ((ANT NULL) (ITER-000 (%ANTECEDENTS PROOF)))
        (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-000 NIL)) DO
         (CL:SETQ ANT (%%VALUE ITER-000))
         (CL:SETQ INDEX
          (TRUTH-VALUE-ARGUMENT-INDEX NET (%PROPOSITION ANT)))
         (CL:WHEN (CL:>= INDEX 0)
          (CL:SETQ SCORE (FORWARD-PROPAGATE-CACHED-NETWORK-PROOF ANT))
          (CL:LET
           ((SELF (%THE-ARRAY INPUTS)) (VALUE (WRAP-FLOAT SCORE))
            (POSITION INDEX))
           (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
            (CL:TYPE CL:FIXNUM POSITION))
           (CL:SETF (CL:AREF SELF POSITION) VALUE)))
         (CL:WHEN (CL:NOT (CL:EQ VECTORARGS NULL))
          (CL:SETQ INDEX
           (VECTOR-ARGUMENT-INDEX NET (%PROPOSITION ANT)))
          (CL:WHEN (CL:>= INDEX 0)
           (CL:LET
            ((SELF (%THE-ARRAY VECTORARGS))
             (VALUE (GET-VECTOR-ARGUMENT-SPEC NET ANT))
             (POSITION INDEX))
            (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
             (CL:TYPE CL:FIXNUM POSITION))
            (CL:SETF (CL:AREF SELF POSITION) VALUE))))
         (CL:SETQ ITER-000 (%%REST ITER-000))))
       (SET-INPUT-VALUES NET INPUTS)
       (CL:WHEN (CL:NOT (CL:EQ VECTORARGS NULL))
        (SET-VECTOR-INPUT-VALUES NET VECTORARGS))
       (CL:SETQ SCORE (FORWARD-PROPAGATE-INPUTS NET))
       (CL:SETF (%MATCH-SCORE PROOF) SCORE) SCORE))
     ((CL:EQ TEST-VALUE-000 KWD-CHAMELEON-MULTIPLE-PROOFS)
      (CL:LET* ((VALUE-000 NIL))
       (CL:LET*
        ((ANT NULL) (ITER-001 (%ANTECEDENTS PROOF)) (COLLECT-000 NULL))
        (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-001 NIL)) DO
         (CL:SETQ ANT (%%VALUE ITER-001))
         (CL:IF (CL:EQ COLLECT-000 NULL)
          (CL:PROGN
           (CL:SETQ COLLECT-000
            (CONS
             (WRAP-FLOAT (FORWARD-PROPAGATE-CACHED-NETWORK-PROOF ANT))
             NIL))
           (CL:IF (CL:EQ VALUE-000 NIL) (CL:SETQ VALUE-000 COLLECT-000)
            (ADD-CONS-TO-END-OF-CONS-LIST VALUE-000 COLLECT-000)))
          (CL:PROGN
           (CL:SETF (%%REST COLLECT-000)
            (CONS
             (WRAP-FLOAT (FORWARD-PROPAGATE-CACHED-NETWORK-PROOF ANT))
             NIL))
           (CL:SETQ COLLECT-000 (%%REST COLLECT-000))))
         (CL:SETQ ITER-001 (%%REST ITER-001))))
       (CL:SETQ SCORE (COMBINE-MULTIPLE-MATCH-SCORES VALUE-000)))
      (CL:SETF (%MATCH-SCORE PROOF) SCORE) SCORE)
     ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-DISPROOF)
       (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-GOAL-COMPLEMENT))
      (CL:SETQ SCORE
       (INVERT-CHAMELEON-MATCH-SCORE
        (%MATCH-SCORE (%%VALUE (%ANTECEDENTS PROOF)))))
      (CL:SETF (%MATCH-SCORE PROOF) SCORE) SCORE)
     (CL:T
      (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
       (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" TEST-VALUE-000
        "' is not a valid case option")
       (CL:ERROR
        (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))))))

;;; (DEFUN (FORWARD-PROPAGATE-CACHED-NETWORK-FROM-JUSTIFICATION FLOAT) ...)

(CL:DECLAIM
 (CL:FTYPE (CL:FUNCTION (CL:T) CL:DOUBLE-FLOAT)
  FORWARD-PROPAGATE-CACHED-NETWORK-FROM-JUSTIFICATION))
(CL:DEFUN FORWARD-PROPAGATE-CACHED-NETWORK-FROM-JUSTIFICATION (JUST)
  "Locally forward-propagate the network associated with `just' based on
previously cached `positive-score's of antecedents."
  (CL:LET* ((SCORE 0.0d0)) (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT SCORE))
   (CL:LET* ((TEST-VALUE-000 (%INFERENCE-RULE JUST)))
    (CL:COND
     ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-AND-INTRODUCTION)
       (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-OR-INTRODUCTION))
      (CL:LET*
       ((NET (GET-JUSTIFICATION-NEURAL-NETWORK JUST))
        (INPUTS (NEW-VECTOR (NUMBER-OF-INPUTS NET)))
        (VECTORARGS
         (CL:IF (HAS-VECTOR-ARGUMENTS? NET)
          (NEW-VECTOR (NUMBER-OF-VECTOR-ARGUMENTS NET NULL)) NULL))
        (INDEX -1))
       (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX))
       (CL:LET* ((ANT NULL) (ITER-000 (%ANTECEDENTS JUST)))
        (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-000 NIL)) DO
         (CL:SETQ ANT (%%VALUE ITER-000))
         (CL:SETQ INDEX
          (TRUTH-VALUE-ARGUMENT-INDEX NET (%PROPOSITION ANT)))
         (CL:WHEN (CL:>= INDEX 0) (CL:SETQ SCORE (%MATCH-SCORE ANT))
          (CL:LET
           ((SELF (%THE-ARRAY INPUTS)) (VALUE (WRAP-FLOAT SCORE))
            (POSITION INDEX))
           (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
            (CL:TYPE CL:FIXNUM POSITION))
           (CL:SETF (CL:AREF SELF POSITION) VALUE)))
         (CL:WHEN (CL:NOT (CL:EQ VECTORARGS NULL))
          (CL:SETQ INDEX
           (VECTOR-ARGUMENT-INDEX NET (%PROPOSITION ANT)))
          (CL:WHEN (CL:>= INDEX 0)
           (CL:LET
            ((SELF (%THE-ARRAY VECTORARGS))
             (VALUE (GET-VECTOR-ARGUMENT-SPEC NET ANT))
             (POSITION INDEX))
            (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
             (CL:TYPE CL:FIXNUM POSITION))
            (CL:SETF (CL:AREF SELF POSITION) VALUE))))
         (CL:SETQ ITER-000 (%%REST ITER-000))))
       (SET-INPUT-VALUES NET INPUTS)
       (CL:WHEN (CL:NOT (CL:EQ VECTORARGS NULL))
        (SET-VECTOR-INPUT-VALUES NET VECTORARGS))
       (CL:SETQ SCORE (FORWARD-PROPAGATE-INPUTS NET)) SCORE))
     (CL:T
      (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
       (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" TEST-VALUE-000
        "' is not a valid case option")
       (CL:ERROR
        (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))))))

;;; (DEFUN BACKWARD-PROPAGATE-CACHED-NETWORK-PROOF ...)

(CL:DEFUN BACKWARD-PROPAGATE-CACHED-NETWORK-PROOF (PROOF ERROR)
  "Propagate the `error' between `proof's conclusion and the desired target value
through `proof's network and its antecedents, and adjust weights to decrease the error.  Multiple
iterations through `forward/backward-propagate-cached-network-proof' with updated top-level
errors will train the involved networks to minimize the error as much as possible."
  (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT ERROR))
  #+MCL
  (CL:CHECK-TYPE ERROR CL:DOUBLE-FLOAT)
  (CL:LET* ((TEST-VALUE-000 (%INFERENCE-RULE PROOF)))
   (CL:COND
    ((CL:EQ TEST-VALUE-000 KWD-CHAMELEON-MULTIPLE-PROOFS)
     (BACKWARD-PROPAGATE-CACHED-NETWORK-MULTI-PROOF PROOF ERROR))
    ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-DISPROOF)
      (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-GOAL-COMPLEMENT))
     (BACKWARD-PROPAGATE-CACHED-NETWORK-PROOF
      (%%VALUE (%ANTECEDENTS PROOF)) ERROR))
    ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-AND-INTRODUCTION)
      (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-OR-INTRODUCTION))
     (CL:LET*
      ((NET (GET-JUSTIFICATION-NEURAL-NETWORK PROOF))
       (REACTIVATE? CL:NIL))
      (FORWARD-PROPAGATE-CACHED-NETWORK-FROM-JUSTIFICATION PROOF)
      (BACKWARD-PROPAGATE-ERROR NET ERROR)
      (CL:LET* ((ANT NULL) (ITER-000 (%ANTECEDENTS PROOF)))
       (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-000 NIL)) DO
        (CL:SETQ ANT (%%VALUE ITER-000))
        (CL:WHEN
         (CL:NOT
          (CL:EQ (%INFERENCE-RULE ANT)
           KWD-CHAMELEON-PRIMITIVE-STRATEGY))
         (CL:LET*
          ((INDEX (TRUTH-VALUE-ARGUMENT-INDEX NET (%PROPOSITION ANT))))
          (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX))
          (CL:WHEN (CL:>= INDEX 0)
           (BACKWARD-PROPAGATE-CACHED-NETWORK-PROOF ANT
            (NTH-INPUT-ERROR NET INDEX))
           (CL:SETQ REACTIVATE? CL:T))))
        (CL:SETQ ITER-000 (%%REST ITER-000))))
      (CL:WHEN REACTIVATE?
       (FORWARD-PROPAGATE-CACHED-NETWORK-FROM-JUSTIFICATION PROOF)
       (BACKWARD-PROPAGATE-ERROR NET ERROR))
      (UPDATE-NETWORK-WEIGHTS NET ERROR)))
    ((CL:EQ TEST-VALUE-000 KWD-CHAMELEON-PRIMITIVE-STRATEGY))
    (CL:T
     (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
      (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" TEST-VALUE-000
       "' is not a valid case option")
      (CL:ERROR
       (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))))

;;; (DEFUN BACKWARD-PROPAGATE-CACHED-NETWORK-MULTI-PROOF ...)

(CL:DEFUN BACKWARD-PROPAGATE-CACHED-NETWORK-MULTI-PROOF (PROOF ERROR)
  "Recurse through :multiple-proofs antecedents guided by the current rule combination scheme."
  (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT ERROR))
  #+MCL
  (CL:CHECK-TYPE ERROR CL:DOUBLE-FLOAT)
  (CL:COND
   ((CL:EQ *RULE-COMBINATION* KWD-CHAMELEON-MAX)
    (CL:LET* ((MAX MOST-NEGATIVE-FLOAT))
     (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT MAX))
     (CL:LET* ((ANT NULL) (ITER-000 (%ANTECEDENTS PROOF)))
      (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-000 NIL)) DO
       (CL:SETQ ANT (%%VALUE ITER-000))
       (CL:WHEN (CL:> (%MATCH-SCORE ANT) MAX)
        (CL:SETQ MAX (%MATCH-SCORE ANT)) (CL:SETQ PROOF ANT))
       (CL:SETQ ITER-000 (%%REST ITER-000))))
     (BACKWARD-PROPAGATE-CACHED-NETWORK-PROOF PROOF ERROR)))
   ((CL:EQ *RULE-COMBINATION* KWD-CHAMELEON-NOISY-OR)
    (CL:LET* ((ANT NULL) (ITER-001 (%ANTECEDENTS PROOF)))
     (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-001 NIL)) DO
      (CL:SETQ ANT (%%VALUE ITER-001))
      (BACKWARD-PROPAGATE-CACHED-NETWORK-PROOF ANT
       (CL:* ERROR (%MATCH-SCORE ANT)))
      (CL:SETQ ITER-001 (%%REST ITER-001)))))
   (CL:T
    (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
     (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" *RULE-COMBINATION*
      "' is not a valid case option")
     (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))))

;;; (DEFMETHOD CLEAR-BATCH-ARRAYS ...)

(CL:DEFMETHOD CLEAR-BATCH-ARRAYS ((SELF NEURAL-NETWORK))
  "Clear all currently batched inputs (with keys) and associated target values."
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "clear-batch-arrays: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD (CURRENT-BATCH-SIZE INTEGER) ...)

(CL:DEFMETHOD CURRENT-BATCH-SIZE ((SELF NEURAL-NETWORK))
  "Return the number of currently batched inputs."
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "current-batch-size: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD (BATCH-IS-FULL? BOOLEAN) ...)

(CL:DEFMETHOD BATCH-IS-FULL? ((SELF NEURAL-NETWORK))
  "Return true if input batch arrays have been filled to capacity."
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "batch-is-full?: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD PUSH-INPUT-VALUES ...)

(CL:DEFMETHOD PUSH-INPUT-VALUES ((SELF NEURAL-NETWORK) KEY VALUES)
  "Push input `values' onto the input batch array and associate them with `key' (which can be NULL).
Associating a key lets us easily map inputs/outputs to some processing object of interest (e.g., a justification)."
  (CL:PROGN (CL:SETQ KEY KEY) (CL:SETQ VALUES VALUES))
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "push-input-values: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD PUSH-VECTOR-INPUT-VALUES ...)

(CL:DEFMETHOD PUSH-VECTOR-INPUT-VALUES ((SELF NEURAL-NETWORK) VECTORSPECS)
  "Push `vectorSpecs' onto the vector argument batch array which is assumed to correspond to the input
values at the same respective position in the batch.  Truth-valued and vector-valued inputs are associated by position
in the batch, they can be pushed independently, as long as they are fully synchronized when processing of the batch starts.
If `self' has no vector-valued argument, the associated batch array can be left undefined."
  (CL:SETQ VECTORSPECS VECTORSPECS)
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "push-vector-input-values: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD PUSH-TARGET-VALUE ...)

(CL:DEFMETHOD PUSH-TARGET-VALUE ((SELF NEURAL-NETWORK) VALUE)
  "Push a target `value' onto the target batch array which is assumed to correspond to the input
values at the same respective position in the batch.  Inputs and targets are associated by position in the batch,
they can be pushed independently, as long as they are fully synchronized when processing of the batch starts."
  (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT VALUE))
  #+MCL
  (CL:CHECK-TYPE VALUE CL:DOUBLE-FLOAT)
  (CL:SETQ VALUE VALUE)
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "push-target-value: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD (NTH-BATCH-KEY OBJECT) ...)

(CL:DEFMETHOD NTH-BATCH-KEY ((SELF NEURAL-NETWORK) N)
  "Return the key associated with the `n'-th set of inputs in the input batch."
  (CL:DECLARE (CL:TYPE CL:FIXNUM N))
  #+MCL
  (CL:CHECK-TYPE N CL:FIXNUM)
  (CL:SETQ N N)
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "nth-batch-key: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD (NTH-KTH-BATCH-INPUT-ERROR FLOAT) ...)

(CL:DEFMETHOD NTH-KTH-BATCH-INPUT-ERROR ((SELF NEURAL-NETWORK) N K)
  "Return error of the `k'-th input in the `n'-th set of inputs in the input batch.
`k' ignores the bias unit."
  (CL:DECLARE (CL:TYPE CL:FIXNUM N K))
  #+MCL
  (CL:CHECK-TYPE N CL:FIXNUM)
  #+MCL
  (CL:CHECK-TYPE K CL:FIXNUM)
  (CL:PROGN (CL:SETQ N N) (CL:SETQ K K))
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "nth-kth-batch-input-error: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD (NTH-BATCH-OUTPUT FLOAT) ...)

(CL:DEFMETHOD NTH-BATCH-OUTPUT ((SELF NEURAL-NETWORK) N)
  "Return the output value for the `n'-th set of inputs in the input batch."
  (CL:DECLARE (CL:TYPE CL:FIXNUM N))
  #+MCL
  (CL:CHECK-TYPE N CL:FIXNUM)
  (CL:SETQ N N)
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "nth-batch-output: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD (BATCH-FORWARD-PROPAGATE-INPUTS FLOAT-ARRAY) ...)

(CL:DEFMETHOD BATCH-FORWARD-PROPAGATE-INPUTS ((SELF NEURAL-NETWORK))
  "Run forward propagation on the current input batch and store outputs in the output batch."
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "batch-forward-propagate-inputs: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD BATCH-BACKWARD-PROPAGATE-ERROR ...)

(CL:DEFMETHOD BATCH-BACKWARD-PROPAGATE-ERROR ((SELF NEURAL-NETWORK))
  "Run backward propagation on the current input and target batch and store back-propagated
errors in the input error batch."
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "batch-backward-propagate-error: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD BATCH-UPDATE-NETWORK-WEIGHTS ...)

(CL:DEFMETHOD BATCH-UPDATE-NETWORK-WEIGHTS ((SELF NEURAL-NETWORK))
  "Run weight updates for the current input and target batches."
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "batch-update-network-weights: Not defined on `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFGLOBAL *NEURAL-NETWORK-BATCH-SIZE* ...)

(CL:DEFVAR *NEURAL-NETWORK-BATCH-SIZE* 128)
(CL:DECLAIM (CL:TYPE CL:FIXNUM *NEURAL-NETWORK-BATCH-SIZE*))

;;; (DEFCLASS CHAMELEON-BATCH-NEURAL-NETWORK ...)

(CL:DEFCLASS CHAMELEON-BATCH-NEURAL-NETWORK (CHAMELEON-NEURAL-NETWORK)
  ((INPUT-BATCH :DOCUMENTATION
    "Each element is a set of values that may be legally passed to `set-input-values'."
    :ALLOCATION :INSTANCE :ACCESSOR %INPUT-BATCH)
   (KEY-BATCH :DOCUMENTATION
    "Each element is a key to identify a specific set of input values."
    :ALLOCATION :INSTANCE :ACCESSOR %KEY-BATCH)
   (TARGET-BATCH :DOCUMENTATION
    "Each element is a target output value for the respective set of input values."
    :ALLOCATION :INSTANCE :ACCESSOR %TARGET-BATCH)
   (OUTPUT-BATCH :ALLOCATION :INSTANCE :ACCESSOR %OUTPUT-BATCH)
   (INPUT-ERROR-BATCH :DOCUMENTATION
    "Copies of `input-error' but without the bias unit, thus shifted by 1."
    :ALLOCATION :INSTANCE :ACCESSOR %INPUT-ERROR-BATCH))
  (:DOCUMENTATION
   "Chameleon neural network that supports batch operations via emulation."))

(CL:DEFUN NEW-CHAMELEON-BATCH-NEURAL-NETWORK ()
  (CL:LET* ((SELF NULL))
   (CL:SETQ SELF
    (CL:MAKE-INSTANCE (CL:QUOTE CHAMELEON-BATCH-NEURAL-NETWORK)))
   (CL:SETF (%HO-DELTA SELF) NULL) (CL:SETF (%IH-DELTA SELF) NULL)
   (CL:SETF (%OUTPUT-ERROR SELF) NULL-FLOAT)
   (CL:SETF (%HIDDEN-ERROR SELF) NULL)
   (CL:SETF (%INPUT-ERROR SELF) NULL) (CL:SETF (%HO SELF) NULL)
   (CL:SETF (%IH SELF) NULL) (CL:SETF (%OUTPUT SELF) NULL-FLOAT)
   (CL:SETF (%HIDDEN SELF) NULL) (CL:SETF (%INPUT SELF) NULL)
   (CL:SETF (%PROPOSITION SELF) NULL)
   (CL:SETF (%INPUT-ERROR-BATCH SELF) NULL)
   (CL:SETF (%OUTPUT-BATCH SELF) NULL)
   (CL:SETF (%TARGET-BATCH SELF) NULL) (CL:SETF (%KEY-BATCH SELF) NULL)
   (CL:SETF (%INPUT-BATCH SELF) NULL) SELF))

(CL:DEFMETHOD PRIMARY-TYPE ((SELF CHAMELEON-BATCH-NEURAL-NETWORK))
  SGT-CHAMELEON-LOGIC-CHAMELEON-BATCH-NEURAL-NETWORK)

(CL:DEFUN ACCESS-CHAMELEON-BATCH-NEURAL-NETWORK-SLOT-VALUE (SELF SLOTNAME VALUE SETVALUE?)
  (CL:COND
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-INPUT-BATCH)
    (CL:IF SETVALUE? (CL:SETF (%INPUT-BATCH SELF) VALUE)
     (CL:SETQ VALUE (%INPUT-BATCH SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-KEY-BATCH)
    (CL:IF SETVALUE? (CL:SETF (%KEY-BATCH SELF) VALUE)
     (CL:SETQ VALUE (%KEY-BATCH SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-TARGET-BATCH)
    (CL:IF SETVALUE? (CL:SETF (%TARGET-BATCH SELF) VALUE)
     (CL:SETQ VALUE (%TARGET-BATCH SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-OUTPUT-BATCH)
    (CL:IF SETVALUE? (CL:SETF (%OUTPUT-BATCH SELF) VALUE)
     (CL:SETQ VALUE (%OUTPUT-BATCH SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-INPUT-ERROR-BATCH)
    (CL:IF SETVALUE? (CL:SETF (%INPUT-ERROR-BATCH SELF) VALUE)
     (CL:SETQ VALUE (%INPUT-ERROR-BATCH SELF))))
   (CL:T
    (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
     (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" SLOTNAME
      "' is not a valid case option")
     (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))
  VALUE)

;;; (DEFMETHOD ALLOCATE-NETWORK-ARRAYS ...)

(CL:DEFMETHOD ALLOCATE-NETWORK-ARRAYS ((SELF CHAMELEON-BATCH-NEURAL-NETWORK) NUM-IN NUM-HIDDEN NUM-OUT)
  (CL:DECLARE (CL:TYPE CL:FIXNUM NUM-IN NUM-HIDDEN NUM-OUT))
  #+MCL
  (CL:CHECK-TYPE NUM-IN CL:FIXNUM)
  #+MCL
  (CL:CHECK-TYPE NUM-HIDDEN CL:FIXNUM)
  #+MCL
  (CL:CHECK-TYPE NUM-OUT CL:FIXNUM)
  (CL:CALL-NEXT-METHOD SELF NUM-IN NUM-HIDDEN NUM-OUT)
  (CL:SETF (%INPUT-BATCH SELF)
   (NEW-VECTOR-SEQUENCE *NEURAL-NETWORK-BATCH-SIZE*))
  (CL:SETF (%KEY-BATCH SELF)
   (NEW-VECTOR-SEQUENCE *NEURAL-NETWORK-BATCH-SIZE*))
  (CL:SETF (%OUTPUT-BATCH SELF)
   (NEW-1D-FLOAT-ARRAY *NEURAL-NETWORK-BATCH-SIZE*))
  (CL:SETF (%TARGET-BATCH SELF)
   (NEW-VECTOR-SEQUENCE *NEURAL-NETWORK-BATCH-SIZE*))
  (CL:SETF (%INPUT-ERROR-BATCH SELF)
   (NEW-VECTOR-SEQUENCE *NEURAL-NETWORK-BATCH-SIZE*)))

;;; (DEFMETHOD CLEAR-BATCH-ARRAYS ...)

(CL:DEFMETHOD CLEAR-BATCH-ARRAYS ((SELF CHAMELEON-BATCH-NEURAL-NETWORK))
  (CLEAR (%INPUT-BATCH SELF))
  (CLEAR (%KEY-BATCH SELF))
  (CLEAR (%TARGET-BATCH SELF))
  (CLEAR (%INPUT-ERROR-BATCH SELF)))

;;; (DEFMETHOD (CURRENT-BATCH-SIZE INTEGER) ...)

(CL:DEFMETHOD CURRENT-BATCH-SIZE ((SELF CHAMELEON-BATCH-NEURAL-NETWORK))
  (%SEQUENCE-LENGTH (%INPUT-BATCH SELF)))

;;; (DEFMETHOD (BATCH-IS-FULL? BOOLEAN) ...)

(CL:DEFMETHOD BATCH-IS-FULL? ((SELF CHAMELEON-BATCH-NEURAL-NETWORK))
  (>= (%SEQUENCE-LENGTH (%INPUT-BATCH SELF))
   (LENGTH (%OUTPUT-BATCH SELF))))

;;; (DEFMETHOD PUSH-INPUT-VALUES ...)

(CL:DEFMETHOD PUSH-INPUT-VALUES ((SELF CHAMELEON-BATCH-NEURAL-NETWORK) KEY VALUES)
  (INSERT (%KEY-BATCH SELF) KEY)
  (INSERT (%INPUT-BATCH SELF) VALUES))

;;; (DEFMETHOD PUSH-TARGET-VALUE ...)

(CL:DEFMETHOD PUSH-TARGET-VALUE ((SELF CHAMELEON-BATCH-NEURAL-NETWORK) VALUE)
  (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT VALUE))
  #+MCL
  (CL:CHECK-TYPE VALUE CL:DOUBLE-FLOAT)
  (INSERT (%TARGET-BATCH SELF) (WRAP-FLOAT VALUE)))

;;; (DEFMETHOD (NTH-BATCH-KEY OBJECT) ...)

(CL:DEFMETHOD NTH-BATCH-KEY ((SELF CHAMELEON-BATCH-NEURAL-NETWORK) N)
  (CL:DECLARE (CL:TYPE CL:FIXNUM N))
  #+MCL
  (CL:CHECK-TYPE N CL:FIXNUM)
  (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%KEY-BATCH SELF))) N))

;;; (DEFMETHOD (NTH-KTH-BATCH-INPUT-ERROR FLOAT) ...)

(CL:DEFMETHOD NTH-KTH-BATCH-INPUT-ERROR ((SELF CHAMELEON-BATCH-NEURAL-NETWORK) N K)
  (CL:DECLARE (CL:TYPE CL:FIXNUM N K))
  #+MCL
  (CL:CHECK-TYPE N CL:FIXNUM)
  #+MCL
  (CL:CHECK-TYPE K CL:FIXNUM)
  (CL:AREF
   (CL:THE CL:SIMPLE-VECTOR
    (%THE-ARRAY
     (CL:AREF
      (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%INPUT-ERROR-BATCH SELF)))
      N)))
   (CL:THE CL:FIXNUM (CL:1+ K))))

;;; (DEFMETHOD (NTH-BATCH-OUTPUT FLOAT) ...)

(CL:DEFMETHOD NTH-BATCH-OUTPUT ((SELF CHAMELEON-BATCH-NEURAL-NETWORK) N)
  (CL:DECLARE (CL:TYPE CL:FIXNUM N))
  #+MCL
  (CL:CHECK-TYPE N CL:FIXNUM)
  (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%OUTPUT-BATCH SELF)))
   N))

;;; (DEFGLOBAL *BATCH-OPERATION-COUNT* ...)

(CL:DEFVAR *BATCH-OPERATION-COUNT* 0)
(CL:DECLAIM (CL:TYPE CL:FIXNUM *BATCH-OPERATION-COUNT*))

;;; (DEFGLOBAL *BATCH-TOTAL-COUNT* ...)

(CL:DEFVAR *BATCH-TOTAL-COUNT* 0)
(CL:DECLAIM (CL:TYPE CL:FIXNUM *BATCH-TOTAL-COUNT*))

;;; (DEFMETHOD (BATCH-FORWARD-PROPAGATE-INPUTS FLOAT-ARRAY) ...)

(CL:DEFMETHOD BATCH-FORWARD-PROPAGATE-INPUTS ((SELF CHAMELEON-BATCH-NEURAL-NETWORK))
  (CL:LET* ((OUTPUTS (%THE-ARRAY (%OUTPUT-BATCH SELF))))
   (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR OUTPUTS))
   (CL:LET*
    ((INPUT NULL) (VECTOR-000 (%INPUT-BATCH SELF)) (INDEX-000 0)
     (LENGTH-000 (%SEQUENCE-LENGTH VECTOR-000)) (I NULL-INTEGER)
     (ITER-000 0))
    (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX-000 LENGTH-000 I ITER-000))
    (CL:LOOP WHILE (CL:< INDEX-000 LENGTH-000) DO
     (CL:SETQ INPUT
      (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY VECTOR-000))
       INDEX-000))
     (CL:SETQ I ITER-000) (SET-INPUT-VALUES SELF INPUT)
     (CL:SETF (CL:AREF OUTPUTS I) (FORWARD-PROPAGATE-INPUTS SELF))
     (CL:SETQ INDEX-000 (CL:1+ INDEX-000))
     (CL:SETQ ITER-000 (CL:1+ ITER-000))))
   (%OUTPUT-BATCH SELF)))

;;; (DEFMETHOD (COPY-INPUT-ERROR FLOAT-ARRAY) ...)

(CL:DEFMETHOD COPY-INPUT-ERROR ((SELF CHAMELEON-BATCH-NEURAL-NETWORK))
  (CL:LET*
   ((INPUTERROR (%INPUT-ERROR SELF))
    (COPYERROR (NEW-1D-FLOAT-ARRAY (%DIM1 INPUTERROR))))
   (COPY-FLOAT-VALUES-TO-BUFFER INPUTERROR (%THE-ARRAY COPYERROR) 0
    (%DIM1 INPUTERROR))
   COPYERROR))

;;; (DEFMETHOD BATCH-BACKWARD-PROPAGATE-ERROR ...)

(CL:DEFMETHOD BATCH-BACKWARD-PROPAGATE-ERROR ((SELF CHAMELEON-BATCH-NEURAL-NETWORK))
  (CL:LET*
   ((TARGETS (%THE-ARRAY (%TARGET-BATCH SELF)))
    (ERRORS (%INPUT-ERROR-BATCH SELF)) (OUTPUT 0.0d0) (ERROR 0.0d0))
   (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR TARGETS)
    (CL:TYPE CL:DOUBLE-FLOAT OUTPUT ERROR))
   (CLEAR ERRORS)
   (CL:LET*
    ((INPUT NULL) (VECTOR-000 (%INPUT-BATCH SELF)) (INDEX-000 0)
     (LENGTH-000 (%SEQUENCE-LENGTH VECTOR-000)) (I NULL-INTEGER)
     (ITER-000 0))
    (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX-000 LENGTH-000 I ITER-000))
    (CL:LOOP WHILE (CL:< INDEX-000 LENGTH-000) DO
     (CL:SETQ INPUT
      (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY VECTOR-000))
       INDEX-000))
     (CL:SETQ I ITER-000) (SET-INPUT-VALUES SELF INPUT)
     (CL:SETQ OUTPUT (FORWARD-PROPAGATE-INPUTS SELF))
     (CL:SETQ ERROR (CL:- (%WRAPPER-VALUE (CL:AREF TARGETS I)) OUTPUT))
     (BACKWARD-PROPAGATE-ERROR SELF ERROR)
     (INSERT ERRORS (COPY-INPUT-ERROR SELF))
     (CL:SETQ INDEX-000 (CL:1+ INDEX-000))
     (CL:SETQ ITER-000 (CL:1+ ITER-000))))))

;;; (DEFMETHOD BATCH-UPDATE-NETWORK-WEIGHTS ...)

(CL:DEFMETHOD BATCH-UPDATE-NETWORK-WEIGHTS ((SELF CHAMELEON-BATCH-NEURAL-NETWORK))
  (CL:LET*
   ((TARGETS (%THE-ARRAY (%TARGET-BATCH SELF))) (OUTPUT 0.0d0)
    (ERROR 0.0d0))
   (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR TARGETS)
    (CL:TYPE CL:DOUBLE-FLOAT OUTPUT ERROR))
   (CL:LET*
    ((INPUT NULL) (VECTOR-000 (%INPUT-BATCH SELF)) (INDEX-000 0)
     (LENGTH-000 (%SEQUENCE-LENGTH VECTOR-000)) (I NULL-INTEGER)
     (ITER-000 0))
    (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX-000 LENGTH-000 I ITER-000))
    (CL:LOOP WHILE (CL:< INDEX-000 LENGTH-000) DO
     (CL:SETQ INPUT
      (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY VECTOR-000))
       INDEX-000))
     (CL:SETQ I ITER-000) (SET-INPUT-VALUES SELF INPUT)
     (CL:SETQ OUTPUT (FORWARD-PROPAGATE-INPUTS SELF))
     (CL:SETQ ERROR (CL:- (%WRAPPER-VALUE (CL:AREF TARGETS I)) OUTPUT))
     (BACKWARD-PROPAGATE-ERROR SELF ERROR)
     (UPDATE-NETWORK-WEIGHTS SELF ERROR)
     (CL:SETQ INDEX-000 (CL:1+ INDEX-000))
     (CL:SETQ ITER-000 (CL:1+ ITER-000))))))

;;; (DEFCLASS 2D-LONG-ARRAY ...)

(CL:DEFCLASS 2D-LONG-ARRAY (ABSTRACT-DIMENSIONAL-ARRAY)
  ((DIM2 :TYPE CL:FIXNUM :INITFORM NULL-INTEGER :ALLOCATION :INSTANCE
    :ACCESSOR %DIM2)
   (DIM1 :TYPE CL:FIXNUM :INITFORM NULL-INTEGER :ALLOCATION :INSTANCE
    :ACCESSOR %DIM1)
   (THE-ARRAY :ALLOCATION :INSTANCE :ACCESSOR %THE-ARRAY))
  (:DOCUMENTATION "2-dimensional array with long integer values."))

(CL:DEFUN NEW-2D-LONG-ARRAY (DIM2 DIM1)
  (CL:DECLARE (CL:TYPE CL:FIXNUM DIM2 DIM1))
  #+MCL
  (CL:CHECK-TYPE DIM2 CL:FIXNUM)
  #+MCL
  (CL:CHECK-TYPE DIM1 CL:FIXNUM)
  (CL:LET* ((SELF NULL))
   (CL:SETQ SELF (CL:MAKE-INSTANCE (CL:QUOTE 2D-LONG-ARRAY)))
   (CL:SETF (%DIM2 SELF) DIM2) (CL:SETF (%DIM1 SELF) DIM1)
   (CL:SETF (%THE-ARRAY SELF) STELLA::NULL-1D-ARRAY)
   (INITIALIZE-DIMENSIONAL-ARRAY SELF) SELF))

(CL:DEFMETHOD PRIMARY-TYPE ((SELF 2D-LONG-ARRAY))
  SGT-CHAMELEON-LOGIC-2D-LONG-ARRAY)

(CL:DEFMETHOD 2D-AREF-ADDRESS ((SELF 2D-LONG-ARRAY) I J)
  "Return the 1D address of the element at position `[i, j]'.
This is useful for fast element-wise iteration that doesn't need arithmetic."
  (CL:DECLARE (CL:TYPE CL:FIXNUM I J))
  #+MCL
  (CL:CHECK-TYPE I CL:FIXNUM)
  #+MCL
  (CL:CHECK-TYPE J CL:FIXNUM)
  (CL:+ (CL:* I (%DIM2 SELF)) J))

(CL:DEFMETHOD 2D-AREF-SETTER ((SELF 2D-LONG-ARRAY) VALUE I J)
  "Set the element of `self' at position `[i, j]' to `value'
and return the result."
  (CL:DECLARE (CL:TYPE CL:FIXNUM I J))
  #+MCL
  (CL:CHECK-TYPE I CL:FIXNUM)
  #+MCL
  (CL:CHECK-TYPE J CL:FIXNUM)
  (CL:SETF
   (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY SELF))
    (CL:THE CL:FIXNUM (CL:+ (CL:* I (%DIM2 SELF)) J)))
   VALUE))

(CL:DEFMETHOD 2D-AREF ((SELF 2D-LONG-ARRAY) I J)
  "Return the element of `self' at position `[i, j]'."
  (CL:DECLARE (CL:TYPE CL:FIXNUM I J))
  #+MCL
  (CL:CHECK-TYPE I CL:FIXNUM)
  #+MCL
  (CL:CHECK-TYPE J CL:FIXNUM)
  (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY SELF))
   (CL:THE CL:FIXNUM (CL:+ (CL:* I (%DIM2 SELF)) J))))

(CL:DEFMETHOD LENGTH ((SELF 2D-LONG-ARRAY))
  "Return the total number of elements in `self'."
  (CL:* (%DIM1 SELF) (%DIM2 SELF)))

(CL:DEFMETHOD 1D-AREF-ADDRESS ((SELF 2D-LONG-ARRAY) I)
  "Return the 1D address of the element at position `[i]'.
This is useful for fast element-wise iteration that doesn't need arithmetic."
  (CL:DECLARE (CL:TYPE CL:FIXNUM I))
  #+MCL
  (CL:CHECK-TYPE I CL:FIXNUM)
  I)

(CL:DEFMETHOD 1D-AREF-SETTER ((SELF 2D-LONG-ARRAY) VALUE I)
  "Set the element of `self' at position `[i]' to `value'
and return the result."
  (CL:DECLARE (CL:TYPE CL:FIXNUM I))
  #+MCL
  (CL:CHECK-TYPE I CL:FIXNUM)
  (CL:SETF (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY SELF)) I)
   VALUE))

(CL:DEFMETHOD 1D-AREF ((SELF 2D-LONG-ARRAY) I)
  "Return the element of `self' at position `[i]'."
  (CL:DECLARE (CL:TYPE CL:FIXNUM I))
  #+MCL
  (CL:CHECK-TYPE I CL:FIXNUM)
  (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY SELF)) I))

(CL:DEFMETHOD INITIALIZE-ARRAY ((SELF 2D-LONG-ARRAY) INITIALVALUE)
  "Initialize the elements of `self' with `initialValue'."
  (CL:LET* ((ARRAY (%THE-ARRAY SELF)))
   (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR ARRAY))
   (CL:LET*
    ((I NULL-INTEGER) (ITER-000 0)
     (UPPER-BOUND-000 (CL:1- (LENGTH SELF))))
    (CL:DECLARE (CL:TYPE CL:FIXNUM I ITER-000 UPPER-BOUND-000))
    (CL:LOOP WHILE (CL:<= ITER-000 UPPER-BOUND-000) DO
     (CL:SETQ I ITER-000) (CL:SETF (CL:AREF ARRAY I) INITIALVALUE)
     (CL:SETQ ITER-000 (CL:1+ ITER-000))))))

(CL:DEFMETHOD INITIALIZE-DIMENSIONAL-ARRAY ((SELF 2D-LONG-ARRAY))
  (CL:SETF (%THE-ARRAY SELF) (CL:MAKE-ARRAY (LENGTH SELF))))

;;; (DEFMETHOD (THE-ARRAY-READER (ARRAY () OF (LIKE (ANY-VALUE SELF)))) ...)

(CL:DEFMETHOD THE-ARRAY-READER ((SELF 2D-LONG-ARRAY))
  (%THE-ARRAY SELF))

;;; (DEFCLASS TENSORFLOW-BATCH-NEURAL-NETWORK ...)

(CL:DEFCLASS TENSORFLOW-BATCH-NEURAL-NETWORK (TENSORFLOW-NEURAL-NETWORK)
  ((INPUT-MODIFIED? :DOCUMENTATION
    "Cleared by Python/Tensorflow side, used to avoid unnecessary copying."
    :ALLOCATION :INSTANCE :ACCESSOR %INPUT-MODIFIED?)
   (INPUT-BATCH :DOCUMENTATION
    "Each row is a set of inputs for the input units of the network, including the bias."
    :ALLOCATION :INSTANCE :ACCESSOR %INPUT-BATCH)
   (INPUT-BATCH-LENGTH :TYPE CL:FIXNUM :INITFORM NULL-INTEGER
    :ALLOCATION :INSTANCE :ACCESSOR %INPUT-BATCH-LENGTH)
   (KEY-BATCH :DOCUMENTATION
    "Each element is a key to identify a specific set of input values."
    :ALLOCATION :INSTANCE :ACCESSOR %KEY-BATCH)
   (VECTOR-BATCH :DOCUMENTATION
    "Each row is a set of vector argument specs for the inputs of the network."
    :ALLOCATION :INSTANCE :ACCESSOR %VECTOR-BATCH)
   (VECTOR-BATCH-LENGTH :TYPE CL:FIXNUM :INITFORM NULL-INTEGER
    :ALLOCATION :INSTANCE :ACCESSOR %VECTOR-BATCH-LENGTH)
   (TARGET-BATCH :DOCUMENTATION
    "Each element is a target output value for the respective set of input values."
    :ALLOCATION :INSTANCE :ACCESSOR %TARGET-BATCH)
   (TARGET-BATCH-LENGTH :TYPE CL:FIXNUM :INITFORM NULL-INTEGER
    :ALLOCATION :INSTANCE :ACCESSOR %TARGET-BATCH-LENGTH)
   (OUTPUT-BATCH :ALLOCATION :INSTANCE :ACCESSOR %OUTPUT-BATCH)
   (INPUT-ERROR-BATCH :DOCUMENTATION
    "Each row is a set of errors the respective inputs including the bias."
    :ALLOCATION :INSTANCE :ACCESSOR %INPUT-ERROR-BATCH))
  (:DOCUMENTATION
   "Tensorflow neural network that supports batch operations.  We implement input and result
batches as 1-D and 2-D float arrays to enable fast back-and-forth copying in a single shot instead of having
multiple method calls.  For this reason, we maintain the input and target sequences manually."))

(CL:DEFUN NEW-TENSORFLOW-BATCH-NEURAL-NETWORK ()
  (CL:LET* ((SELF NULL))
   (CL:SETQ SELF
    (CL:MAKE-INSTANCE (CL:QUOTE TENSORFLOW-BATCH-NEURAL-NETWORK)))
   (CL:SETF (%N-VECTOR-ARGUMENT-INPUTS SELF) -1)
   (CL:SETF (%N-VECTOR-ARGUMENT-SPECS SELF) -1)
   (CL:SETF (%N-VECTOR-ARGUMENTS SELF) -1) (CL:SETF (%MODEL SELF) NULL)
   (CL:SETF (%PROPOSITION SELF) NULL)
   (CL:SETF (%INPUT-ERROR-BATCH SELF) NULL)
   (CL:SETF (%OUTPUT-BATCH SELF) NULL)
   (CL:SETF (%TARGET-BATCH-LENGTH SELF) 0)
   (CL:SETF (%TARGET-BATCH SELF) NULL)
   (CL:SETF (%VECTOR-BATCH-LENGTH SELF) 0)
   (CL:SETF (%VECTOR-BATCH SELF) NULL) (CL:SETF (%KEY-BATCH SELF) NULL)
   (CL:SETF (%INPUT-BATCH-LENGTH SELF) 0)
   (CL:SETF (%INPUT-BATCH SELF) NULL)
   (CL:SETF (%INPUT-MODIFIED? SELF) CL:T) SELF))

(CL:DEFMETHOD PRIMARY-TYPE ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK))
  SGT-CHAMELEON-LOGIC-TENSORFLOW-BATCH-NEURAL-NETWORK)

(CL:DEFUN ACCESS-TENSORFLOW-BATCH-NEURAL-NETWORK-SLOT-VALUE (SELF SLOTNAME VALUE SETVALUE?)
  (CL:COND
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-INPUT-MODIFIED?)
    (CL:IF SETVALUE?
     (CL:SETF (%INPUT-MODIFIED? SELF)
      (COERCE-WRAPPED-BOOLEAN-TO-BOOLEAN VALUE))
     (CL:SETQ VALUE
      (CL:IF (%INPUT-MODIFIED? SELF) TRUE-WRAPPER FALSE-WRAPPER))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-INPUT-BATCH)
    (CL:IF SETVALUE? (CL:SETF (%INPUT-BATCH SELF) VALUE)
     (CL:SETQ VALUE (%INPUT-BATCH SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-INPUT-BATCH-LENGTH)
    (CL:IF SETVALUE?
     (CL:SETF (%INPUT-BATCH-LENGTH SELF) (%WRAPPER-VALUE VALUE))
     (CL:SETQ VALUE (WRAP-INTEGER (%INPUT-BATCH-LENGTH SELF)))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-KEY-BATCH)
    (CL:IF SETVALUE? (CL:SETF (%KEY-BATCH SELF) VALUE)
     (CL:SETQ VALUE (%KEY-BATCH SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-VECTOR-BATCH)
    (CL:IF SETVALUE? (CL:SETF (%VECTOR-BATCH SELF) VALUE)
     (CL:SETQ VALUE (%VECTOR-BATCH SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-VECTOR-BATCH-LENGTH)
    (CL:IF SETVALUE?
     (CL:SETF (%VECTOR-BATCH-LENGTH SELF) (%WRAPPER-VALUE VALUE))
     (CL:SETQ VALUE (WRAP-INTEGER (%VECTOR-BATCH-LENGTH SELF)))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-TARGET-BATCH)
    (CL:IF SETVALUE? (CL:SETF (%TARGET-BATCH SELF) VALUE)
     (CL:SETQ VALUE (%TARGET-BATCH SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-TARGET-BATCH-LENGTH)
    (CL:IF SETVALUE?
     (CL:SETF (%TARGET-BATCH-LENGTH SELF) (%WRAPPER-VALUE VALUE))
     (CL:SETQ VALUE (WRAP-INTEGER (%TARGET-BATCH-LENGTH SELF)))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-OUTPUT-BATCH)
    (CL:IF SETVALUE? (CL:SETF (%OUTPUT-BATCH SELF) VALUE)
     (CL:SETQ VALUE (%OUTPUT-BATCH SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-INPUT-ERROR-BATCH)
    (CL:IF SETVALUE? (CL:SETF (%INPUT-ERROR-BATCH SELF) VALUE)
     (CL:SETQ VALUE (%INPUT-ERROR-BATCH SELF))))
   (CL:T
    (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
     (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" SLOTNAME
      "' is not a valid case option")
     (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))
  VALUE)

;;; (DEFMETHOD PRINT-NETWORK-ARRAYS ...)

(CL:DEFMETHOD PRINT-NETWORK-ARRAYS ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK))
  (CL:LET* ((BATCHLENGTH (%INPUT-BATCH-LENGTH SELF)))
   (CL:DECLARE (CL:TYPE CL:FIXNUM BATCHLENGTH))
   (%%PRINT-STREAM (%NATIVE-STREAM STANDARD-OUTPUT) "input batch ("
    BATCHLENGTH "):" EOL)
   (CL:LET*
    ((I NULL-INTEGER) (ITER-000 0)
     (UPPER-BOUND-000 (CL:1- BATCHLENGTH)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM I ITER-000 UPPER-BOUND-000))
    (CL:LOOP WHILE (CL:<= ITER-000 UPPER-BOUND-000) DO
     (CL:SETQ I ITER-000)
     (CL:LET*
      ((J NULL-INTEGER) (ITER-001 0)
       (UPPER-BOUND-001 (CL:1- (%DIM2 (%INPUT-BATCH SELF)))))
      (CL:DECLARE (CL:TYPE CL:FIXNUM J ITER-001 UPPER-BOUND-001))
      (CL:LOOP WHILE (CL:<= ITER-001 UPPER-BOUND-001) DO
       (CL:SETQ J ITER-001)
       (%%PRINT-STREAM (%NATIVE-STREAM STANDARD-OUTPUT)
        (CL:AREF
         (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%INPUT-BATCH SELF)))
         (CL:THE CL:FIXNUM
          (CL:+ (CL:* I (%DIM2 (%INPUT-BATCH SELF))) J)))
        " ")
       (CL:SETQ ITER-001 (CL:1+ ITER-001))))
     (%%PRINT-STREAM (%NATIVE-STREAM STANDARD-OUTPUT) EOL)
     (CL:SETQ ITER-000 (CL:1+ ITER-000))))
   (CL:SETQ BATCHLENGTH (%TARGET-BATCH-LENGTH SELF))
   (%%PRINT-STREAM (%NATIVE-STREAM STANDARD-OUTPUT) "target batch ("
    BATCHLENGTH "):" EOL)
   (CL:LET*
    ((I NULL-INTEGER) (ITER-002 0)
     (UPPER-BOUND-002 (CL:1- BATCHLENGTH)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM I ITER-002 UPPER-BOUND-002))
    (CL:LOOP WHILE (CL:<= ITER-002 UPPER-BOUND-002) DO
     (CL:SETQ I ITER-002)
     (%%PRINT-STREAM (%NATIVE-STREAM STANDARD-OUTPUT)
      (CL:AREF
       (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%TARGET-BATCH SELF))) I)
      " ")
     (CL:SETQ ITER-002 (CL:1+ ITER-002))))
   (%%PRINT-STREAM (%NATIVE-STREAM STANDARD-OUTPUT) EOL)
   (CL:SETQ BATCHLENGTH (%INPUT-BATCH-LENGTH SELF))
   (%%PRINT-STREAM (%NATIVE-STREAM STANDARD-OUTPUT) "output batch ("
    BATCHLENGTH "):" EOL)
   (CL:LET*
    ((I NULL-INTEGER) (ITER-003 0)
     (UPPER-BOUND-003 (CL:1- BATCHLENGTH)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM I ITER-003 UPPER-BOUND-003))
    (CL:LOOP WHILE (CL:<= ITER-003 UPPER-BOUND-003) DO
     (CL:SETQ I ITER-003)
     (%%PRINT-STREAM (%NATIVE-STREAM STANDARD-OUTPUT)
      (CL:AREF
       (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%OUTPUT-BATCH SELF))) I)
      " ")
     (CL:SETQ ITER-003 (CL:1+ ITER-003))))
   (%%PRINT-STREAM (%NATIVE-STREAM STANDARD-OUTPUT) EOL)
   (%%PRINT-STREAM (%NATIVE-STREAM STANDARD-OUTPUT)
    "input error batch (" BATCHLENGTH "):" EOL)
   (CL:LET*
    ((I NULL-INTEGER) (ITER-004 0)
     (UPPER-BOUND-004 (CL:1- BATCHLENGTH)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM I ITER-004 UPPER-BOUND-004))
    (CL:LOOP WHILE (CL:<= ITER-004 UPPER-BOUND-004) DO
     (CL:SETQ I ITER-004)
     (CL:LET*
      ((J NULL-INTEGER) (ITER-005 0)
       (UPPER-BOUND-005 (CL:1- (%DIM2 (%INPUT-ERROR-BATCH SELF)))))
      (CL:DECLARE (CL:TYPE CL:FIXNUM J ITER-005 UPPER-BOUND-005))
      (CL:LOOP WHILE (CL:<= ITER-005 UPPER-BOUND-005) DO
       (CL:SETQ J ITER-005)
       (%%PRINT-STREAM (%NATIVE-STREAM STANDARD-OUTPUT)
        (CL:AREF
         (CL:THE CL:SIMPLE-VECTOR
          (%THE-ARRAY (%INPUT-ERROR-BATCH SELF)))
         (CL:THE CL:FIXNUM
          (CL:+ (CL:* I (%DIM2 (%INPUT-ERROR-BATCH SELF))) J)))
        " ")
       (CL:SETQ ITER-005 (CL:1+ ITER-005))))
     (%%PRINT-STREAM (%NATIVE-STREAM STANDARD-OUTPUT) EOL)
     (CL:SETQ ITER-004 (CL:1+ ITER-004))))))

;;; (DEFMETHOD ALLOCATE-NETWORK-ARRAYS ...)

(CL:DEFMETHOD ALLOCATE-NETWORK-ARRAYS ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) NUM-IN NUM-HIDDEN NUM-OUT)
  (CL:DECLARE (CL:TYPE CL:FIXNUM NUM-IN NUM-HIDDEN NUM-OUT))
  #+MCL
  (CL:CHECK-TYPE NUM-IN CL:FIXNUM)
  #+MCL
  (CL:CHECK-TYPE NUM-HIDDEN CL:FIXNUM)
  #+MCL
  (CL:CHECK-TYPE NUM-OUT CL:FIXNUM)
  (CL:CALL-NEXT-METHOD SELF NUM-IN NUM-HIDDEN NUM-OUT)
  (CL:LET*
   ((TVNUMIN
     (CL:1+
      (NUMBER-OF-TRUTH-VALUE-ARGUMENTS SELF (%PROPOSITION SELF)))))
   (CL:DECLARE (CL:TYPE CL:FIXNUM TVNUMIN))
   (CL:SETF (%INPUT-BATCH SELF)
    (NEW-2D-FLOAT-ARRAY TVNUMIN *NEURAL-NETWORK-BATCH-SIZE*))
   (CL:SETF (%KEY-BATCH SELF)
    (NEW-VECTOR-SEQUENCE *NEURAL-NETWORK-BATCH-SIZE*))
   (CL:WHEN (CL:> (NUMBER-OF-VECTOR-ARGUMENT-SPECS SELF NULL) 0)
    (CL:SETF (%VECTOR-BATCH SELF)
     (NEW-2D-LONG-ARRAY (NUMBER-OF-VECTOR-ARGUMENT-SPECS SELF NULL)
      *NEURAL-NETWORK-BATCH-SIZE*)))
   (CL:SETF (%TARGET-BATCH SELF)
    (NEW-1D-FLOAT-ARRAY *NEURAL-NETWORK-BATCH-SIZE*))
   (CL:SETF (%OUTPUT-BATCH SELF)
    (NEW-1D-FLOAT-ARRAY *NEURAL-NETWORK-BATCH-SIZE*))
   (CL:SETF (%INPUT-ERROR-BATCH SELF)
    (NEW-2D-FLOAT-ARRAY TVNUMIN *NEURAL-NETWORK-BATCH-SIZE*))
   (CL:SETF (%INPUT-MODIFIED? SELF) CL:T)))

;;; (DEFMETHOD BUILD-PROPOSITION-NETWORK ...)

(CL:DEFMETHOD BUILD-PROPOSITION-NETWORK ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) PROP)
  "Build a neural network for the proposition `prop'.  This builds a two-layer
perceptron network whose input nodes are activated by the truth of `prop's arguments and whose
output node computes the truth of `prop'."
  (CL:LET*
   ((NUM-IN
     (CL:+ (NUMBER-OF-TRUTH-VALUE-ARGUMENTS SELF PROP)
      (NUMBER-OF-VECTOR-ARGUMENT-INPUTS SELF PROP) 1))
    (NUM-HIDDEN (MIN (CL:+ NUM-IN 0) 20)))
   (CL:DECLARE (CL:TYPE CL:FIXNUM NUM-IN NUM-HIDDEN))
   (CL:WHEN (CL:> NUM-IN 100)
    (CL:SETQ NUM-HIDDEN (CL:+ (FLOOR (CL:/ NUM-IN 10.0d0)) 10)))
   (CL:SETF (%PROPOSITION SELF) PROP)
   (ALLOCATE-NETWORK-ARRAYS SELF NUM-IN NUM-HIDDEN 1)
   (CL:LET* ((TEST-VALUE-000 (%KIND PROP)))
    (CL:COND
     ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-AND)
       (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-OR))
      (INITIALIZE-NETWORK-WEIGHTS SELF))
     (CL:T (INITIALIZE-NETWORK-WEIGHTS SELF))))
   (LINK-NEURAL-NETWORK SELF PROP)))

;;; (DEFMETHOD (NUMBER-OF-INPUTS INTEGER) ...)

(CL:DEFMETHOD NUMBER-OF-INPUTS ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK))
  "Return the number of input values expected by `self' (ignores bias unit)."
  (CL:1- (%DIM2 (%INPUT-BATCH SELF))))

;;; (DEFMETHOD (NTH-INPUT FLOAT) ...)

(CL:DEFMETHOD NTH-INPUT ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) N)
  "Return the 0-based `n'-th proposition input of `self' (ignores bias unit)."
  (CL:DECLARE (CL:TYPE CL:FIXNUM N))
  #+MCL
  (CL:CHECK-TYPE N CL:FIXNUM)
  (CL:SETQ N N)
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "nth-input: not supported on: `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD (NTH-INPUT-ERROR FLOAT) ...)

(CL:DEFMETHOD NTH-INPUT-ERROR ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) N)
  "Return the 0-based `n'-th proposition input error of `self' (ignores bias unit)."
  (CL:DECLARE (CL:TYPE CL:FIXNUM N))
  #+MCL
  (CL:CHECK-TYPE N CL:FIXNUM)
  (CL:SETQ N N)
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "nth-input-error: not supported on: `" SELF "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD SET-INPUT-VALUES ...)

(CL:DEFMETHOD SET-INPUT-VALUES ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) VALUES)
  "Set the current truth-value inputs of the network `self' to float `values' in sequence.
Missing inputs will be set to 0.0, extra values will be ignored."
  (CL:CALL-NEXT-METHOD SELF VALUES))

;;; (DEFMETHOD (GET-VECTOR-ARGUMENT-SPEC OBJECT) ...)

(CL:DEFMETHOD GET-VECTOR-ARGUMENT-SPEC ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) ARG)
  "Generate a single argument spec for `arg' that can be used for `set-vector-input-values'.
`arg' can either be a proposition or justification."
  (CL:LET* ((SPEC (CL:CALL-NEXT-METHOD SELF ARG)) (EVALARGS NIL))
   (CL:COND
    ((CL:EQ (SAFE-PRIMARY-TYPE SPEC) SGT-CHAMELEON-STELLA-CONS)
     (CL:PROGN
      (CL:LET* ((ELT NULL) (ITER-000 SPEC) (COLLECT-000 NULL))
       (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-000 NIL)) DO
        (CL:SETQ ELT (%%VALUE ITER-000))
        (CL:WHEN (LONG-INTEGER? ELT)
         (CL:IF (CL:EQ COLLECT-000 NULL)
          (CL:PROGN (CL:SETQ COLLECT-000 (CONS ELT NIL))
           (CL:IF (CL:EQ EVALARGS NIL) (CL:SETQ EVALARGS COLLECT-000)
            (ADD-CONS-TO-END-OF-CONS-LIST EVALARGS COLLECT-000)))
          (CL:PROGN (CL:SETF (%%REST COLLECT-000) (CONS ELT NIL))
           (CL:SETQ COLLECT-000 (%%REST COLLECT-000)))))
        (CL:SETQ ITER-000 (%%REST ITER-000))))))
    (CL:T))
   (CL:IF (CL:NOT (CL:EQ EVALARGS NIL)) EVALARGS SPEC)))

;;; (DEFMETHOD SET-VECTOR-INPUT-VALUES ...)

(CL:DEFMETHOD SET-VECTOR-INPUT-VALUES ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) VECTORSPECS)
  "Set the current vector inputs of the network `self' to the vectors described by `vectorSpecs'.
Each vector spec describes a vector-generating proposition that produces one or more vectors.  How those specs
are translated into actual numeric vectors such as embeddings is specific to the particular neural network type."
  (CL:CALL-NEXT-METHOD SELF VECTORSPECS))

;;; (DEFMETHOD (FORWARD-PROPAGATE-INPUTS FLOAT) ...)

(CL:DEFMETHOD FORWARD-PROPAGATE-INPUTS ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK))
  "Activates the current inputs of the network `self' to compute its output.
Sets `self's `output' slot and returns the computed value.  Reads input activations and
weights and updates hidden and output activations."
  (CL:CALL-NEXT-METHOD SELF))

;;; (DEFMETHOD CLEAR-BATCH-ARRAYS ...)

(CL:DEFMETHOD CLEAR-BATCH-ARRAYS ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK))
  (CL:SETF (%INPUT-BATCH-LENGTH SELF) 0)
  (CLEAR (%KEY-BATCH SELF))
  (CL:SETF (%VECTOR-BATCH-LENGTH SELF) 0)
  (CL:SETF (%TARGET-BATCH-LENGTH SELF) 0)
  (CL:SETF (%INPUT-MODIFIED? SELF) CL:T))

;;; (DEFMETHOD (CURRENT-BATCH-SIZE INTEGER) ...)

(CL:DEFMETHOD CURRENT-BATCH-SIZE ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK))
  (%INPUT-BATCH-LENGTH SELF))

;;; (DEFMETHOD (BATCH-IS-FULL? BOOLEAN) ...)

(CL:DEFMETHOD BATCH-IS-FULL? ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK))
  (>= (%INPUT-BATCH-LENGTH SELF) *NEURAL-NETWORK-BATCH-SIZE*))

;;; (DEFMETHOD PUSH-INPUT-VALUES ...)

(CL:DEFMETHOD PUSH-INPUT-VALUES ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) KEY VALUES)
  (CL:LET*
   ((INPUTBATCH (%INPUT-BATCH SELF))
    (INPUTARRAY (%THE-ARRAY INPUTBATCH))
    (START
     (CL:+ (CL:* (%INPUT-BATCH-LENGTH SELF) (%DIM2 INPUTBATCH)) 0)))
   (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR INPUTARRAY)
    (CL:TYPE CL:FIXNUM START))
   (CL:SETF (CL:AREF INPUTARRAY START) 1.0d0)
   (COPY-FLOAT-VALUES-TO-BUFFER VALUES INPUTARRAY (CL:1+ START)
    (CL:+ START (%DIM2 INPUTBATCH)))
   (CL:SETF (%INPUT-BATCH-LENGTH SELF)
    (CL:1+ (%INPUT-BATCH-LENGTH SELF)))
   (INSERT (%KEY-BATCH SELF) KEY)
   (CL:SETF (%INPUT-MODIFIED? SELF) CL:T)))

;;; (DEFMETHOD PUSH-VECTOR-INPUT-VALUES ...)

(CL:DEFMETHOD PUSH-VECTOR-INPUT-VALUES ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) VECTORSPECS)
  (CL:WHEN (CL:NOT (CL:EQ (%VECTOR-BATCH SELF) NULL))
   (CL:LET*
    ((VECTORBATCH (%VECTOR-BATCH SELF))
     (VECTORARRAY (%THE-ARRAY VECTORBATCH))
     (START
      (CL:+ (CL:* (%VECTOR-BATCH-LENGTH SELF) (%DIM2 VECTORBATCH)) 0))
     (I START))
    (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR VECTORARRAY)
     (CL:TYPE CL:FIXNUM START I))
    (CL:LET* ((TEST-VALUE-000 (SAFE-PRIMARY-TYPE VECTORSPECS)))
     (CL:COND
      ((SUBTYPE-OF? TEST-VALUE-000 SGT-CHAMELEON-STELLA-VECTOR)
       (CL:PROGN
        (CL:LET*
         ((SPEC NULL) (VECTOR-000 VECTORSPECS) (INDEX-000 0)
          (LENGTH-000 (LENGTH VECTOR-000)))
         (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX-000 LENGTH-000))
         (CL:LOOP WHILE (CL:< INDEX-000 LENGTH-000) DO
          (CL:SETQ SPEC
           (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY VECTOR-000))
            INDEX-000))
          (CL:COND
           ((CL:EQ (SAFE-PRIMARY-TYPE SPEC) SGT-CHAMELEON-STELLA-CONS)
            (CL:PROGN
             (CL:LET* ((ELT NULL) (ITER-000 SPEC))
              (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-000 NIL)) DO
               (CL:SETQ ELT (%%VALUE ITER-000))
               (CL:COND
                ((SUBTYPE-OF-LONG-INTEGER? (SAFE-PRIMARY-TYPE ELT))
                 (CL:PROGN
                  (CL:SETF (CL:AREF VECTORARRAY I)
                   (%WRAPPER-VALUE ELT))
                  (CL:SETQ I (CL:1+ I))))
                (CL:T
                 (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
                  (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
                   "push-vector-input-values: unexpected vector argument spec: `"
                   ELT "'")
                  (CL:ERROR
                   (NEW-STELLA-EXCEPTION
                    (THE-STRING-READER STREAM-000))))))
               (CL:SETQ ITER-000 (%%REST ITER-000))))))
           (CL:T))
          (CL:SETQ INDEX-000 (CL:1+ INDEX-000))))))
      ((CL:EQ TEST-VALUE-000 SGT-CHAMELEON-STELLA-CONS)
       (CL:PROGN
        (CL:LET* ((SPEC NULL) (ITER-001 VECTORSPECS))
         (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-001 NIL)) DO
          (CL:SETQ SPEC (%%VALUE ITER-001))
          (CL:COND
           ((CL:EQ (SAFE-PRIMARY-TYPE SPEC) SGT-CHAMELEON-STELLA-CONS)
            (CL:PROGN
             (CL:LET* ((ELT NULL) (ITER-002 SPEC))
              (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-002 NIL)) DO
               (CL:SETQ ELT (%%VALUE ITER-002))
               (CL:COND
                ((SUBTYPE-OF-LONG-INTEGER? (SAFE-PRIMARY-TYPE ELT))
                 (CL:PROGN
                  (CL:SETF (CL:AREF VECTORARRAY I)
                   (%WRAPPER-VALUE ELT))
                  (CL:SETQ I (CL:1+ I))))
                (CL:T
                 (CL:LET* ((STREAM-001 (NEW-OUTPUT-STRING-STREAM)))
                  (%%PRINT-STREAM (%NATIVE-STREAM STREAM-001)
                   "push-vector-input-values: unexpected vector argument spec: `"
                   ELT "'")
                  (CL:ERROR
                   (NEW-STELLA-EXCEPTION
                    (THE-STRING-READER STREAM-001))))))
               (CL:SETQ ITER-002 (%%REST ITER-002))))))
           (CL:T))
          (CL:SETQ ITER-001 (%%REST ITER-001))))))
      (CL:T
       (CL:LET* ((STREAM-002 (NEW-OUTPUT-STRING-STREAM)))
        (%%PRINT-STREAM (%NATIVE-STREAM STREAM-002) "`" TEST-VALUE-000
         "' is not a valid case option")
        (CL:ERROR
         (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-002)))))))
    (CL:WHEN (CL:> I START)
     (CL:SETF (%VECTOR-BATCH-LENGTH SELF)
      (CL:1+ (%VECTOR-BATCH-LENGTH SELF)))
     (CL:SETF (%INPUT-MODIFIED? SELF) CL:T)))))

;;; (DEFMETHOD PUSH-TARGET-VALUE ...)

(CL:DEFMETHOD PUSH-TARGET-VALUE ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) VALUE)
  (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT VALUE))
  #+MCL
  (CL:CHECK-TYPE VALUE CL:DOUBLE-FLOAT)
  (CL:LET* ((CURSOR (%TARGET-BATCH-LENGTH SELF)))
   (CL:DECLARE (CL:TYPE CL:FIXNUM CURSOR))
   (CL:SETF
    (CL:AREF
     (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%TARGET-BATCH SELF)))
     CURSOR)
    VALUE)
   (CL:SETF (%TARGET-BATCH-LENGTH SELF) (CL:1+ CURSOR))
   (CL:SETF (%INPUT-MODIFIED? SELF) CL:T)))

;;; (DEFMETHOD (NTH-BATCH-KEY OBJECT) ...)

(CL:DEFMETHOD NTH-BATCH-KEY ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) N)
  (CL:DECLARE (CL:TYPE CL:FIXNUM N))
  #+MCL
  (CL:CHECK-TYPE N CL:FIXNUM)
  (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%KEY-BATCH SELF))) N))

;;; (DEFMETHOD (NTH-KTH-BATCH-INPUT-ERROR FLOAT) ...)

(CL:DEFMETHOD NTH-KTH-BATCH-INPUT-ERROR ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) N K)
  (CL:DECLARE (CL:TYPE CL:FIXNUM N K))
  #+MCL
  (CL:CHECK-TYPE N CL:FIXNUM)
  #+MCL
  (CL:CHECK-TYPE K CL:FIXNUM)
  (CL:AREF
   (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%INPUT-ERROR-BATCH SELF)))
   (CL:THE CL:FIXNUM
    (CL:+ (CL:* N (%DIM2 (%INPUT-ERROR-BATCH SELF))) (CL:1+ K)))))

;;; (DEFMETHOD (NTH-BATCH-OUTPUT FLOAT) ...)

(CL:DEFMETHOD NTH-BATCH-OUTPUT ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) N)
  (CL:DECLARE (CL:TYPE CL:FIXNUM N))
  #+MCL
  (CL:CHECK-TYPE N CL:FIXNUM)
  (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%OUTPUT-BATCH SELF)))
   N))

;;; (DEFMETHOD (BATCH-FORWARD-PROPAGATE-INPUTS FLOAT-ARRAY) ...)

(CL:DEFMETHOD BATCH-FORWARD-PROPAGATE-INPUTS ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK))
  (CL:FUNCALL
   (%WRAPPER-VALUE
    (%%VALUE
     (%SYMBOL-VALUE-AND-PLIST
      SYM-CHAMELEON-LOGIC-TENSORFLOW-BATCH-NEURAL-NETWORK.BATCH-FORWARD-PROPAGATE-INPUTS))))
  (%OUTPUT-BATCH SELF))

;;; (DEFMETHOD BATCH-BACKWARD-PROPAGATE-ERROR ...)

(CL:DEFMETHOD BATCH-BACKWARD-PROPAGATE-ERROR ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK))
  (CL:FUNCALL
   (%WRAPPER-VALUE
    (%%VALUE
     (%SYMBOL-VALUE-AND-PLIST
      SYM-CHAMELEON-LOGIC-TENSORFLOW-BATCH-NEURAL-NETWORK.BATCH-BACKWARD-PROPAGATE-ERROR)))))

;;; (DEFMETHOD BATCH-UPDATE-NETWORK-WEIGHTS ...)

(CL:DEFMETHOD BATCH-UPDATE-NETWORK-WEIGHTS ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK))
  (CL:FUNCALL
   (%WRAPPER-VALUE
    (%%VALUE
     (%SYMBOL-VALUE-AND-PLIST
      SYM-CHAMELEON-LOGIC-TENSORFLOW-BATCH-NEURAL-NETWORK.BATCH-UPDATE-NETWORK-WEIGHTS)))))

;;; (DEFCLASS NETWORK-PROOF-QUEUE ...)

(CL:DEFCLASS NETWORK-PROOF-QUEUE (STANDARD-OBJECT)
  ((DEPENDENTS :DOCUMENTATION
    "Map from computation prerequisites to their dependents."
    :ALLOCATION :INSTANCE :ACCESSOR %DEPENDENTS)
   (PREREQUISITES :DOCUMENTATION
    "Map from dependents to their computation prerequisites."
    :ALLOCATION :INSTANCE :ACCESSOR %PREREQUISITES)
   (ACTIVE-NETWORKS :ALLOCATION :INSTANCE :ACCESSOR %ACTIVE-NETWORKS)
   (MIN-BATCH-SIZE :TYPE CL:FIXNUM :INITFORM NULL-INTEGER :ALLOCATION
    :INSTANCE :ACCESSOR %MIN-BATCH-SIZE)
   (N-QUEUED :TYPE CL:FIXNUM :INITFORM NULL-INTEGER :ALLOCATION
    :INSTANCE :ACCESSOR %N-QUEUED)))

(CL:DEFUN NEW-NETWORK-PROOF-QUEUE ()
  (CL:LET* ((SELF NULL))
   (CL:SETQ SELF (CL:MAKE-INSTANCE (CL:QUOTE NETWORK-PROOF-QUEUE)))
   (CL:SETF (%N-QUEUED SELF) 0)
   (CL:SETF (%MIN-BATCH-SIZE SELF)
    (FLOOR (CL:* *NEURAL-NETWORK-BATCH-SIZE* 0.8d0)))
   (CL:SETF (%ACTIVE-NETWORKS SELF) (NEW-HASH-SET))
   (CL:SETF (%PREREQUISITES SELF) (NEW-KEY-VALUE-MAP))
   (CL:SETF (%DEPENDENTS SELF) (NEW-KEY-VALUE-MAP)) SELF))

(CL:DEFMETHOD PRIMARY-TYPE ((SELF NETWORK-PROOF-QUEUE))
  SGT-CHAMELEON-LOGIC-NETWORK-PROOF-QUEUE)

(CL:DEFUN ACCESS-NETWORK-PROOF-QUEUE-SLOT-VALUE (SELF SLOTNAME VALUE SETVALUE?)
  (CL:COND
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-DEPENDENTS)
    (CL:IF SETVALUE? (CL:SETF (%DEPENDENTS SELF) VALUE)
     (CL:SETQ VALUE (%DEPENDENTS SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-PREREQUISITES)
    (CL:IF SETVALUE? (CL:SETF (%PREREQUISITES SELF) VALUE)
     (CL:SETQ VALUE (%PREREQUISITES SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-ACTIVE-NETWORKS)
    (CL:IF SETVALUE? (CL:SETF (%ACTIVE-NETWORKS SELF) VALUE)
     (CL:SETQ VALUE (%ACTIVE-NETWORKS SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-MIN-BATCH-SIZE)
    (CL:IF SETVALUE?
     (CL:SETF (%MIN-BATCH-SIZE SELF) (%WRAPPER-VALUE VALUE))
     (CL:SETQ VALUE (WRAP-INTEGER (%MIN-BATCH-SIZE SELF)))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-N-QUEUED)
    (CL:IF SETVALUE? (CL:SETF (%N-QUEUED SELF) (%WRAPPER-VALUE VALUE))
     (CL:SETQ VALUE (WRAP-INTEGER (%N-QUEUED SELF)))))
   (CL:T
    (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
     (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" SLOTNAME
      "' is not a valid case option")
     (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))
  VALUE)

;;; (DEFCLASS NETWORK-PROOF-FORWARD-QUEUE ...)

(CL:DEFCLASS NETWORK-PROOF-FORWARD-QUEUE (NETWORK-PROOF-QUEUE)
  ())

(CL:DEFUN NEW-NETWORK-PROOF-FORWARD-QUEUE ()
  (CL:LET* ((SELF NULL))
   (CL:SETQ SELF
    (CL:MAKE-INSTANCE (CL:QUOTE NETWORK-PROOF-FORWARD-QUEUE)))
   (CL:SETF (%N-QUEUED SELF) 0)
   (CL:SETF (%MIN-BATCH-SIZE SELF)
    (FLOOR (CL:* *NEURAL-NETWORK-BATCH-SIZE* 0.8d0)))
   (CL:SETF (%ACTIVE-NETWORKS SELF) (NEW-HASH-SET))
   (CL:SETF (%PREREQUISITES SELF) (NEW-KEY-VALUE-MAP))
   (CL:SETF (%DEPENDENTS SELF) (NEW-KEY-VALUE-MAP)) SELF))

(CL:DEFMETHOD PRIMARY-TYPE ((SELF NETWORK-PROOF-FORWARD-QUEUE))
  SGT-CHAMELEON-LOGIC-NETWORK-PROOF-FORWARD-QUEUE)

;;; (DEFCLASS NETWORK-PROOF-BACKWARD-QUEUE ...)

(CL:DEFCLASS NETWORK-PROOF-BACKWARD-QUEUE (NETWORK-PROOF-QUEUE)
  ())

(CL:DEFUN NEW-NETWORK-PROOF-BACKWARD-QUEUE ()
  (CL:LET* ((SELF NULL))
   (CL:SETQ SELF
    (CL:MAKE-INSTANCE (CL:QUOTE NETWORK-PROOF-BACKWARD-QUEUE)))
   (CL:SETF (%N-QUEUED SELF) 0)
   (CL:SETF (%MIN-BATCH-SIZE SELF)
    (FLOOR (CL:* *NEURAL-NETWORK-BATCH-SIZE* 0.8d0)))
   (CL:SETF (%ACTIVE-NETWORKS SELF) (NEW-HASH-SET))
   (CL:SETF (%PREREQUISITES SELF) (NEW-KEY-VALUE-MAP))
   (CL:SETF (%DEPENDENTS SELF) (NEW-KEY-VALUE-MAP)) SELF))

(CL:DEFMETHOD PRIMARY-TYPE ((SELF NETWORK-PROOF-BACKWARD-QUEUE))
  SGT-CHAMELEON-LOGIC-NETWORK-PROOF-BACKWARD-QUEUE)

;;; (DEFCLASS NETWORK-PROOF-UPDATE-QUEUE ...)

(CL:DEFCLASS NETWORK-PROOF-UPDATE-QUEUE (NETWORK-PROOF-QUEUE)
  ())

(CL:DEFUN NEW-NETWORK-PROOF-UPDATE-QUEUE ()
  (CL:LET* ((SELF NULL))
   (CL:SETQ SELF
    (CL:MAKE-INSTANCE (CL:QUOTE NETWORK-PROOF-UPDATE-QUEUE)))
   (CL:SETF (%N-QUEUED SELF) 0)
   (CL:SETF (%MIN-BATCH-SIZE SELF)
    (FLOOR (CL:* *NEURAL-NETWORK-BATCH-SIZE* 0.8d0)))
   (CL:SETF (%ACTIVE-NETWORKS SELF) (NEW-HASH-SET))
   (CL:SETF (%PREREQUISITES SELF) (NEW-KEY-VALUE-MAP))
   (CL:SETF (%DEPENDENTS SELF) (NEW-KEY-VALUE-MAP)) SELF))

(CL:DEFMETHOD PRIMARY-TYPE ((SELF NETWORK-PROOF-UPDATE-QUEUE))
  SGT-CHAMELEON-LOGIC-NETWORK-PROOF-UPDATE-QUEUE)

;;; (DEFUN ADD-NETWORK-PROOF-DEPENDENCY-LINK ...)

(CL:DEFUN ADD-NETWORK-PROOF-DEPENDENCY-LINK (TABLE SUBJECT OBJECT)
  (CL:LET* ((LINKS (LOOKUP TABLE SUBJECT)))
   (CL:COND
    ((CL:EQ LINKS NULL) (INSERT-AT TABLE SUBJECT (CONS OBJECT NIL)))
    ((CL:EQ LINKS NIL) (INSERT-AT TABLE SUBJECT (CONS OBJECT NIL)))
    ((CL:NOT (MEMB? LINKS OBJECT))
     (CONCATENATE LINKS (CONS OBJECT NIL))))))

;;; (DEFUN REMOVE-NETWORK-PROOF-DEPENDENCY-LINK ...)

(CL:DEFUN REMOVE-NETWORK-PROOF-DEPENDENCY-LINK (TABLE SUBJECT OBJECT)
  (CL:LET* ((LINKS (LOOKUP TABLE SUBJECT)))
   (CL:WHEN
    (CL:AND (CL:NOT (CL:EQ LINKS NULL)) (CL:NOT (CL:EQ LINKS NIL)))
    (CL:SETQ LINKS (REMOVE LINKS OBJECT))
    (CL:WHEN (CL:EQ LINKS NIL) (REMOVE-AT TABLE SUBJECT)))))

;;; (DEFMETHOD ADD-DEPENDENT ...)

(CL:DEFMETHOD ADD-DEPENDENT ((QUEUE NETWORK-PROOF-QUEUE) PREREQUISITE DEPENDENT)
  (ADD-NETWORK-PROOF-DEPENDENCY-LINK (%DEPENDENTS QUEUE) PREREQUISITE
   DEPENDENT)
  (ADD-NETWORK-PROOF-DEPENDENCY-LINK (%PREREQUISITES QUEUE) DEPENDENT
   PREREQUISITE))

;;; (DEFMETHOD REMOVE-DEPENDENT ...)

(CL:DEFMETHOD REMOVE-DEPENDENT ((QUEUE NETWORK-PROOF-QUEUE) PREREQUISITE DEPENDENT)
  (REMOVE-NETWORK-PROOF-DEPENDENCY-LINK (%DEPENDENTS QUEUE)
   PREREQUISITE DEPENDENT)
  (REMOVE-NETWORK-PROOF-DEPENDENCY-LINK (%PREREQUISITES QUEUE)
   DEPENDENT PREREQUISITE))

;;; (DEFMETHOD (GET-DEPENDENTS (CONS OF JUSTIFICATION)) ...)

(CL:DEFMETHOD GET-DEPENDENTS ((QUEUE NETWORK-PROOF-QUEUE) PREREQUISITE)
  (CL:LET* ((TEMP-000 (LOOKUP (%DEPENDENTS QUEUE) PREREQUISITE)))
   (CL:LET*
    ((VALUE-000 (CL:IF (CL:NOT (CL:EQ TEMP-000 NULL)) TEMP-000 NIL)))
    VALUE-000)))

;;; (DEFMETHOD (HAS-DEPENDENT? BOOLEAN) ...)

(CL:DEFMETHOD HAS-DEPENDENT? ((QUEUE NETWORK-PROOF-QUEUE) PREREQUISITE DEPENDENT)
  (MEMB? (GET-DEPENDENTS QUEUE PREREQUISITE) DEPENDENT))

;;; (DEFMETHOD (GET-PREREQUISITES (CONS OF JUSTIFICATION)) ...)

(CL:DEFMETHOD GET-PREREQUISITES ((QUEUE NETWORK-PROOF-QUEUE) DEPENDENT)
  (CL:LET* ((TEMP-000 (LOOKUP (%PREREQUISITES QUEUE) DEPENDENT)))
   (CL:LET*
    ((VALUE-000 (CL:IF (CL:NOT (CL:EQ TEMP-000 NULL)) TEMP-000 NIL)))
    VALUE-000)))

;;; (DEFMETHOD (HAS-PREREQUISITE? BOOLEAN) ...)

(CL:DEFMETHOD HAS-PREREQUISITE? ((QUEUE NETWORK-PROOF-QUEUE) DEPENDENT PREREQUISITE)
  (MEMB? (GET-PREREQUISITES QUEUE DEPENDENT) PREREQUISITE))

;;; (DEFMETHOD BATCH-PROCESS-CACHED-NETWORK-PROOF ...)

(CL:DEFMETHOD BATCH-PROCESS-CACHED-NETWORK-PROOF ((QUEUE NETWORK-PROOF-QUEUE) PROOF)
  (CL:SETQ PROOF PROOF)
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "batch-process-cached-network-proof: not implemented on: `" QUEUE
    "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD QUEUE-NETWORK-OPERATION ...)

(CL:DEFMETHOD QUEUE-NETWORK-OPERATION ((QUEUE NETWORK-PROOF-QUEUE) PROOF)
  (CL:SETQ PROOF PROOF)
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "queue-network-operation: not implemented on: `" QUEUE "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD EXECUTE-NETWORK-OPERATION ...)

(CL:DEFMETHOD EXECUTE-NETWORK-OPERATION ((QUEUE NETWORK-PROOF-QUEUE) NET FORCE?)
  (CL:PROGN (CL:SETQ NET NET) (CL:SETQ FORCE? FORCE?))
  (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
   (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000)
    "execute-network-operation: not implemented on: `" QUEUE "'")
   (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))

;;; (DEFMETHOD BATCH-PROCESS-CACHED-NETWORK-PROOF ...)

(CL:DEFMETHOD BATCH-PROCESS-CACHED-NETWORK-PROOF ((QUEUE NETWORK-PROOF-FORWARD-QUEUE) PROOF)
  "Compute the same partial match score as the call to `compute-partial-truth'
that generated `proof' (which is assumed to have been compacted with a call to
`compact-partial-proof-to-network-proof'.  The score will only be identical of course, if
the various networks and their weights have not yet been updated during learning."
  (CL:LET* ((TEST-VALUE-000 (%INFERENCE-RULE PROOF)))
   (CL:COND
    ((CL:EQ TEST-VALUE-000 KWD-CHAMELEON-PRIMITIVE-STRATEGY)
     (CL:LET* ((DEP NULL) (ITER-000 (GET-DEPENDENTS QUEUE PROOF)))
      (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-000 NIL)) DO
       (CL:SETQ DEP (%%VALUE ITER-000))
       (NOTIFY-OF-COMPLETION QUEUE DEP PROOF)
       (CL:SETQ ITER-000 (%%REST ITER-000)))))
    ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-AND-INTRODUCTION)
      (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-OR-INTRODUCTION))
     (CL:LET* ((NET (GET-JUSTIFICATION-NEURAL-NETWORK PROOF)))
      (CL:LET* ((ANT NULL) (ITER-001 (%ANTECEDENTS PROOF)))
       (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-001 NIL)) DO
        (CL:SETQ ANT (%%VALUE ITER-001))
        (CL:WHEN
         (CL:NOT (IGNORED-VALUE-ARGUMENT? NET (%PROPOSITION ANT)))
         (ADD-DEPENDENT QUEUE ANT PROOF))
        (CL:SETQ ITER-001 (%%REST ITER-001))))
      (CL:LET* ((ANT NULL) (ITER-002 (%ANTECEDENTS PROOF)))
       (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-002 NIL)) DO
        (CL:SETQ ANT (%%VALUE ITER-002))
        (CL:WHEN
         (CL:NOT (IGNORED-VALUE-ARGUMENT? NET (%PROPOSITION ANT)))
         (BATCH-PROCESS-CACHED-NETWORK-PROOF QUEUE ANT))
        (CL:SETQ ITER-002 (%%REST ITER-002))))))
    ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-MULTIPLE-PROOFS)
      (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-DISPROOF)
      (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-GOAL-COMPLEMENT))
     (CL:LET* ((ANT NULL) (ITER-003 (%ANTECEDENTS PROOF)))
      (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-003 NIL)) DO
       (CL:SETQ ANT (%%VALUE ITER-003)) (ADD-DEPENDENT QUEUE ANT PROOF)
       (CL:SETQ ITER-003 (%%REST ITER-003))))
     (CL:LET* ((ANT NULL) (ITER-004 (%ANTECEDENTS PROOF)))
      (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-004 NIL)) DO
       (CL:SETQ ANT (%%VALUE ITER-004))
       (BATCH-PROCESS-CACHED-NETWORK-PROOF QUEUE ANT)
       (CL:SETQ ITER-004 (%%REST ITER-004)))))
    (CL:T
     (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
      (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" TEST-VALUE-000
       "' is not a valid case option")
      (CL:ERROR
       (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))))

;;; (DEFMETHOD NOTIFY-OF-COMPLETION ...)

(CL:DEFMETHOD NOTIFY-OF-COMPLETION ((QUEUE NETWORK-PROOF-QUEUE) PROOF PREREQUISITE)
  "Notify `proof' that one of its `prerequisite's had its computation completed."
  (REMOVE-DEPENDENT QUEUE PREREQUISITE PROOF)
  (CL:WHEN (CL:EQ (GET-PREREQUISITES QUEUE PROOF) NIL)
   (QUEUE-NETWORK-OPERATION QUEUE PROOF)))

;;; (DEFMETHOD QUEUE-INPUT-VALUES ...)

(CL:DEFMETHOD QUEUE-INPUT-VALUES ((QUEUE NETWORK-PROOF-QUEUE) NET PROOF INPUTS VECTORSPECS)
  "Queue `inputs' in `net's input batch.  Execute the current batch if we are full."
  (INSERT (%ACTIVE-NETWORKS QUEUE) NET)
  (CL:LOOP WHILE (BATCH-IS-FULL? NET) DO
   (EXECUTE-NETWORK-OPERATION QUEUE NET CL:T))
  (PUSH-INPUT-VALUES NET PROOF INPUTS)
  (CL:WHEN (CL:NOT (CL:EQ VECTORSPECS NULL))
   (PUSH-VECTOR-INPUT-VALUES NET VECTORSPECS))
  (CL:SETF (%N-QUEUED QUEUE) (CL:1+ (%N-QUEUED QUEUE))))

;;; (DEFMETHOD QUEUE-NETWORK-OPERATION ...)

(CL:DEFMETHOD QUEUE-NETWORK-OPERATION ((QUEUE NETWORK-PROOF-FORWARD-QUEUE) PROOF)
  (CL:LET* ((SCORE 0.0d0)) (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT SCORE))
   (CL:LET* ((TEST-VALUE-000 (%INFERENCE-RULE PROOF)))
    (CL:COND
     ((CL:EQ TEST-VALUE-000 KWD-CHAMELEON-PRIMITIVE-STRATEGY)
      (CL:ERROR
       (NEW-STELLA-EXCEPTION
        "INTERNAL ERROR: unexpected justification type in batch forward computation")))
     ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-AND-INTRODUCTION)
       (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-OR-INTRODUCTION))
      (CL:LET*
       ((NET (GET-JUSTIFICATION-NEURAL-NETWORK PROOF))
        (INPUTS (NEW-VECTOR (NUMBER-OF-INPUTS NET)))
        (VECTORARGS
         (CL:IF (HAS-VECTOR-ARGUMENTS? NET)
          (NEW-VECTOR (NUMBER-OF-VECTOR-ARGUMENTS NET NULL)) NULL))
        (INDEX -1))
       (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX))
       (CL:LET* ((ANT NULL) (ITER-000 (%ANTECEDENTS PROOF)))
        (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-000 NIL)) DO
         (CL:SETQ ANT (%%VALUE ITER-000))
         (CL:SETQ INDEX
          (TRUTH-VALUE-ARGUMENT-INDEX NET (%PROPOSITION ANT)))
         (CL:WHEN (CL:>= INDEX 0) (CL:SETQ SCORE (%MATCH-SCORE ANT))
          (CL:LET
           ((SELF (%THE-ARRAY INPUTS)) (VALUE (WRAP-FLOAT SCORE))
            (POSITION INDEX))
           (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
            (CL:TYPE CL:FIXNUM POSITION))
           (CL:SETF (CL:AREF SELF POSITION) VALUE)))
         (CL:WHEN (CL:NOT (CL:EQ VECTORARGS NULL))
          (CL:SETQ INDEX
           (VECTOR-ARGUMENT-INDEX NET (%PROPOSITION ANT)))
          (CL:WHEN (CL:>= INDEX 0)
           (CL:LET
            ((SELF (%THE-ARRAY VECTORARGS))
             (VALUE (GET-VECTOR-ARGUMENT-SPEC NET ANT))
             (POSITION INDEX))
            (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
             (CL:TYPE CL:FIXNUM POSITION))
            (CL:SETF (CL:AREF SELF POSITION) VALUE))))
         (CL:SETQ ITER-000 (%%REST ITER-000))))
       (QUEUE-INPUT-VALUES QUEUE NET PROOF INPUTS VECTORARGS)))
     ((CL:EQ TEST-VALUE-000 KWD-CHAMELEON-MULTIPLE-PROOFS)
      (CL:LET* ((VALUE-000 NIL))
       (CL:LET*
        ((ANT NULL) (ITER-001 (%ANTECEDENTS PROOF)) (COLLECT-000 NULL))
        (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-001 NIL)) DO
         (CL:SETQ ANT (%%VALUE ITER-001))
         (CL:IF (CL:EQ COLLECT-000 NULL)
          (CL:PROGN
           (CL:SETQ COLLECT-000
            (CONS (WRAP-FLOAT (%MATCH-SCORE ANT)) NIL))
           (CL:IF (CL:EQ VALUE-000 NIL) (CL:SETQ VALUE-000 COLLECT-000)
            (ADD-CONS-TO-END-OF-CONS-LIST VALUE-000 COLLECT-000)))
          (CL:PROGN
           (CL:SETF (%%REST COLLECT-000)
            (CONS (WRAP-FLOAT (%MATCH-SCORE ANT)) NIL))
           (CL:SETQ COLLECT-000 (%%REST COLLECT-000))))
         (CL:SETQ ITER-001 (%%REST ITER-001))))
       (CL:SETQ SCORE (COMBINE-MULTIPLE-MATCH-SCORES VALUE-000)))
      (CL:SETF (%MATCH-SCORE PROOF) SCORE)
      (CL:LET* ((DEP NULL) (ITER-002 (GET-DEPENDENTS QUEUE PROOF)))
       (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-002 NIL)) DO
        (CL:SETQ DEP (%%VALUE ITER-002))
        (NOTIFY-OF-COMPLETION QUEUE DEP PROOF)
        (CL:SETQ ITER-002 (%%REST ITER-002)))))
     ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-DISPROOF)
       (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-GOAL-COMPLEMENT))
      (CL:SETQ SCORE
       (INVERT-CHAMELEON-MATCH-SCORE
        (%MATCH-SCORE (%%VALUE (%ANTECEDENTS PROOF)))))
      (CL:SETF (%MATCH-SCORE PROOF) SCORE)
      (CL:LET* ((DEP NULL) (ITER-003 (GET-DEPENDENTS QUEUE PROOF)))
       (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-003 NIL)) DO
        (CL:SETQ DEP (%%VALUE ITER-003))
        (NOTIFY-OF-COMPLETION QUEUE DEP PROOF)
        (CL:SETQ ITER-003 (%%REST ITER-003)))))
     (CL:T
      (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
       (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" TEST-VALUE-000
        "' is not a valid case option")
       (CL:ERROR
        (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))))))

;;; (DEFMETHOD EXECUTE-NETWORK-OPERATION ...)

(CL:DEFMETHOD EXECUTE-NETWORK-OPERATION ((QUEUE NETWORK-PROOF-FORWARD-QUEUE) NET FORCE?)
  (CL:LET* ((BATCHSIZE (CURRENT-BATCH-SIZE NET)))
   (CL:DECLARE (CL:TYPE CL:FIXNUM BATCHSIZE))
   (CL:WHEN
    (CL:AND (CL:> BATCHSIZE 0)
     (CL:OR FORCE? (CL:>= BATCHSIZE (%MIN-BATCH-SIZE QUEUE))))
    (CL:LET*
     ((OUTPUT 0.0d0) (PROOF NULL)
      (SCOREDPROOFS (NEW-VECTOR-SEQUENCE BATCHSIZE)))
     (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT OUTPUT))
     (BATCH-FORWARD-PROPAGATE-INPUTS NET)
     (CL:LET*
      ((I NULL-INTEGER) (ITER-000 0)
       (UPPER-BOUND-000 (CL:1- BATCHSIZE)))
      (CL:DECLARE (CL:TYPE CL:FIXNUM I ITER-000 UPPER-BOUND-000))
      (CL:LOOP WHILE (CL:<= ITER-000 UPPER-BOUND-000) DO
       (CL:SETQ I ITER-000) (CL:SETQ OUTPUT (NTH-BATCH-OUTPUT NET I))
       (CL:SETQ PROOF (NTH-BATCH-KEY NET I))
       (CL:SETF (%MATCH-SCORE PROOF) OUTPUT)
       (INSERT SCOREDPROOFS PROOF)
       (CL:SETQ ITER-000 (CL:1+ ITER-000))))
     (CL:SETF (%N-QUEUED QUEUE) (CL:- (%N-QUEUED QUEUE) BATCHSIZE))
     (CLEAR-BATCH-ARRAYS NET)
     (CL:LET*
      ((PROOF NULL) (VECTOR-000 SCOREDPROOFS) (INDEX-000 0)
       (LENGTH-000 (%SEQUENCE-LENGTH VECTOR-000)))
      (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX-000 LENGTH-000))
      (CL:LOOP WHILE (CL:< INDEX-000 LENGTH-000) DO
       (CL:SETQ PROOF
        (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY VECTOR-000))
         INDEX-000))
       (CL:LET* ((DEP NULL) (ITER-001 (GET-DEPENDENTS QUEUE PROOF)))
        (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-001 NIL)) DO
         (CL:SETQ DEP (%%VALUE ITER-001))
         (NOTIFY-OF-COMPLETION QUEUE DEP PROOF)
         (CL:SETQ ITER-001 (%%REST ITER-001))))
       (CL:SETQ INDEX-000 (CL:1+ INDEX-000))))))))

;;; (DEFMETHOD EXECUTE-ALL ...)

(CL:DEFMETHOD EXECUTE-ALL ((QUEUE NETWORK-PROOF-QUEUE))
  "Execute queued ops in `queue' until there is nothing more to do."
  (CL:LET*
   ((LOWWATERMARK
     (CL:* (LENGTH (%ACTIVE-NETWORKS QUEUE)) (%MIN-BATCH-SIZE QUEUE))))
   (CL:DECLARE (CL:TYPE CL:FIXNUM LOWWATERMARK))
   (CL:LOOP WHILE (CL:> (%N-QUEUED QUEUE) 0) DO
    (CL:LET*
     ((NET NULL)
      (ITER-000 (ALLOCATE-ITERATOR (%ACTIVE-NETWORKS QUEUE))))
     (CL:LOOP WHILE (NEXT? ITER-000) DO (CL:SETQ NET (%VALUE ITER-000))
      (EXECUTE-NETWORK-OPERATION QUEUE NET
       (<= (%N-QUEUED QUEUE) LOWWATERMARK)))))))

;;; (DEFMETHOD BATCH-PROCESS-CACHED-NETWORK-PROOF ...)

(CL:DEFMETHOD BATCH-PROCESS-CACHED-NETWORK-PROOF ((QUEUE NETWORK-PROOF-BACKWARD-QUEUE) PROOF)
  "Queue and process operations for `update-network-weights' for `proof'."
  (CL:LET* ((TEST-VALUE-000 (%INFERENCE-RULE PROOF)))
   (CL:COND
    ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-AND-INTRODUCTION)
      (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-OR-INTRODUCTION))
     (CL:LET* ((NET (GET-JUSTIFICATION-NEURAL-NETWORK PROOF)))
      (CL:LET* ((ANT NULL) (ITER-000 (%ANTECEDENTS PROOF)))
       (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-000 NIL)) DO
        (CL:SETQ ANT (%%VALUE ITER-000))
        (CL:WHEN
         (CL:AND
          (CL:NOT
           (CL:EQ (%INFERENCE-RULE ANT)
            KWD-CHAMELEON-PRIMITIVE-STRATEGY))
          (CL:NOT (IGNORED-VALUE-ARGUMENT? NET (%PROPOSITION ANT))))
         (ADD-DEPENDENT QUEUE PROOF ANT))
        (CL:SETQ ITER-000 (%%REST ITER-000))))
      (CL:WHEN (CL:EQ (GET-PREREQUISITES QUEUE PROOF) NIL)
       (QUEUE-NETWORK-OPERATION QUEUE PROOF))
      (CL:LET* ((ANT NULL) (ITER-001 (%ANTECEDENTS PROOF)))
       (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-001 NIL)) DO
        (CL:SETQ ANT (%%VALUE ITER-001))
        (CL:WHEN
         (CL:AND
          (CL:NOT
           (CL:EQ (%INFERENCE-RULE ANT)
            KWD-CHAMELEON-PRIMITIVE-STRATEGY))
          (CL:NOT (IGNORED-VALUE-ARGUMENT? NET (%PROPOSITION ANT))))
         (BATCH-PROCESS-CACHED-NETWORK-PROOF QUEUE ANT))
        (CL:SETQ ITER-001 (%%REST ITER-001))))))
    ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-MULTIPLE-PROOFS)
      (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-DISPROOF)
      (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-GOAL-COMPLEMENT))
     (CL:LET* ((ANT NULL) (ITER-002 (%ANTECEDENTS PROOF)))
      (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-002 NIL)) DO
       (CL:SETQ ANT (%%VALUE ITER-002))
       (CL:WHEN
        (CL:NOT
         (CL:EQ (%INFERENCE-RULE ANT)
          KWD-CHAMELEON-PRIMITIVE-STRATEGY))
        (ADD-DEPENDENT QUEUE PROOF ANT))
       (CL:SETQ ITER-002 (%%REST ITER-002))))
     (CL:WHEN (CL:EQ (GET-PREREQUISITES QUEUE PROOF) NIL)
      (QUEUE-NETWORK-OPERATION QUEUE PROOF))
     (CL:LET* ((ANT NULL) (ITER-003 (%ANTECEDENTS PROOF)))
      (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-003 NIL)) DO
       (CL:SETQ ANT (%%VALUE ITER-003))
       (CL:WHEN
        (CL:NOT
         (CL:EQ (%INFERENCE-RULE ANT)
          KWD-CHAMELEON-PRIMITIVE-STRATEGY))
        (BATCH-PROCESS-CACHED-NETWORK-PROOF QUEUE ANT))
       (CL:SETQ ITER-003 (%%REST ITER-003)))))
    ((CL:EQ TEST-VALUE-000 KWD-CHAMELEON-PRIMITIVE-STRATEGY))
    (CL:T
     (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
      (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" TEST-VALUE-000
       "' is not a valid case option")
      (CL:ERROR
       (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))))

;;; (DEFMETHOD QUEUE-NETWORK-OPERATION ...)

(CL:DEFMETHOD QUEUE-NETWORK-OPERATION ((QUEUE NETWORK-PROOF-BACKWARD-QUEUE) PROOF)
  (CL:LET* ((SCORE 0.0d0) (ERROR (%ERROR-SCORE PROOF)))
   (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT SCORE ERROR))
   (CL:LET* ((TEST-VALUE-000 (%INFERENCE-RULE PROOF)))
    (CL:COND
     ((CL:EQ TEST-VALUE-000 KWD-CHAMELEON-PRIMITIVE-STRATEGY)
      (CL:ERROR
       (NEW-STELLA-EXCEPTION
        "INTERNAL ERROR: unexpected justification type in batch backward computation")))
     ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-AND-INTRODUCTION)
       (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-OR-INTRODUCTION))
      (CL:LET*
       ((NET (GET-JUSTIFICATION-NEURAL-NETWORK PROOF))
        (INPUTS (NEW-VECTOR (NUMBER-OF-INPUTS NET)))
        (VECTORARGS
         (CL:IF (HAS-VECTOR-ARGUMENTS? NET)
          (NEW-VECTOR (NUMBER-OF-VECTOR-ARGUMENTS NET NULL)) NULL))
        (INDEX -1))
       (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX))
       (CL:LET* ((ANT NULL) (ITER-000 (%ANTECEDENTS PROOF)))
        (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-000 NIL)) DO
         (CL:SETQ ANT (%%VALUE ITER-000))
         (CL:SETQ INDEX
          (TRUTH-VALUE-ARGUMENT-INDEX NET (%PROPOSITION ANT)))
         (CL:WHEN (CL:>= INDEX 0) (CL:SETQ SCORE (%MATCH-SCORE ANT))
          (CL:LET
           ((SELF (%THE-ARRAY INPUTS)) (VALUE (WRAP-FLOAT SCORE))
            (POSITION INDEX))
           (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
            (CL:TYPE CL:FIXNUM POSITION))
           (CL:SETF (CL:AREF SELF POSITION) VALUE)))
         (CL:WHEN (CL:NOT (CL:EQ VECTORARGS NULL))
          (CL:SETQ INDEX
           (VECTOR-ARGUMENT-INDEX NET (%PROPOSITION ANT)))
          (CL:WHEN (CL:>= INDEX 0)
           (CL:LET
            ((SELF (%THE-ARRAY VECTORARGS))
             (VALUE (GET-VECTOR-ARGUMENT-SPEC NET ANT))
             (POSITION INDEX))
            (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
             (CL:TYPE CL:FIXNUM POSITION))
            (CL:SETF (CL:AREF SELF POSITION) VALUE))))
         (CL:SETQ ITER-000 (%%REST ITER-000))))
       (CL:SETQ SCORE (%MATCH-SCORE PROOF))
       (QUEUE-INPUT-VALUES QUEUE NET PROOF INPUTS VECTORARGS)
       (PUSH-TARGET-VALUE NET (CL:+ SCORE ERROR))))
     ((CL:EQ TEST-VALUE-000 KWD-CHAMELEON-MULTIPLE-PROOFS)
      (CL:LET* ((ANT NULL) (ITER-001 (%ANTECEDENTS PROOF)))
       (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-001 NIL)) DO
        (CL:SETQ ANT (%%VALUE ITER-001))
        (CL:COND
         ((CL:EQ *RULE-COMBINATION* KWD-CHAMELEON-MAX)
          (CL:SETF (%ERROR-SCORE ANT) ERROR))
         ((CL:EQ *RULE-COMBINATION* KWD-CHAMELEON-NOISY-OR)
          (CL:SETF (%ERROR-SCORE ANT) (CL:* ERROR (%MATCH-SCORE ANT))))
         (CL:T
          (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
           (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`"
            *RULE-COMBINATION* "' is not a valid case option")
           (CL:ERROR
            (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))
        (REMOVE-DEPENDENT QUEUE PROOF ANT)
        (CL:SETQ ITER-001 (%%REST ITER-001)))))
     ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-DISPROOF)
       (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-GOAL-COMPLEMENT))
      (CL:SETF (%ERROR-SCORE (%%VALUE (%ANTECEDENTS PROOF))) ERROR)
      (REMOVE-DEPENDENT QUEUE PROOF (%%VALUE (%ANTECEDENTS PROOF))))
     (CL:T
      (CL:LET* ((STREAM-001 (NEW-OUTPUT-STRING-STREAM)))
       (%%PRINT-STREAM (%NATIVE-STREAM STREAM-001) "`" TEST-VALUE-000
        "' is not a valid case option")
       (CL:ERROR
        (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-001)))))))))

;;; (DEFMETHOD EXECUTE-NETWORK-OPERATION ...)

(CL:DEFMETHOD EXECUTE-NETWORK-OPERATION ((QUEUE NETWORK-PROOF-BACKWARD-QUEUE) NET FORCE?)
  (CL:LET* ((BATCHSIZE (CURRENT-BATCH-SIZE NET)))
   (CL:DECLARE (CL:TYPE CL:FIXNUM BATCHSIZE))
   (CL:WHEN
    (CL:AND (CL:> BATCHSIZE 0)
     (CL:OR FORCE? (CL:>= BATCHSIZE (%MIN-BATCH-SIZE QUEUE))))
    (CL:LET*
     ((ERROR 0.0d0) (INDEX -1) (PROOF NULL)
      (PROCESSEDPROOFS (NEW-VECTOR-SEQUENCE BATCHSIZE)))
     (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT ERROR)
      (CL:TYPE CL:FIXNUM INDEX))
     (BATCH-BACKWARD-PROPAGATE-ERROR NET)
     (CL:LET*
      ((I NULL-INTEGER) (ITER-000 0)
       (UPPER-BOUND-000 (CL:1- BATCHSIZE)))
      (CL:DECLARE (CL:TYPE CL:FIXNUM I ITER-000 UPPER-BOUND-000))
      (CL:LOOP WHILE (CL:<= ITER-000 UPPER-BOUND-000) DO
       (CL:SETQ I ITER-000) (CL:SETQ PROOF (NTH-BATCH-KEY NET I))
       (INSERT PROCESSEDPROOFS PROOF)
       (CL:LET* ((ANT NULL) (ITER-001 (%ANTECEDENTS PROOF)))
        (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-001 NIL)) DO
         (CL:SETQ ANT (%%VALUE ITER-001))
         (CL:WHEN
          (CL:NOT
           (CL:EQ (%INFERENCE-RULE ANT)
            KWD-CHAMELEON-PRIMITIVE-STRATEGY))
          (CL:SETQ INDEX
           (TRUTH-VALUE-ARGUMENT-INDEX NET (%PROPOSITION ANT)))
          (CL:WHEN (CL:>= INDEX 0)
           (CL:SETQ ERROR (NTH-KTH-BATCH-INPUT-ERROR NET I INDEX))
           (CL:SETF (%ERROR-SCORE ANT) ERROR)))
         (CL:SETQ ITER-001 (%%REST ITER-001))))
       (CL:SETQ ITER-000 (CL:1+ ITER-000))))
     (CL:SETF (%N-QUEUED QUEUE) (CL:- (%N-QUEUED QUEUE) BATCHSIZE))
     (CLEAR-BATCH-ARRAYS NET)
     (CL:LET*
      ((PROOF NULL) (VECTOR-000 PROCESSEDPROOFS) (INDEX-000 0)
       (LENGTH-000 (%SEQUENCE-LENGTH VECTOR-000)))
      (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX-000 LENGTH-000))
      (CL:LOOP WHILE (CL:< INDEX-000 LENGTH-000) DO
       (CL:SETQ PROOF
        (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY VECTOR-000))
         INDEX-000))
       (CL:LET* ((DEP NULL) (ITER-002 (GET-DEPENDENTS QUEUE PROOF)))
        (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-002 NIL)) DO
         (CL:SETQ DEP (%%VALUE ITER-002))
         (NOTIFY-OF-COMPLETION QUEUE DEP PROOF)
         (CL:SETQ ITER-002 (%%REST ITER-002))))
       (CL:SETQ INDEX-000 (CL:1+ INDEX-000))))))))

;;; (DEFMETHOD BATCH-PROCESS-CACHED-NETWORK-PROOF ...)

(CL:DEFMETHOD BATCH-PROCESS-CACHED-NETWORK-PROOF ((QUEUE NETWORK-PROOF-UPDATE-QUEUE) PROOF)
  "Queue and process operations for `update-network-weights' for `proof'."
  (CL:LET* ((TEST-VALUE-000 (%INFERENCE-RULE PROOF)))
   (CL:COND
    ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-AND-INTRODUCTION)
      (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-OR-INTRODUCTION))
     (CL:LET* ((NET (GET-JUSTIFICATION-NEURAL-NETWORK PROOF)))
      (QUEUE-NETWORK-OPERATION QUEUE PROOF)
      (CL:LET* ((ANT NULL) (ITER-000 (%ANTECEDENTS PROOF)))
       (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-000 NIL)) DO
        (CL:SETQ ANT (%%VALUE ITER-000))
        (CL:WHEN
         (CL:AND
          (CL:NOT
           (CL:EQ (%INFERENCE-RULE ANT)
            KWD-CHAMELEON-PRIMITIVE-STRATEGY))
          (CL:NOT (IGNORED-VALUE-ARGUMENT? NET (%PROPOSITION ANT))))
         (BATCH-PROCESS-CACHED-NETWORK-PROOF QUEUE ANT))
        (CL:SETQ ITER-000 (%%REST ITER-000))))))
    ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-MULTIPLE-PROOFS)
      (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-DISPROOF)
      (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-GOAL-COMPLEMENT))
     (CL:LET* ((ANT NULL) (ITER-001 (%ANTECEDENTS PROOF)))
      (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-001 NIL)) DO
       (CL:SETQ ANT (%%VALUE ITER-001))
       (CL:WHEN
        (CL:NOT
         (CL:EQ (%INFERENCE-RULE ANT)
          KWD-CHAMELEON-PRIMITIVE-STRATEGY))
        (BATCH-PROCESS-CACHED-NETWORK-PROOF QUEUE ANT))
       (CL:SETQ ITER-001 (%%REST ITER-001)))))
    ((CL:EQ TEST-VALUE-000 KWD-CHAMELEON-PRIMITIVE-STRATEGY))
    (CL:T
     (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
      (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" TEST-VALUE-000
       "' is not a valid case option")
      (CL:ERROR
       (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))))

;;; (DEFMETHOD QUEUE-NETWORK-OPERATION ...)

(CL:DEFMETHOD QUEUE-NETWORK-OPERATION ((QUEUE NETWORK-PROOF-UPDATE-QUEUE) PROOF)
  (CL:LET* ((SCORE 0.0d0) (ERROR (%ERROR-SCORE PROOF)))
   (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT SCORE ERROR))
   (CL:LET* ((TEST-VALUE-000 (%INFERENCE-RULE PROOF)))
    (CL:COND
     ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-PRIMITIVE-STRATEGY)
       (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-MULTIPLE-PROOFS)
       (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-DISPROOF)
       (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-GOAL-COMPLEMENT))
      (CL:ERROR
       (NEW-STELLA-EXCEPTION
        "INTERNAL ERROR: unexpected justification type in batch update computation")))
     ((CL:OR (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-AND-INTRODUCTION)
       (CL:EQ TEST-VALUE-000 KWD-CHAMELEON-OR-INTRODUCTION))
      (CL:LET*
       ((NET (GET-JUSTIFICATION-NEURAL-NETWORK PROOF))
        (INPUTS (NEW-VECTOR (NUMBER-OF-INPUTS NET)))
        (VECTORARGS
         (CL:IF (HAS-VECTOR-ARGUMENTS? NET)
          (NEW-VECTOR (NUMBER-OF-VECTOR-ARGUMENTS NET NULL)) NULL))
        (INDEX -1))
       (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX))
       (CL:LET* ((ANT NULL) (ITER-000 (%ANTECEDENTS PROOF)))
        (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-000 NIL)) DO
         (CL:SETQ ANT (%%VALUE ITER-000))
         (CL:SETQ INDEX
          (TRUTH-VALUE-ARGUMENT-INDEX NET (%PROPOSITION ANT)))
         (CL:WHEN (CL:>= INDEX 0) (CL:SETQ SCORE (%MATCH-SCORE ANT))
          (CL:LET
           ((SELF (%THE-ARRAY INPUTS)) (VALUE (WRAP-FLOAT SCORE))
            (POSITION INDEX))
           (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
            (CL:TYPE CL:FIXNUM POSITION))
           (CL:SETF (CL:AREF SELF POSITION) VALUE)))
         (CL:WHEN (CL:NOT (CL:EQ VECTORARGS NULL))
          (CL:SETQ INDEX
           (VECTOR-ARGUMENT-INDEX NET (%PROPOSITION ANT)))
          (CL:WHEN (CL:>= INDEX 0)
           (CL:LET
            ((SELF (%THE-ARRAY VECTORARGS))
             (VALUE (GET-VECTOR-ARGUMENT-SPEC NET ANT))
             (POSITION INDEX))
            (CL:DECLARE (CL:TYPE CL:SIMPLE-VECTOR SELF)
             (CL:TYPE CL:FIXNUM POSITION))
            (CL:SETF (CL:AREF SELF POSITION) VALUE))))
         (CL:SETQ ITER-000 (%%REST ITER-000))))
       (CL:SETQ SCORE (%MATCH-SCORE PROOF))
       (QUEUE-INPUT-VALUES QUEUE NET PROOF INPUTS VECTORARGS)
       (PUSH-TARGET-VALUE NET (CL:+ SCORE ERROR))))
     (CL:T
      (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
       (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" TEST-VALUE-000
        "' is not a valid case option")
       (CL:ERROR
        (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000)))))))))

;;; (DEFMETHOD EXECUTE-NETWORK-OPERATION ...)

(CL:DEFMETHOD EXECUTE-NETWORK-OPERATION ((QUEUE NETWORK-PROOF-UPDATE-QUEUE) NET FORCE?)
  (CL:LET* ((BATCHSIZE (CURRENT-BATCH-SIZE NET)))
   (CL:DECLARE (CL:TYPE CL:FIXNUM BATCHSIZE))
   (CL:WHEN
    (CL:AND (CL:> BATCHSIZE 0)
     (CL:OR FORCE? (CL:>= BATCHSIZE (%MIN-BATCH-SIZE QUEUE))))
    (BATCH-UPDATE-NETWORK-WEIGHTS NET)
    (CL:SETF (%N-QUEUED QUEUE) (CL:- (%N-QUEUED QUEUE) BATCHSIZE))
    (CLEAR-BATCH-ARRAYS NET))))

;;; (DEFUN (RETRIEVE-TRAINING-EXAMPLES (LIST OF TRAINING-EXAMPLE)) ...)

(CL:DEFUN %RETRIEVE-TRAINING-EXAMPLES (OPTIONS)
  "Retrieve a subset of current training examples defined via `cham/training-example'."
  (CL:LET*
   ((THEOPTIONS
     (PARSE-OPTIONS OPTIONS
      (LIST* KWD-CHAMELEON-MODULE SGT-CHAMELEON-STELLA-MODULE
       KWD-CHAMELEON-LOCAL? SGT-CHAMELEON-STELLA-BOOLEAN
       KWD-CHAMELEON-N-TRAIN SGT-CHAMELEON-STELLA-INTEGER NIL)
      CL:T CL:T))
    (THEMODULE
     (LOOKUP-WITH-DEFAULT THEOPTIONS KWD-CHAMELEON-MODULE *MODULE*))
    (NUMTRAINING
     (%WRAPPER-VALUE
      (LOOKUP-WITH-DEFAULT THEOPTIONS KWD-CHAMELEON-N-TRAIN
       (WRAP-INTEGER MOST-POSITIVE-INTEGER))))
    (EXAMPLE NULL) (EXAMPLES (NEW-LIST)))
   (CL:DECLARE (CL:TYPE CL:FIXNUM NUMTRAINING))
   (CL:LET* ((*MODULE* THEMODULE) (*CONTEXT* *MODULE*))
    (CL:DECLARE (CL:SPECIAL *MODULE* *CONTEXT*))
    (CL:LET*
     ((SOLUTION NULL)
      (ITER-000
       (ALLOCATE-ITERATOR
        (%SOLUTIONS
         (CALL-RETRIEVE
          (CONS (WRAP-INTEGER NUMTRAINING)
           (CONS
            (LIST* SYM-CHAMELEON-CHAMELEON-TRAINING-EXAMPLE
             SYM-CHAMELEON-LOGIC-?P SYM-CHAMELEON-LOGIC-?S NIL)
            NIL))))))
      (COLLECT-000 NULL))
     (CL:LOOP WHILE (NEXT? ITER-000) DO
      (CL:SETQ SOLUTION (%VALUE ITER-000))
      (CL:LET* ((SELF-001 (NEW-TRAINING-EXAMPLE)))
       (CL:SETF (%QUERY SELF-001)
        (GENERATE-PROPOSITION
         (CL:AREF
          (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%BINDINGS SOLUTION)))
          0)))
       (CL:SETF (%SCORE SELF-001)
        (COERCE-TO-FLOAT
         (CL:AREF
          (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%BINDINGS SOLUTION)))
          1)))
       (CL:SETF (%MODULE SELF-001) THEMODULE)
       (CL:SETQ EXAMPLE SELF-001))
      (CL:IF (CL:EQ COLLECT-000 NULL)
       (CL:PROGN (CL:SETQ COLLECT-000 (CONS EXAMPLE NIL))
        (CL:IF (CL:EQ (%THE-CONS-LIST EXAMPLES) NIL)
         (CL:SETF (%THE-CONS-LIST EXAMPLES) COLLECT-000)
         (ADD-CONS-TO-END-OF-CONS-LIST (%THE-CONS-LIST EXAMPLES)
          COLLECT-000)))
       (CL:PROGN (CL:SETF (%%REST COLLECT-000) (CONS EXAMPLE NIL))
        (CL:SETQ COLLECT-000 (%%REST COLLECT-000))))))
    EXAMPLES)))

(CL:DEFUN RETRIEVE-TRAINING-EXAMPLES-EVALUATOR-WRAPPER (ARGUMENTS)
  (%RETRIEVE-TRAINING-EXAMPLES ARGUMENTS))

(CL:DEFMACRO RETRIEVE-TRAINING-EXAMPLES (CL:&WHOLE EXPRESSION CL:&REST IGNORE)
  "Retrieve a subset of current training examples defined via `cham/training-example'."
  (CL:DECLARE (CL:IGNORE IGNORE))
  (CL:LET ((*IGNORETRANSLATIONERRORS?* FALSE))
   (CL-INCREMENTALLY-TRANSLATE EXPRESSION)))

(CL:SETF (CL:MACRO-FUNCTION (CL:QUOTE |/LOGIC/RETRIEVE-TRAINING-EXAMPLES|)) (CL:MACRO-FUNCTION (CL:QUOTE RETRIEVE-TRAINING-EXAMPLES)))

;;; (DEFUN (SELECT-TRAINING-EXAMPLES (VECTOR OF TRAINING-EXAMPLE)) ...)

(CL:DEFUN %SELECT-TRAINING-EXAMPLES (OPTIONS)
  "Select a subset of currently defined training examples.  Currently the selection
is purely based on module and/or number.  Results will be shuffled if :shuffle? is TRUE (default)."
  (CL:LET*
   ((THEOPTIONS
     (PARSE-OPTIONS OPTIONS
      (LIST* KWD-CHAMELEON-MODULE SGT-CHAMELEON-STELLA-MODULE
       KWD-CHAMELEON-LOCAL? SGT-CHAMELEON-STELLA-BOOLEAN
       KWD-CHAMELEON-N-TRAIN SGT-CHAMELEON-STELLA-INTEGER
       KWD-CHAMELEON-SHUFFLE? SGT-CHAMELEON-STELLA-BOOLEAN NIL)
      CL:T CL:NIL))
    (TRAININGEXAMPLES
     (CONCATENATE
      (%RETRIEVE-TRAINING-EXAMPLES
       (CONS-LIST KWD-CHAMELEON-OPTIONS THEOPTIONS))
      *TRAINING-EXAMPLES*))
    (THEMODULE
     (LOOKUP-WITH-DEFAULT THEOPTIONS KWD-CHAMELEON-MODULE *MODULE*))
    (LOCAL?
     (COERCE-WRAPPED-BOOLEAN-TO-BOOLEAN
      (LOOKUP-WITH-DEFAULT THEOPTIONS KWD-CHAMELEON-LOCAL?
       FALSE-WRAPPER)))
    (NUMTRAINING
     (%WRAPPER-VALUE
      (LOOKUP-WITH-DEFAULT THEOPTIONS KWD-CHAMELEON-N-TRAIN
       (WRAP-INTEGER MOST-POSITIVE-INTEGER))))
    (SHUFFLE?
     (COERCE-WRAPPED-BOOLEAN-TO-BOOLEAN
      (LOOKUP-WITH-DEFAULT THEOPTIONS KWD-CHAMELEON-SHUFFLE?
       TRUE-WRAPPER)))
    (EXAMPLES (NEW-VECTOR-SEQUENCE 100)))
   (CL:DECLARE (CL:TYPE CL:FIXNUM NUMTRAINING))
   (CL:LET* ((EXP NULL) (ITER-000 (%THE-CONS-LIST TRAININGEXAMPLES)))
    (CL:LOOP WHILE (CL:NOT (CL:EQ ITER-000 NIL)) DO
     (CL:SETQ EXP (%%VALUE ITER-000))
     (CL:WHEN (CL:> NUMTRAINING 0)
      (CL:WHEN
       (CL:OR (CL:EQ (%MODULE EXP) NULL)
        (CL:EQ (%MODULE EXP) THEMODULE)
        (CL:AND (CL:NOT LOCAL?)
         (VISIBLE-FROM? (%MODULE EXP) THEMODULE)))
       (INSERT EXAMPLES EXP)
       (CL:SETQ NUMTRAINING (CL:1- NUMTRAINING))))
     (CL:SETQ ITER-000 (%%REST ITER-000))))
   (CL:SETF (%ARRAY-SIZE EXAMPLES) (%SEQUENCE-LENGTH EXAMPLES))
   (CL:WHEN SHUFFLE? (SHUFFLE-VECTOR EXAMPLES)) EXAMPLES))

(CL:DEFUN SELECT-TRAINING-EXAMPLES-EVALUATOR-WRAPPER (ARGUMENTS)
  (%SELECT-TRAINING-EXAMPLES ARGUMENTS))

(CL:DEFMACRO SELECT-TRAINING-EXAMPLES (CL:&WHOLE EXPRESSION CL:&REST IGNORE)
  "Select a subset of currently defined training examples.  Currently the selection
is purely based on module and/or number.  Results will be shuffled if :shuffle? is TRUE (default)."
  (CL:DECLARE (CL:IGNORE IGNORE))
  (CL:LET ((*IGNORETRANSLATIONERRORS?* FALSE))
   (CL-INCREMENTALLY-TRANSLATE EXPRESSION)))

(CL:SETF (CL:MACRO-FUNCTION (CL:QUOTE |/LOGIC/SELECT-TRAINING-EXAMPLES|)) (CL:MACRO-FUNCTION (CL:QUOTE SELECT-TRAINING-EXAMPLES)))

;;; (DEFUN (NORMALIZE-CHAMELEON-TRAINING-OPTIONS PROPERTY-LIST) ...)

(CL:DEFUN NORMALIZE-CHAMELEON-TRAINING-OPTIONS (OPTIONS)
  "Normalize and provide defaults for `options' supplied
to `train-chameleon-neural-networks'."
  (CL:LET*
   ((THEOPTIONS
     (PARSE-OPTIONS OPTIONS
      (LIST* KWD-CHAMELEON-MODULE SGT-CHAMELEON-STELLA-MODULE
       KWD-CHAMELEON-LOCAL? SGT-CHAMELEON-STELLA-BOOLEAN
       KWD-CHAMELEON-EPOCHS SGT-CHAMELEON-STELLA-INTEGER
       KWD-CHAMELEON-N-TRAIN SGT-CHAMELEON-STELLA-INTEGER
       KWD-CHAMELEON-PRINT-CYCLE SGT-CHAMELEON-STELLA-INTEGER
       KWD-CHAMELEON-ERROR-CUTOFF SGT-CHAMELEON-STELLA-FLOAT
       KWD-CHAMELEON-SHUFFLE? SGT-CHAMELEON-STELLA-BOOLEAN
       KWD-CHAMELEON-BATCH? SGT-CHAMELEON-STELLA-BOOLEAN
       KWD-CHAMELEON-EXAMPLES SGT-CHAMELEON-STELLA-OBJECT NIL)
      CL:T CL:NIL))
    (BATCHDEFAULT?
     (CL:NOT
      (CL:=
       (STRING-SEARCH-IGNORE-CASE
        (%SYMBOL-NAME *CHAMELEON-NEURAL-NETWORK-IMPLEMENTATION*)
        "-batch" 0)
       NULL-INTEGER))))
   (INSERT-AT THEOPTIONS KWD-CHAMELEON-MODULE
    (LOOKUP-WITH-DEFAULT THEOPTIONS KWD-CHAMELEON-MODULE *MODULE*))
   (INSERT-AT THEOPTIONS KWD-CHAMELEON-LOCAL?
    (LOOKUP-WITH-DEFAULT THEOPTIONS KWD-CHAMELEON-LOCAL?
     FALSE-WRAPPER))
   (INSERT-AT THEOPTIONS KWD-CHAMELEON-EPOCHS
    (LOOKUP-WITH-DEFAULT THEOPTIONS KWD-CHAMELEON-EPOCHS
     (WRAP-INTEGER 20)))
   (INSERT-AT THEOPTIONS KWD-CHAMELEON-PRINT-CYCLE
    (LOOKUP-WITH-DEFAULT THEOPTIONS KWD-CHAMELEON-PRINT-CYCLE
     (WRAP-INTEGER -1)))
   (INSERT-AT THEOPTIONS KWD-CHAMELEON-ERROR-CUTOFF
    (LOOKUP-WITH-DEFAULT THEOPTIONS KWD-CHAMELEON-ERROR-CUTOFF
     (WRAP-FLOAT *ERROR-CUTOFF*)))
   (INSERT-AT THEOPTIONS KWD-CHAMELEON-SHUFFLE?
    (LOOKUP-WITH-DEFAULT THEOPTIONS KWD-CHAMELEON-SHUFFLE?
     TRUE-WRAPPER))
   (INSERT-AT THEOPTIONS KWD-CHAMELEON-BATCH?
    (LOOKUP-WITH-DEFAULT THEOPTIONS KWD-CHAMELEON-BATCH?
     (CL:IF BATCHDEFAULT? TRUE-WRAPPER FALSE-WRAPPER)))
   (INSERT-AT THEOPTIONS KWD-CHAMELEON-EXAMPLES
    (%SELECT-TRAINING-EXAMPLES
     (CONS-LIST KWD-CHAMELEON-MODULE
      (LOOKUP THEOPTIONS KWD-CHAMELEON-MODULE) KWD-CHAMELEON-LOCAL?
      (LOOKUP THEOPTIONS KWD-CHAMELEON-LOCAL?) KWD-CHAMELEON-N-TRAIN
      (LOOKUP THEOPTIONS KWD-CHAMELEON-N-TRAIN) KWD-CHAMELEON-SHUFFLE?
      (LOOKUP THEOPTIONS KWD-CHAMELEON-SHUFFLE?))))
   (INSERT-AT THEOPTIONS KWD-CHAMELEON-N-TRAIN
    (LOOKUP-WITH-DEFAULT THEOPTIONS KWD-CHAMELEON-N-TRAIN
     (WRAP-INTEGER
      (LENGTH (LOOKUP THEOPTIONS KWD-CHAMELEON-EXAMPLES)))))
   THEOPTIONS))

;;; (DEFUN TRAIN-CHAMELEON-NEURAL-NETWORKS ...)

(CL:DEFUN %TRAIN-CHAMELEON-NEURAL-NETWORKS (OPTIONS)
  "Train rule neural networks based on :n-train (or all) training examples looked
up in :module/:local?.  Train for :epochs (defaults to 20) or until :error-cutoff is reached.
Print every :print-cycle epochs or not at all.  If :shuffle? (the default) randomly shuffle the
selected training examples before every epoch.  If :batch?, use batch training mechanism (which
will fail if the current network implementation does not support it)."
  (CL:LET*
   ((THEOPTIONS (NORMALIZE-CHAMELEON-TRAINING-OPTIONS OPTIONS))
    (EPOCHS (%WRAPPER-VALUE (LOOKUP THEOPTIONS KWD-CHAMELEON-EPOCHS)))
    (NUMTRAINING
     (%WRAPPER-VALUE (LOOKUP THEOPTIONS KWD-CHAMELEON-N-TRAIN)))
    (PRINTCYCLE
     (%WRAPPER-VALUE (LOOKUP THEOPTIONS KWD-CHAMELEON-PRINT-CYCLE)))
    (ERRORCUTOFF
     (%WRAPPER-VALUE (LOOKUP THEOPTIONS KWD-CHAMELEON-ERROR-CUTOFF)))
    (SHUFFLE?
     (COERCE-WRAPPED-BOOLEAN-TO-BOOLEAN
      (LOOKUP THEOPTIONS KWD-CHAMELEON-SHUFFLE?)))
    (BATCH?
     (COERCE-WRAPPED-BOOLEAN-TO-BOOLEAN
      (LOOKUP THEOPTIONS KWD-CHAMELEON-BATCH?)))
    (EXAMPLES (LOOKUP THEOPTIONS KWD-CHAMELEON-EXAMPLES))
    (CACHEDPROOF NULL) (BATCHQUEUE NULL) (TARGET 0.0d0) (OUTPUT 0.0d0)
    (ERROR 0.0d0) (TOTALABSERROR 0.0d0) (LOG STANDARD-OUTPUT))
   (CL:DECLARE (CL:TYPE CL:FIXNUM EPOCHS NUMTRAINING PRINTCYCLE)
    (CL:TYPE CL:DOUBLE-FLOAT ERRORCUTOFF TARGET OUTPUT ERROR
     TOTALABSERROR))
   (CL:LET*
    ((EXP NULL) (VECTOR-000 EXAMPLES) (INDEX-000 0)
     (LENGTH-000 (LENGTH VECTOR-000)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX-000 LENGTH-000))
    (CL:LOOP WHILE (CL:< INDEX-000 LENGTH-000) DO
     (CL:SETQ EXP
      (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY VECTOR-000))
       INDEX-000))
     (GET-CACHED-NETWORK-PROOF EXP)
     (CL:SETQ INDEX-000 (CL:1+ INDEX-000))))
   (CL:WHEN (CL:> PRINTCYCLE 0)
    (%%PRINT-STREAM (%NATIVE-STREAM LOG) "Training networks..." EOL))
   (CL:LET*
    ((CYCLE NULL-INTEGER) (ITER-000 1) (UPPER-BOUND-000 EPOCHS)
     (UNBOUNDED?-000 (CL:= UPPER-BOUND-000 NULL-INTEGER)))
    (CL:DECLARE (CL:TYPE CL:FIXNUM CYCLE ITER-000 UPPER-BOUND-000))
    (CL:LOOP WHILE
     (CL:OR UNBOUNDED?-000 (CL:<= ITER-000 UPPER-BOUND-000)) DO
     (CL:SETQ CYCLE ITER-000) (CL:SETQ TOTALABSERROR 0.0d0)
     (CL:WHEN SHUFFLE? (SHUFFLE-VECTOR EXAMPLES))
     (CL:COND
      (BATCH? (CL:SETQ BATCHQUEUE (NEW-NETWORK-PROOF-FORWARD-QUEUE))
       (CL:LET*
        ((EXP NULL) (VECTOR-001 EXAMPLES) (INDEX-001 0)
         (LENGTH-001 (LENGTH VECTOR-001)))
        (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX-001 LENGTH-001))
        (CL:LOOP WHILE (CL:< INDEX-001 LENGTH-001) DO
         (CL:SETQ EXP
          (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY VECTOR-001))
           INDEX-001))
         (CL:SETQ CACHEDPROOF (GET-CACHED-NETWORK-PROOF EXP))
         (BATCH-PROCESS-CACHED-NETWORK-PROOF BATCHQUEUE CACHEDPROOF)
         (CL:SETQ INDEX-001 (CL:1+ INDEX-001))))
       (EXECUTE-ALL BATCHQUEUE)
       (CL:SETQ BATCHQUEUE (NEW-NETWORK-PROOF-BACKWARD-QUEUE))
       (CL:LET*
        ((EXP NULL) (VECTOR-002 EXAMPLES) (INDEX-002 0)
         (LENGTH-002 (LENGTH VECTOR-002)))
        (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX-002 LENGTH-002))
        (CL:LOOP WHILE (CL:< INDEX-002 LENGTH-002) DO
         (CL:SETQ EXP
          (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY VECTOR-002))
           INDEX-002))
         (CL:SETQ TARGET (%SCORE EXP))
         (CL:SETQ CACHEDPROOF (GET-CACHED-NETWORK-PROOF EXP))
         (CL:SETQ OUTPUT (%MATCH-SCORE CACHEDPROOF))
         (CL:SETQ ERROR (CL:- TARGET OUTPUT))
         (CL:SETF (%ERROR-SCORE CACHEDPROOF) ERROR)
         (CL:SETQ TOTALABSERROR
          (CL:+ TOTALABSERROR
           (CL:IF (CL:< ERROR 0.0d0) (CL:- 0.0d0 ERROR) ERROR)))
         (BATCH-PROCESS-CACHED-NETWORK-PROOF BATCHQUEUE CACHEDPROOF)
         (CL:SETQ INDEX-002 (CL:1+ INDEX-002))))
       (EXECUTE-ALL BATCHQUEUE)
       (CL:SETQ BATCHQUEUE (NEW-NETWORK-PROOF-UPDATE-QUEUE))
       (CL:LET*
        ((EXP NULL) (VECTOR-003 EXAMPLES) (INDEX-003 0)
         (LENGTH-003 (LENGTH VECTOR-003)))
        (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX-003 LENGTH-003))
        (CL:LOOP WHILE (CL:< INDEX-003 LENGTH-003) DO
         (CL:SETQ EXP
          (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY VECTOR-003))
           INDEX-003))
         (CL:SETQ CACHEDPROOF (GET-CACHED-NETWORK-PROOF EXP))
         (BATCH-PROCESS-CACHED-NETWORK-PROOF BATCHQUEUE CACHEDPROOF)
         (CL:SETQ INDEX-003 (CL:1+ INDEX-003))))
       (EXECUTE-ALL BATCHQUEUE))
      (CL:T
       (CL:LET*
        ((EXP NULL) (VECTOR-004 EXAMPLES) (INDEX-004 0)
         (LENGTH-004 (LENGTH VECTOR-004)))
        (CL:DECLARE (CL:TYPE CL:FIXNUM INDEX-004 LENGTH-004))
        (CL:LOOP WHILE (CL:< INDEX-004 LENGTH-004) DO
         (CL:SETQ EXP
          (CL:AREF (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY VECTOR-004))
           INDEX-004))
         (CL:SETQ TARGET (%SCORE EXP))
         (CL:SETQ CACHEDPROOF (GET-CACHED-NETWORK-PROOF EXP))
         (CL:SETQ OUTPUT
          (FORWARD-PROPAGATE-CACHED-NETWORK-PROOF CACHEDPROOF))
         (CL:SETQ ERROR (CL:- TARGET OUTPUT))
         (CL:SETQ TOTALABSERROR
          (CL:+ TOTALABSERROR
           (CL:IF (CL:< ERROR 0.0d0) (CL:- 0.0d0 ERROR) ERROR)))
         (BACKWARD-PROPAGATE-CACHED-NETWORK-PROOF CACHEDPROOF ERROR)
         (CL:SETQ INDEX-004 (CL:1+ INDEX-004))))))
     (CL:WHEN
      (CL:AND (CL:> PRINTCYCLE 0)
       (CL:= (CL:THE CL:FIXNUM (CL:REM CYCLE PRINTCYCLE)) 0))
      (%%PRINT-STREAM (%NATIVE-STREAM LOG) "Cycle " CYCLE " Error: "
       (CL:/ TOTALABSERROR NUMTRAINING) EOL))
     (CL:WHEN (CL:<= (CL:/ TOTALABSERROR NUMTRAINING) ERRORCUTOFF)
      (CL:RETURN))
     (CL:SETQ ITER-000 (CL:1+ ITER-000))))
   (CL:WHEN (CL:> PRINTCYCLE 0)
    (%%PRINT-STREAM (%NATIVE-STREAM LOG) "Final error: "
     (CL:/ TOTALABSERROR NUMTRAINING) EOL))))

(CL:DEFUN TRAIN-CHAMELEON-NEURAL-NETWORKS-EVALUATOR-WRAPPER (ARGUMENTS)
  (%TRAIN-CHAMELEON-NEURAL-NETWORKS ARGUMENTS))

(CL:DEFMACRO TRAIN-CHAMELEON-NEURAL-NETWORKS (CL:&WHOLE EXPRESSION CL:&REST IGNORE)
  "Train rule neural networks based on :n-train (or all) training examples looked
up in :module/:local?.  Train for :epochs (defaults to 20) or until :error-cutoff is reached.
Print every :print-cycle epochs or not at all.  If :shuffle? (the default) randomly shuffle the
selected training examples before every epoch.  If :batch?, use batch training mechanism (which
will fail if the current network implementation does not support it)."
  (CL:DECLARE (CL:IGNORE IGNORE))
  (CL:LET ((*IGNORETRANSLATIONERRORS?* FALSE))
   (CL-INCREMENTALLY-TRANSLATE EXPRESSION)))

(CL:SETF (CL:MACRO-FUNCTION (CL:QUOTE |/LOGIC/TRAIN-CHAMELEON-NEURAL-NETWORKS|)) (CL:MACRO-FUNCTION (CL:QUOTE TRAIN-CHAMELEON-NEURAL-NETWORKS)))

;;; (DEFCLASS SCORED-QUERY-PROOF-ADJUNCT ...)

(CL:DEFCLASS SCORED-QUERY-PROOF-ADJUNCT (PROOF-ADJUNCT)
  ((PARTIAL-MATCH-STRATEGY :ALLOCATION :INSTANCE :ACCESSOR
    %PARTIAL-MATCH-STRATEGY)
   (DOWN-FRAME :ALLOCATION :INSTANCE :ACCESSOR %DOWN-FRAME)))

(CL:DEFUN NEW-SCORED-QUERY-PROOF-ADJUNCT ()
  (CL:LET* ((SELF NULL))
   (CL:SETQ SELF
    (CL:MAKE-INSTANCE (CL:QUOTE SCORED-QUERY-PROOF-ADJUNCT)))
   (CL:SETF (%DOWN-FRAME SELF) NULL)
   (CL:SETF (%PARTIAL-MATCH-STRATEGY SELF) NULL) SELF))

(CL:DEFMETHOD PRIMARY-TYPE ((SELF SCORED-QUERY-PROOF-ADJUNCT))
  SGT-CHAMELEON-LOGIC-SCORED-QUERY-PROOF-ADJUNCT)

(CL:DEFUN ACCESS-SCORED-QUERY-PROOF-ADJUNCT-SLOT-VALUE (SELF SLOTNAME VALUE SETVALUE?)
  (CL:COND
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-PARTIAL-MATCH-STRATEGY)
    (CL:IF SETVALUE? (CL:SETF (%PARTIAL-MATCH-STRATEGY SELF) VALUE)
     (CL:SETQ VALUE (%PARTIAL-MATCH-STRATEGY SELF))))
   ((CL:EQ SLOTNAME SYM-CHAMELEON-LOGIC-DOWN-FRAME)
    (CL:IF SETVALUE? (CL:SETF (%DOWN-FRAME SELF) VALUE)
     (CL:SETQ VALUE (%DOWN-FRAME SELF))))
   (CL:T
    (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
     (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" SLOTNAME
      "' is not a valid case option")
     (CL:ERROR (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))
  VALUE)

;;; (DEFUN (SCORED-QUERY-SPECIALIST KEYWORD) ...)

(CL:DEFUN SCORED-QUERY-SPECIALIST (FRAME LASTMOVE)
  (CL:LET*
   ((PROPOSITION (%PROPOSITION FRAME))
    (ARGPROPVALUE
     (ARGUMENT-BOUND-TO
      (CL:AREF
       (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%ARGUMENTS PROPOSITION)))
       0)))
    (ARGSCOREVALUE
     (ARGUMENT-BOUND-TO
      (CL:AREF
       (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%ARGUMENTS PROPOSITION)))
       1)))
    (ADJUNCT
     (DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS FRAME)
      SYM-CHAMELEON-LOGIC-PROOF-ADJUNCT NULL)))
   (CL:COND
    ((CL:EQ LASTMOVE KWD-CHAMELEON-DOWN)
     (CL:WHEN (CL:EQ ADJUNCT NULL)
      (CL:WHEN
       (CL:OR (CL:EQ ARGPROPVALUE NULL)
        (CL:NOT (ISA? ARGPROPVALUE SGT-CHAMELEON-LOGIC-PROPOSITION)))
       (CL:RETURN-FROM SCORED-QUERY-SPECIALIST
        KWD-CHAMELEON-TERMINAL-FAILURE))
      (CL:SETF (%CHOICE-POINT-UNBINDING-OFFSET FRAME) NULL-INTEGER)
      (CL:LET* ((SELF-000 (NEW-SCORED-QUERY-PROOF-ADJUNCT)))
       (CL:SETF (%DOWN-FRAME SELF-000)
        (CREATE-DOWN-FRAME FRAME ARGPROPVALUE))
       (CL:SETQ ADJUNCT SELF-000))
      (SET-DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS FRAME)
       SYM-CHAMELEON-LOGIC-PROOF-ADJUNCT ADJUNCT NULL))
     (CL:SETF (%DOWN FRAME) (%DOWN-FRAME ADJUNCT))
     (CL:SETF (%PARTIAL-MATCH-FRAME (%DOWN FRAME)) NULL)
     (CL:SETF (%PARTIAL-MATCH-STRATEGY ADJUNCT)
      (%PARTIAL-MATCH-STRATEGY *QUERYITERATOR*))
     (CL:SETF (%PARTIAL-MATCH-STRATEGY *QUERYITERATOR*) NULL)
     KWD-CHAMELEON-MOVE-DOWN)
    ((CL:EQ LASTMOVE KWD-CHAMELEON-UP-TRUE)
     (CL:WHEN
      (CL:OR (CL:EQ ARGSCOREVALUE NULL)
       (CL:NOT
        (ISA? ARGSCOREVALUE SGT-CHAMELEON-STELLA-NUMBER-WRAPPER)))
      (CL:RETURN-FROM SCORED-QUERY-SPECIALIST
       (SCORED-QUERY-SPECIALIST FRAME KWD-CHAMELEON-UP-FAIL)))
     (CL:SETF (%PARTIAL-MATCH-STRATEGY *QUERYITERATOR*)
      (%PARTIAL-MATCH-STRATEGY ADJUNCT))
     (PROPAGATE-FRAME-TRUTH-VALUE (%RESULT FRAME) FRAME)
     (CL:WHEN
      (CL:AND (CL:NOT (CL:EQ *QUERYITERATOR* NULL))
       (CL:NOT (CL:EQ (%PARTIAL-MATCH-STRATEGY *QUERYITERATOR*) NULL)))
      (SET-FRAME-PARTIAL-TRUTH (%PARTIAL-MATCH-FRAME FRAME)
       (%TRUTH-VALUE (%RESULT FRAME)) (COERCE-TO-FLOAT ARGSCOREVALUE)
       CL:T))
     (CL:WHEN *RECORD-JUSTIFICATIONS?*
      (CL:LET* ((SELF-001 (NEW-JUSTIFICATION)))
       (CL:SETF (%INFERENCE-RULE SELF-001) KWD-CHAMELEON-SCORED-QUERY)
       (CL:SETF (%ANTECEDENTS SELF-001)
        (CONS
         (DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS (%RESULT FRAME))
          SYM-CHAMELEON-LOGIC-JUSTIFICATION NULL)
         NIL))
       (RECORD-GOAL-JUSTIFICATION FRAME SELF-001)))
     (CL:COND
      ((CL:NOT (CL:EQ (%DOWN FRAME) NULL))
       (CL:SETF (%DOWN-FRAME ADJUNCT) (%DOWN FRAME))
       (CL:SETF (%DOWN FRAME) NULL) KWD-CHAMELEON-CONTINUING-SUCCESS)
      (CL:T KWD-CHAMELEON-FINAL-SUCCESS)))
    ((CL:EQ LASTMOVE KWD-CHAMELEON-UP-FAIL)
     (CL:SETF (%PARTIAL-MATCH-STRATEGY *QUERYITERATOR*)
      (%PARTIAL-MATCH-STRATEGY ADJUNCT))
     (PROPAGATE-FRAME-TRUTH-VALUE (%RESULT FRAME) FRAME)
     (CL:WHEN
      (CL:AND (CL:NOT (CL:EQ *QUERYITERATOR* NULL))
       (CL:NOT (CL:EQ (%PARTIAL-MATCH-STRATEGY *QUERYITERATOR*) NULL)))
      (SET-FRAME-PARTIAL-TRUTH (%PARTIAL-MATCH-FRAME FRAME)
       UNKNOWN-TRUTH-VALUE NULL-FLOAT CL:T))
     (CL:WHEN *RECORD-JUSTIFICATIONS?*
      (RECORD-PRIMITIVE-JUSTIFICATION FRAME KWD-CHAMELEON-UP-FAIL))
     KWD-CHAMELEON-TERMINAL-FAILURE)
    (CL:T
     (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
      (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" LASTMOVE
       "' is not a valid case option")
      (CL:ERROR
       (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))))

;;; (DEFUN (MATCH-SCORE-SPECIALIST KEYWORD) ...)

(CL:DEFUN MATCH-SCORE-SPECIALIST (FRAME LASTMOVE)
  (CL:LET*
   ((PROPOSITION (%PROPOSITION FRAME))
    (ARGPROPVALUE
     (ARGUMENT-BOUND-TO
      (CL:AREF
       (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%ARGUMENTS PROPOSITION)))
       0)))
    (ARGSCORE
     (CL:AREF
      (CL:THE CL:SIMPLE-VECTOR (%THE-ARRAY (%ARGUMENTS PROPOSITION)))
      1))
    (ADJUNCT
     (DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS FRAME)
      SYM-CHAMELEON-LOGIC-PROOF-ADJUNCT NULL)))
   (CL:COND
    ((CL:EQ LASTMOVE KWD-CHAMELEON-DOWN)
     (CL:WHEN (CL:EQ ADJUNCT NULL)
      (CL:WHEN
       (CL:OR (CL:EQ ARGPROPVALUE NULL)
        (CL:NOT (ISA? ARGPROPVALUE SGT-CHAMELEON-LOGIC-PROPOSITION)))
       (CL:RETURN-FROM MATCH-SCORE-SPECIALIST
        KWD-CHAMELEON-TERMINAL-FAILURE))
      (CL:SETF (%CHOICE-POINT-UNBINDING-OFFSET FRAME) NULL-INTEGER)
      (CL:LET* ((SELF-000 (NEW-SCORED-QUERY-PROOF-ADJUNCT)))
       (CL:SETF (%DOWN-FRAME SELF-000)
        (CREATE-DOWN-FRAME FRAME ARGPROPVALUE))
       (CL:SETQ ADJUNCT SELF-000))
      (SET-DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS FRAME)
       SYM-CHAMELEON-LOGIC-PROOF-ADJUNCT ADJUNCT NULL))
     (CL:SETF (%DOWN FRAME) (%DOWN-FRAME ADJUNCT))
     (CL:WHEN (CL:EQ (%PARTIAL-MATCH-FRAME (%DOWN FRAME)) NULL)
      (CL:SETF (%PARTIAL-MATCH-FRAME (%DOWN FRAME))
       (NEW-CHAMELEON-PARTIAL-MATCH NULL (%DOWN FRAME))))
     (CL:SETF (%PARTIAL-MATCH-STRATEGY ADJUNCT)
      (%PARTIAL-MATCH-STRATEGY *QUERYITERATOR*))
     (CL:SETF (%PARTIAL-MATCH-STRATEGY *QUERYITERATOR*)
      (%PARTIAL-MATCH-FRAME (%DOWN FRAME)))
     KWD-CHAMELEON-MOVE-DOWN)
    ((CL:EQ LASTMOVE KWD-CHAMELEON-UP-TRUE)
     (CL:SETF (%PARTIAL-MATCH-STRATEGY *QUERYITERATOR*)
      (%PARTIAL-MATCH-STRATEGY ADJUNCT))
     (CL:LET*
      ((SCORE (%MATCH-SCORE (%PARTIAL-MATCH-FRAME (%RESULT FRAME)))))
      (CL:DECLARE (CL:TYPE CL:DOUBLE-FLOAT SCORE))
      (CL:COND
       ((BIND-ARGUMENT-TO-VALUE? ARGSCORE (WRAP-FLOAT SCORE) CL:T)
        (PROPAGATE-FRAME-TRUTH-VALUE (%RESULT FRAME) FRAME)
        (CL:WHEN
         (CL:AND (CL:NOT (CL:EQ *QUERYITERATOR* NULL))
          (CL:NOT
           (CL:EQ (%PARTIAL-MATCH-STRATEGY *QUERYITERATOR*) NULL)))
         (PROPAGATE-FRAME-PARTIAL-TRUTH
          (%PARTIAL-MATCH-FRAME (%RESULT FRAME)) FRAME))
        (CL:WHEN *RECORD-JUSTIFICATIONS?*
         (CL:LET* ((SELF-002 (NEW-JUSTIFICATION)))
          (CL:SETF (%INFERENCE-RULE SELF-002)
           KWD-CHAMELEON-MATCH-SCORE)
          (CL:SETF (%ANTECEDENTS SELF-002)
           (CONS
            (DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS (%RESULT FRAME))
             SYM-CHAMELEON-LOGIC-JUSTIFICATION NULL)
            NIL))
          (RECORD-GOAL-JUSTIFICATION FRAME SELF-002)))
        (CL:COND
         ((CL:NOT (CL:EQ (%DOWN FRAME) NULL))
          (CL:SETF (%DOWN-FRAME ADJUNCT) (%DOWN FRAME))
          (CL:SETF (%DOWN FRAME) NULL)
          KWD-CHAMELEON-CONTINUING-SUCCESS)
         (CL:T KWD-CHAMELEON-FINAL-SUCCESS)))
       (CL:T (MATCH-SCORE-SPECIALIST FRAME KWD-CHAMELEON-UP-FAIL)))))
    ((CL:EQ LASTMOVE KWD-CHAMELEON-UP-FAIL)
     (CL:SETF (%PARTIAL-MATCH-STRATEGY *QUERYITERATOR*)
      (%PARTIAL-MATCH-STRATEGY ADJUNCT))
     (PROPAGATE-FRAME-TRUTH-VALUE (%RESULT FRAME) FRAME)
     (CL:WHEN
      (CL:AND (CL:NOT (CL:EQ *QUERYITERATOR* NULL))
       (CL:NOT (CL:EQ (%PARTIAL-MATCH-STRATEGY *QUERYITERATOR*) NULL)))
      (SET-FRAME-PARTIAL-TRUTH (%PARTIAL-MATCH-FRAME FRAME)
       UNKNOWN-TRUTH-VALUE NULL-FLOAT CL:T))
     (CL:WHEN *RECORD-JUSTIFICATIONS?*
      (RECORD-PRIMITIVE-JUSTIFICATION FRAME KWD-CHAMELEON-UP-FAIL))
     KWD-CHAMELEON-TERMINAL-FAILURE)
    (CL:T
     (CL:LET* ((STREAM-000 (NEW-OUTPUT-STRING-STREAM)))
      (%%PRINT-STREAM (%NATIVE-STREAM STREAM-000) "`" LASTMOVE
       "' is not a valid case option")
      (CL:ERROR
       (NEW-STELLA-EXCEPTION (THE-STRING-READER STREAM-000))))))))

(CL:DEFUN HELP-STARTUP-CHAMELEON1 ()
  (CL:PROGN
   (CL:SETQ SGT-CHAMELEON-CHAMELEON-TRUTH-VALUE-RELATION
    (INTERN-RIGID-SYMBOL-WRT-MODULE "TRUTH-VALUE-RELATION"
     (GET-STELLA-MODULE "/CHAMELEON" CL:T) 1))
   (CL:SETQ SGT-CHAMELEON-CHAMELEON-VECTOR-RELATION
    (INTERN-RIGID-SYMBOL-WRT-MODULE "VECTOR-RELATION"
     (GET-STELLA-MODULE "/CHAMELEON" CL:T) 1))
   (CL:SETQ SGT-CHAMELEON-CHAMELEON-IGNORED-VALUE-RELATION
    (INTERN-RIGID-SYMBOL-WRT-MODULE "IGNORED-VALUE-RELATION"
     (GET-STELLA-MODULE "/CHAMELEON" CL:T) 1))
   (CL:SETQ SGT-CHAMELEON-CHAMELEON-PRIMITIVE-VALUE-RELATION
    (INTERN-RIGID-SYMBOL-WRT-MODULE "PRIMITIVE-VALUE-RELATION"
     (GET-STELLA-MODULE "/CHAMELEON" CL:T) 1))
   (CL:SETQ SGT-CHAMELEON-LOGIC-CHAMELEON-PARTIAL-MATCH
    (INTERN-RIGID-SYMBOL-WRT-MODULE "CHAMELEON-PARTIAL-MATCH" NULL 1))
   (CL:SETQ SYM-CHAMELEON-LOGIC-ARGUMENT-JUSTIFICATIONS
    (INTERN-RIGID-SYMBOL-WRT-MODULE "ARGUMENT-JUSTIFICATIONS" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-ARGUMENT-PROPOSITIONS
    (INTERN-RIGID-SYMBOL-WRT-MODULE "ARGUMENT-PROPOSITIONS" NULL 0))
   (CL:SETQ KWD-CHAMELEON-AND
    (INTERN-RIGID-SYMBOL-WRT-MODULE "AND" NULL 2))
   (CL:SETQ KWD-CHAMELEON-OR
    (INTERN-RIGID-SYMBOL-WRT-MODULE "OR" NULL 2))
   (CL:SETQ KWD-CHAMELEON-ATOMIC-GOAL
    (INTERN-RIGID-SYMBOL-WRT-MODULE "ATOMIC-GOAL" NULL 2))
   (CL:SETQ KWD-CHAMELEON-UP-TRUE
    (INTERN-RIGID-SYMBOL-WRT-MODULE "UP-TRUE" NULL 2))
   (CL:SETQ KWD-CHAMELEON-UP-FAIL
    (INTERN-RIGID-SYMBOL-WRT-MODULE "UP-FAIL" NULL 2))
   (CL:SETQ KWD-CHAMELEON-DOWN
    (INTERN-RIGID-SYMBOL-WRT-MODULE "DOWN" NULL 2))
   (CL:SETQ SYM-CHAMELEON-LOGIC-JUSTIFICATION
    (INTERN-RIGID-SYMBOL-WRT-MODULE "JUSTIFICATION" NULL 0))
   (CL:SETQ KWD-CHAMELEON-GOAL-TREE
    (INTERN-RIGID-SYMBOL-WRT-MODULE "GOAL-TREE" NULL 2))
   (CL:SETQ KWD-CHAMELEON-OR-INTRODUCTION
    (INTERN-RIGID-SYMBOL-WRT-MODULE "OR-INTRODUCTION" NULL 2))
   (CL:SETQ KWD-CHAMELEON-FAILURE
    (INTERN-RIGID-SYMBOL-WRT-MODULE "FAILURE" NULL 2))
   (CL:SETQ KWD-CHAMELEON-OTHER
    (INTERN-RIGID-SYMBOL-WRT-MODULE "OTHER" NULL 2))
   (CL:SETQ KWD-CHAMELEON-VARIANT1
    (INTERN-RIGID-SYMBOL-WRT-MODULE "VARIANT1" NULL 2))
   (CL:SETQ KWD-CHAMELEON-FINAL-SUCCESS
    (INTERN-RIGID-SYMBOL-WRT-MODULE "FINAL-SUCCESS" NULL 2))
   (CL:SETQ KWD-CHAMELEON-VARIANT2
    (INTERN-RIGID-SYMBOL-WRT-MODULE "VARIANT2" NULL 2))
   (CL:SETQ SYM-CHAMELEON-LOGIC-ANTECEDENTS-RULE
    (INTERN-RIGID-SYMBOL-WRT-MODULE "ANTECEDENTS-RULE" NULL 0))
   (CL:SETQ KWD-CHAMELEON-MULTIPLE-PROOFS
    (INTERN-RIGID-SYMBOL-WRT-MODULE "MULTIPLE-PROOFS" NULL 2))
   (CL:SETQ KWD-CHAMELEON-TECHNICAL
    (INTERN-RIGID-SYMBOL-WRT-MODULE "TECHNICAL" NULL 2))
   (CL:SETQ KWD-CHAMELEON-LAY
    (INTERN-RIGID-SYMBOL-WRT-MODULE "LAY" NULL 2))
   (CL:SETQ KWD-CHAMELEON-MINIMUM-SCORE
    (INTERN-RIGID-SYMBOL-WRT-MODULE "MINIMUM-SCORE" NULL 2))
   (CL:SETQ KWD-CHAMELEON-MAXIMIZE-SCORE?
    (INTERN-RIGID-SYMBOL-WRT-MODULE "MAXIMIZE-SCORE?" NULL 2))
   (CL:SETQ KWD-CHAMELEON-RECORD-JUSTIFICATIONS?
    (INTERN-RIGID-SYMBOL-WRT-MODULE "RECORD-JUSTIFICATIONS?" NULL 2))
   (CL:SETQ SGT-CHAMELEON-STELLA-BOOLEAN
    (INTERN-RIGID-SYMBOL-WRT-MODULE "BOOLEAN"
     (GET-STELLA-MODULE "/STELLA" CL:T) 1))
   (CL:SETQ KWD-CHAMELEON-NOISY-OR
    (INTERN-RIGID-SYMBOL-WRT-MODULE "NOISY-OR" NULL 2))
   (CL:SETQ KWD-CHAMELEON-ORIGINAL
    (INTERN-RIGID-SYMBOL-WRT-MODULE "ORIGINAL" NULL 2))
   (CL:SETQ SYM-CHAMELEON-LOGIC-NEURAL-NET
    (INTERN-RIGID-SYMBOL-WRT-MODULE "NEURAL-NET" NULL 0))
   (CL:SETQ KWD-CHAMELEON-PROPOSITION
    (INTERN-RIGID-SYMBOL-WRT-MODULE "PROPOSITION" NULL 2))
   (CL:SETQ KWD-CHAMELEON-CHAMELEON
    (INTERN-RIGID-SYMBOL-WRT-MODULE "CHAMELEON" NULL 2))
   (CL:SETQ KWD-CHAMELEON-CHAMELEON-BATCH
    (INTERN-RIGID-SYMBOL-WRT-MODULE "CHAMELEON-BATCH" NULL 2))
   (CL:SETQ KWD-CHAMELEON-TENSORFLOW
    (INTERN-RIGID-SYMBOL-WRT-MODULE "TENSORFLOW" NULL 2))
   (CL:SETQ KWD-CHAMELEON-TENSORFLOW-BATCH
    (INTERN-RIGID-SYMBOL-WRT-MODULE "TENSORFLOW-BATCH" NULL 2))
   (CL:SETQ KWD-CHAMELEON-NOT
    (INTERN-RIGID-SYMBOL-WRT-MODULE "NOT" NULL 2))
   (CL:SETQ KWD-CHAMELEON-FAIL
    (INTERN-RIGID-SYMBOL-WRT-MODULE "FAIL" NULL 2))
   (CL:SETQ KWD-CHAMELEON-TRUTH-VALUE
    (INTERN-RIGID-SYMBOL-WRT-MODULE "TRUTH-VALUE" NULL 2))
   (CL:SETQ KWD-CHAMELEON-IGNORED-VALUE
    (INTERN-RIGID-SYMBOL-WRT-MODULE "IGNORED-VALUE" NULL 2))
   (CL:SETQ KWD-CHAMELEON-VECTOR
    (INTERN-RIGID-SYMBOL-WRT-MODULE "VECTOR" NULL 2))
   (CL:SETQ SGT-CHAMELEON-LOGIC-PROPOSITION
    (INTERN-RIGID-SYMBOL-WRT-MODULE "PROPOSITION" NULL 1))
   (CL:SETQ
    SGT-CHAMELEON-LOGIC-M-NEURAL-NETWORK.TRUTH-VALUE-ARGUMENT-INDEX-MEMO-TABLE-000
    (INTERN-RIGID-SYMBOL-WRT-MODULE
     "M-NEURAL-NETWORK.TRUTH-VALUE-ARGUMENT-INDEX-MEMO-TABLE-000" NULL
     1))
   (CL:SETQ KWD-CHAMELEON-QUICKPROP
    (INTERN-RIGID-SYMBOL-WRT-MODULE "QUICKPROP" NULL 2))
   (CL:SETQ SGT-CHAMELEON-STELLA-CONS
    (INTERN-RIGID-SYMBOL-WRT-MODULE "CONS"
     (GET-STELLA-MODULE "/STELLA" CL:T) 1))
   (CL:SETQ SGT-CHAMELEON-STELLA-LIST
    (INTERN-RIGID-SYMBOL-WRT-MODULE "LIST"
     (GET-STELLA-MODULE "/STELLA" CL:T) 1))
   (CL:SETQ SGT-CHAMELEON-STELLA-VECTOR
    (INTERN-RIGID-SYMBOL-WRT-MODULE "VECTOR"
     (GET-STELLA-MODULE "/STELLA" CL:T) 1))
   (CL:SETQ SGT-CHAMELEON-STELLA-SEQUENCE
    (INTERN-RIGID-SYMBOL-WRT-MODULE "SEQUENCE"
     (GET-STELLA-MODULE "/STELLA" CL:T) 1))
   (CL:SETQ SGT-CHAMELEON-STELLA-ITERATOR
    (INTERN-RIGID-SYMBOL-WRT-MODULE "ITERATOR"
     (GET-STELLA-MODULE "/STELLA" CL:T) 1))
   (CL:SETQ SGT-CHAMELEON-LOGIC-CHAMELEON-NEURAL-NETWORK
    (INTERN-RIGID-SYMBOL-WRT-MODULE "CHAMELEON-NEURAL-NETWORK" NULL 1))
   (CL:SETQ SYM-CHAMELEON-LOGIC-PROPOSITION
    (INTERN-RIGID-SYMBOL-WRT-MODULE "PROPOSITION" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-INPUT
    (INTERN-RIGID-SYMBOL-WRT-MODULE "INPUT" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-HIDDEN
    (INTERN-RIGID-SYMBOL-WRT-MODULE "HIDDEN" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-OUTPUT
    (INTERN-RIGID-SYMBOL-WRT-MODULE "OUTPUT" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-IH
    (INTERN-RIGID-SYMBOL-WRT-MODULE "IH" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-HO
    (INTERN-RIGID-SYMBOL-WRT-MODULE "HO" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-INPUT-ERROR
    (INTERN-RIGID-SYMBOL-WRT-MODULE "INPUT-ERROR" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-HIDDEN-ERROR
    (INTERN-RIGID-SYMBOL-WRT-MODULE "HIDDEN-ERROR" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-OUTPUT-ERROR
    (INTERN-RIGID-SYMBOL-WRT-MODULE "OUTPUT-ERROR" NULL 0))))

(CL:DEFUN HELP-STARTUP-CHAMELEON2 ()
  (CL:PROGN
   (CL:SETQ SYM-CHAMELEON-LOGIC-IH-DELTA
    (INTERN-RIGID-SYMBOL-WRT-MODULE "IH-DELTA" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-HO-DELTA
    (INTERN-RIGID-SYMBOL-WRT-MODULE "HO-DELTA" NULL 0))
   (CL:SETQ SGT-CHAMELEON-STELLA-FLOAT-ARRAY
    (INTERN-RIGID-SYMBOL-WRT-MODULE "FLOAT-ARRAY"
     (GET-STELLA-MODULE "/STELLA" CL:T) 1))
   (CL:SETQ SGT-CHAMELEON-LOGIC-VECTOR-NEURAL-NETWORK
    (INTERN-RIGID-SYMBOL-WRT-MODULE "VECTOR-NEURAL-NETWORK" NULL 1))
   (CL:SETQ SYM-CHAMELEON-LOGIC-N-VECTOR-ARGUMENTS
    (INTERN-RIGID-SYMBOL-WRT-MODULE "N-VECTOR-ARGUMENTS" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-N-VECTOR-ARGUMENT-SPECS
    (INTERN-RIGID-SYMBOL-WRT-MODULE "N-VECTOR-ARGUMENT-SPECS" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-N-VECTOR-ARGUMENT-INPUTS
    (INTERN-RIGID-SYMBOL-WRT-MODULE "N-VECTOR-ARGUMENT-INPUTS" NULL 0))
   (CL:SETQ
    SGT-CHAMELEON-LOGIC-M-VECTOR-NEURAL-NETWORK.VECTOR-ARGUMENT-INDEX-MEMO-TABLE-000
    (INTERN-RIGID-SYMBOL-WRT-MODULE
     "M-VECTOR-NEURAL-NETWORK.VECTOR-ARGUMENT-INDEX-MEMO-TABLE-000"
     NULL 1))
   (CL:SETQ SGT-CHAMELEON-CHAMELEON-VECTOR-ARITY
    (INTERN-RIGID-SYMBOL-WRT-MODULE "VECTOR-ARITY"
     (GET-STELLA-MODULE "/CHAMELEON" CL:T) 1))
   (CL:SETQ SGT-CHAMELEON-CHAMELEON-VECTOR-DIMENSIONS
    (INTERN-RIGID-SYMBOL-WRT-MODULE "VECTOR-DIMENSIONS"
     (GET-STELLA-MODULE "/CHAMELEON" CL:T) 1))
   (CL:SETQ SGT-CHAMELEON-LOGIC-JUSTIFICATION
    (INTERN-RIGID-SYMBOL-WRT-MODULE "JUSTIFICATION" NULL 1))
   (CL:SETQ SGT-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK
    (INTERN-RIGID-SYMBOL-WRT-MODULE "TENSORFLOW-NEURAL-NETWORK" NULL
     1))
   (CL:SETQ SYM-CHAMELEON-LOGIC-MODEL
    (INTERN-RIGID-SYMBOL-WRT-MODULE "MODEL" NULL 0))
   (CL:SETQ
    SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.BUILD-PROPOSITION-NETWORK
    (INTERN-RIGID-SYMBOL-WRT-MODULE
     "TENSORFLOW-NEURAL-NETWORK.BUILD-PROPOSITION-NETWORK" NULL 0))
   (CL:SETQ
    SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.ALLOCATE-NETWORK-ARRAYS
    (INTERN-RIGID-SYMBOL-WRT-MODULE
     "TENSORFLOW-NEURAL-NETWORK.ALLOCATE-NETWORK-ARRAYS" NULL 0))
   (CL:SETQ
    SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.RANDOMIZE-NETWORK-WEIGHTS
    (INTERN-RIGID-SYMBOL-WRT-MODULE
     "TENSORFLOW-NEURAL-NETWORK.RANDOMIZE-NETWORK-WEIGHTS" NULL 0))
   (CL:SETQ
    SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.INITIALIZE-NETWORK-WEIGHTS
    (INTERN-RIGID-SYMBOL-WRT-MODULE
     "TENSORFLOW-NEURAL-NETWORK.INITIALIZE-NETWORK-WEIGHTS" NULL 0))
   (CL:SETQ
    SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.NUMBER-OF-INPUTS
    (INTERN-RIGID-SYMBOL-WRT-MODULE
     "TENSORFLOW-NEURAL-NETWORK.NUMBER-OF-INPUTS" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.NTH-INPUT
    (INTERN-RIGID-SYMBOL-WRT-MODULE
     "TENSORFLOW-NEURAL-NETWORK.NTH-INPUT" NULL 0))
   (CL:SETQ
    SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.NTH-INPUT-ERROR
    (INTERN-RIGID-SYMBOL-WRT-MODULE
     "TENSORFLOW-NEURAL-NETWORK.NTH-INPUT-ERROR" NULL 0))
   (CL:SETQ
    SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.SET-INPUT-VALUES
    (INTERN-RIGID-SYMBOL-WRT-MODULE
     "TENSORFLOW-NEURAL-NETWORK.SET-INPUT-VALUES" NULL 0))
   (CL:SETQ
    SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.SET-VECTOR-INPUT-VALUES
    (INTERN-RIGID-SYMBOL-WRT-MODULE
     "TENSORFLOW-NEURAL-NETWORK.SET-VECTOR-INPUT-VALUES" NULL 0))
   (CL:SETQ
    SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.FORWARD-PROPAGATE-INPUTS
    (INTERN-RIGID-SYMBOL-WRT-MODULE
     "TENSORFLOW-NEURAL-NETWORK.FORWARD-PROPAGATE-INPUTS" NULL 0))
   (CL:SETQ
    SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.BACKWARD-PROPAGATE-ERROR
    (INTERN-RIGID-SYMBOL-WRT-MODULE
     "TENSORFLOW-NEURAL-NETWORK.BACKWARD-PROPAGATE-ERROR" NULL 0))
   (CL:SETQ
    SYM-CHAMELEON-LOGIC-TENSORFLOW-NEURAL-NETWORK.UPDATE-NETWORK-WEIGHTS
    (INTERN-RIGID-SYMBOL-WRT-MODULE
     "TENSORFLOW-NEURAL-NETWORK.UPDATE-NETWORK-WEIGHTS" NULL 0))
   (CL:SETQ KWD-CHAMELEON-MATCH-MODE
    (INTERN-RIGID-SYMBOL-WRT-MODULE "MATCH-MODE" NULL 2))
   (CL:SETQ KWD-CHAMELEON-WARNING
    (INTERN-RIGID-SYMBOL-WRT-MODULE "WARNING" NULL 2))
   (CL:SETQ KWD-CHAMELEON-PRIMITIVE-STRATEGY
    (INTERN-RIGID-SYMBOL-WRT-MODULE "PRIMITIVE-STRATEGY" NULL 2))
   (CL:SETQ KWD-CHAMELEON-GOAL-COMPLEMENT
    (INTERN-RIGID-SYMBOL-WRT-MODULE "GOAL-COMPLEMENT" NULL 2))
   (CL:SETQ KWD-CHAMELEON-AND-INTRODUCTION
    (INTERN-RIGID-SYMBOL-WRT-MODULE "AND-INTRODUCTION" NULL 2))
   (CL:SETQ KWD-CHAMELEON-DISPROOF
    (INTERN-RIGID-SYMBOL-WRT-MODULE "DISPROOF" NULL 2))
   (CL:SETQ KWD-CHAMELEON-MODUS-PONENS
    (INTERN-RIGID-SYMBOL-WRT-MODULE "MODUS-PONENS" NULL 2))
   (CL:SETQ KWD-CHAMELEON-MODUS-TOLLENS
    (INTERN-RIGID-SYMBOL-WRT-MODULE "MODUS-TOLLENS" NULL 2))
   (CL:SETQ KWD-CHAMELEON-SUBSUMPTION-REASONING
    (INTERN-RIGID-SYMBOL-WRT-MODULE "SUBSUMPTION-REASONING" NULL 2))
   (CL:SETQ KWD-CHAMELEON-FAIL-INTRODUCTION
    (INTERN-RIGID-SYMBOL-WRT-MODULE "FAIL-INTRODUCTION" NULL 2))
   (CL:SETQ KWD-CHAMELEON-MAX
    (INTERN-RIGID-SYMBOL-WRT-MODULE "MAX" NULL 2))
   (CL:SETQ SGT-CHAMELEON-LOGIC-CHAMELEON-BATCH-NEURAL-NETWORK
    (INTERN-RIGID-SYMBOL-WRT-MODULE "CHAMELEON-BATCH-NEURAL-NETWORK"
     NULL 1))
   (CL:SETQ SYM-CHAMELEON-LOGIC-INPUT-BATCH
    (INTERN-RIGID-SYMBOL-WRT-MODULE "INPUT-BATCH" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-KEY-BATCH
    (INTERN-RIGID-SYMBOL-WRT-MODULE "KEY-BATCH" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-TARGET-BATCH
    (INTERN-RIGID-SYMBOL-WRT-MODULE "TARGET-BATCH" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-OUTPUT-BATCH
    (INTERN-RIGID-SYMBOL-WRT-MODULE "OUTPUT-BATCH" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-INPUT-ERROR-BATCH
    (INTERN-RIGID-SYMBOL-WRT-MODULE "INPUT-ERROR-BATCH" NULL 0))
   (CL:SETQ SGT-CHAMELEON-LOGIC-2D-LONG-ARRAY
    (INTERN-RIGID-SYMBOL-WRT-MODULE "2D-LONG-ARRAY" NULL 1))
   (CL:SETQ SGT-CHAMELEON-LOGIC-TENSORFLOW-BATCH-NEURAL-NETWORK
    (INTERN-RIGID-SYMBOL-WRT-MODULE "TENSORFLOW-BATCH-NEURAL-NETWORK"
     NULL 1))
   (CL:SETQ SYM-CHAMELEON-LOGIC-INPUT-MODIFIED?
    (INTERN-RIGID-SYMBOL-WRT-MODULE "INPUT-MODIFIED?" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-INPUT-BATCH-LENGTH
    (INTERN-RIGID-SYMBOL-WRT-MODULE "INPUT-BATCH-LENGTH" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-VECTOR-BATCH
    (INTERN-RIGID-SYMBOL-WRT-MODULE "VECTOR-BATCH" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-VECTOR-BATCH-LENGTH
    (INTERN-RIGID-SYMBOL-WRT-MODULE "VECTOR-BATCH-LENGTH" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-TARGET-BATCH-LENGTH
    (INTERN-RIGID-SYMBOL-WRT-MODULE "TARGET-BATCH-LENGTH" NULL 0))
   (CL:SETQ
    SYM-CHAMELEON-LOGIC-TENSORFLOW-BATCH-NEURAL-NETWORK.BATCH-FORWARD-PROPAGATE-INPUTS
    (INTERN-RIGID-SYMBOL-WRT-MODULE
     "TENSORFLOW-BATCH-NEURAL-NETWORK.BATCH-FORWARD-PROPAGATE-INPUTS"
     NULL 0))
   (CL:SETQ
    SYM-CHAMELEON-LOGIC-TENSORFLOW-BATCH-NEURAL-NETWORK.BATCH-BACKWARD-PROPAGATE-ERROR
    (INTERN-RIGID-SYMBOL-WRT-MODULE
     "TENSORFLOW-BATCH-NEURAL-NETWORK.BATCH-BACKWARD-PROPAGATE-ERROR"
     NULL 0))
   (CL:SETQ
    SYM-CHAMELEON-LOGIC-TENSORFLOW-BATCH-NEURAL-NETWORK.BATCH-UPDATE-NETWORK-WEIGHTS
    (INTERN-RIGID-SYMBOL-WRT-MODULE
     "TENSORFLOW-BATCH-NEURAL-NETWORK.BATCH-UPDATE-NETWORK-WEIGHTS"
     NULL 0))
   (CL:SETQ SGT-CHAMELEON-LOGIC-NETWORK-PROOF-QUEUE
    (INTERN-RIGID-SYMBOL-WRT-MODULE "NETWORK-PROOF-QUEUE" NULL 1))
   (CL:SETQ SYM-CHAMELEON-LOGIC-DEPENDENTS
    (INTERN-RIGID-SYMBOL-WRT-MODULE "DEPENDENTS" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-PREREQUISITES
    (INTERN-RIGID-SYMBOL-WRT-MODULE "PREREQUISITES" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-ACTIVE-NETWORKS
    (INTERN-RIGID-SYMBOL-WRT-MODULE "ACTIVE-NETWORKS" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-MIN-BATCH-SIZE
    (INTERN-RIGID-SYMBOL-WRT-MODULE "MIN-BATCH-SIZE" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-N-QUEUED
    (INTERN-RIGID-SYMBOL-WRT-MODULE "N-QUEUED" NULL 0))
   (CL:SETQ SGT-CHAMELEON-LOGIC-NETWORK-PROOF-FORWARD-QUEUE
    (INTERN-RIGID-SYMBOL-WRT-MODULE "NETWORK-PROOF-FORWARD-QUEUE" NULL
     1))
   (CL:SETQ SGT-CHAMELEON-LOGIC-NETWORK-PROOF-BACKWARD-QUEUE
    (INTERN-RIGID-SYMBOL-WRT-MODULE "NETWORK-PROOF-BACKWARD-QUEUE" NULL
     1))))

(CL:DEFUN HELP-STARTUP-CHAMELEON3 ()
  (CL:PROGN
   (CL:SETQ SGT-CHAMELEON-LOGIC-NETWORK-PROOF-UPDATE-QUEUE
    (INTERN-RIGID-SYMBOL-WRT-MODULE "NETWORK-PROOF-UPDATE-QUEUE" NULL
     1))
   (CL:SETQ KWD-CHAMELEON-MODULE
    (INTERN-RIGID-SYMBOL-WRT-MODULE "MODULE" NULL 2))
   (CL:SETQ SGT-CHAMELEON-STELLA-MODULE
    (INTERN-RIGID-SYMBOL-WRT-MODULE "MODULE"
     (GET-STELLA-MODULE "/STELLA" CL:T) 1))
   (CL:SETQ KWD-CHAMELEON-LOCAL?
    (INTERN-RIGID-SYMBOL-WRT-MODULE "LOCAL?" NULL 2))
   (CL:SETQ KWD-CHAMELEON-N-TRAIN
    (INTERN-RIGID-SYMBOL-WRT-MODULE "N-TRAIN" NULL 2))
   (CL:SETQ SGT-CHAMELEON-STELLA-INTEGER
    (INTERN-RIGID-SYMBOL-WRT-MODULE "INTEGER"
     (GET-STELLA-MODULE "/STELLA" CL:T) 1))
   (CL:SETQ SYM-CHAMELEON-CHAMELEON-TRAINING-EXAMPLE
    (INTERN-RIGID-SYMBOL-WRT-MODULE "TRAINING-EXAMPLE"
     (GET-STELLA-MODULE "/CHAMELEON" CL:T) 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-?P
    (INTERN-RIGID-SYMBOL-WRT-MODULE "?P" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-?S
    (INTERN-RIGID-SYMBOL-WRT-MODULE "?S" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-RETRIEVE-TRAINING-EXAMPLES
    (INTERN-RIGID-SYMBOL-WRT-MODULE "RETRIEVE-TRAINING-EXAMPLES" NULL
     0))
   (CL:SETQ KWD-CHAMELEON-COMMON-LISP
    (INTERN-RIGID-SYMBOL-WRT-MODULE "COMMON-LISP" NULL 2))
   (CL:SETQ KWD-CHAMELEON-FUNCTION
    (INTERN-RIGID-SYMBOL-WRT-MODULE "FUNCTION" NULL 2))
   (CL:SETQ KWD-CHAMELEON-SHUFFLE?
    (INTERN-RIGID-SYMBOL-WRT-MODULE "SHUFFLE?" NULL 2))
   (CL:SETQ KWD-CHAMELEON-OPTIONS
    (INTERN-RIGID-SYMBOL-WRT-MODULE "OPTIONS" NULL 2))
   (CL:SETQ SYM-CHAMELEON-LOGIC-SELECT-TRAINING-EXAMPLES
    (INTERN-RIGID-SYMBOL-WRT-MODULE "SELECT-TRAINING-EXAMPLES" NULL 0))
   (CL:SETQ KWD-CHAMELEON-EPOCHS
    (INTERN-RIGID-SYMBOL-WRT-MODULE "EPOCHS" NULL 2))
   (CL:SETQ KWD-CHAMELEON-PRINT-CYCLE
    (INTERN-RIGID-SYMBOL-WRT-MODULE "PRINT-CYCLE" NULL 2))
   (CL:SETQ KWD-CHAMELEON-ERROR-CUTOFF
    (INTERN-RIGID-SYMBOL-WRT-MODULE "ERROR-CUTOFF" NULL 2))
   (CL:SETQ SGT-CHAMELEON-STELLA-FLOAT
    (INTERN-RIGID-SYMBOL-WRT-MODULE "FLOAT"
     (GET-STELLA-MODULE "/STELLA" CL:T) 1))
   (CL:SETQ KWD-CHAMELEON-BATCH?
    (INTERN-RIGID-SYMBOL-WRT-MODULE "BATCH?" NULL 2))
   (CL:SETQ KWD-CHAMELEON-EXAMPLES
    (INTERN-RIGID-SYMBOL-WRT-MODULE "EXAMPLES" NULL 2))
   (CL:SETQ SGT-CHAMELEON-STELLA-OBJECT
    (INTERN-RIGID-SYMBOL-WRT-MODULE "OBJECT"
     (GET-STELLA-MODULE "/STELLA" CL:T) 1))
   (CL:SETQ SYM-CHAMELEON-LOGIC-TRAIN-CHAMELEON-NEURAL-NETWORKS
    (INTERN-RIGID-SYMBOL-WRT-MODULE "TRAIN-CHAMELEON-NEURAL-NETWORKS"
     NULL 0))
   (CL:SETQ SGT-CHAMELEON-LOGIC-SCORED-QUERY-PROOF-ADJUNCT
    (INTERN-RIGID-SYMBOL-WRT-MODULE "SCORED-QUERY-PROOF-ADJUNCT" NULL
     1))
   (CL:SETQ SYM-CHAMELEON-LOGIC-PARTIAL-MATCH-STRATEGY
    (INTERN-RIGID-SYMBOL-WRT-MODULE "PARTIAL-MATCH-STRATEGY" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-DOWN-FRAME
    (INTERN-RIGID-SYMBOL-WRT-MODULE "DOWN-FRAME" NULL 0))
   (CL:SETQ SYM-CHAMELEON-LOGIC-PROOF-ADJUNCT
    (INTERN-RIGID-SYMBOL-WRT-MODULE "PROOF-ADJUNCT" NULL 0))
   (CL:SETQ KWD-CHAMELEON-TERMINAL-FAILURE
    (INTERN-RIGID-SYMBOL-WRT-MODULE "TERMINAL-FAILURE" NULL 2))
   (CL:SETQ KWD-CHAMELEON-MOVE-DOWN
    (INTERN-RIGID-SYMBOL-WRT-MODULE "MOVE-DOWN" NULL 2))
   (CL:SETQ SGT-CHAMELEON-STELLA-NUMBER-WRAPPER
    (INTERN-RIGID-SYMBOL-WRT-MODULE "NUMBER-WRAPPER"
     (GET-STELLA-MODULE "/STELLA" CL:T) 1))
   (CL:SETQ KWD-CHAMELEON-SCORED-QUERY
    (INTERN-RIGID-SYMBOL-WRT-MODULE "SCORED-QUERY" NULL 2))
   (CL:SETQ KWD-CHAMELEON-CONTINUING-SUCCESS
    (INTERN-RIGID-SYMBOL-WRT-MODULE "CONTINUING-SUCCESS" NULL 2))
   (CL:SETQ KWD-CHAMELEON-MATCH-SCORE
    (INTERN-RIGID-SYMBOL-WRT-MODULE "MATCH-SCORE" NULL 2))
   (CL:SETQ SYM-CHAMELEON-LOGIC-STARTUP-CHAMELEON
    (INTERN-RIGID-SYMBOL-WRT-MODULE "STARTUP-CHAMELEON" NULL 0))
   (CL:SETQ SYM-CHAMELEON-STELLA-METHOD-STARTUP-CLASSNAME
    (INTERN-RIGID-SYMBOL-WRT-MODULE "METHOD-STARTUP-CLASSNAME"
     (GET-STELLA-MODULE "/STELLA" CL:T) 0))))

(CL:DEFUN HELP-STARTUP-CHAMELEON4 ()
  (CL:PROGN
   (CL:LET*
    ((CLASS
      (DEFINE-CLASS-FROM-STRINGIFIED-SOURCE "CHAMELEON-PARTIAL-MATCH"
       "(DEFCLASS CHAMELEON-PARTIAL-MATCH (INCREMENTAL-PARTIAL-MATCH) :DOCUMENTATION \"Variant of :BASIC partial match strategy to support CHAMELEON queries.\" :SLOTS ((ARGUMENT-JUSTIFICATIONS :TYPE (CONS OF JUSTIFICATION) :INITIALLY NIL :DOCUMENTATION \"Holds justifications for OR arguments and alternative rules.\") (ARGUMENT-PROPOSITIONS :TYPE (CONS OF PROPOSITION) :INITIALLY NIL :DOCUMENTATION \"Holds argument propositions in the order they are associated with scores\")))")))
    (CL:SETF (%CLASS-CONSTRUCTOR-CODE CLASS)
     (CL:FUNCTION NEW-CHAMELEON-PARTIAL-MATCH))
    (CL:SETF (%CLASS-SLOT-ACCESSOR-CODE CLASS)
     (CL:FUNCTION ACCESS-CHAMELEON-PARTIAL-MATCH-SLOT-VALUE)))
   (CL:LET*
    ((CLASS
      (DEFINE-CLASS-FROM-STRINGIFIED-SOURCE "CHAMELEON-NEURAL-NETWORK"
       "(DEFCLASS CHAMELEON-NEURAL-NETWORK (NEURAL-NETWORK) :DOCUMENTATION \"Stream-lined neural network structure that doesn't require float wrapping.\" :SLOTS ((PROPOSITION :TYPE PROPOSITION) (INPUT :TYPE FLOAT-ARRAY) (HIDDEN :TYPE FLOAT-ARRAY) (OUTPUT :TYPE FLOAT) (IH :TYPE 2D-FLOAT-ARRAY) (HO :TYPE FLOAT-ARRAY) (INPUT-ERROR :TYPE FLOAT-ARRAY) (HIDDEN-ERROR :TYPE FLOAT-ARRAY) (OUTPUT-ERROR :TYPE FLOAT) (IH-DELTA :TYPE 2D-FLOAT-ARRAY) (HO-DELTA :TYPE FLOAT-ARRAY)))")))
    (CL:SETF (%CLASS-CONSTRUCTOR-CODE CLASS)
     (CL:FUNCTION NEW-CHAMELEON-NEURAL-NETWORK))
    (CL:SETF (%CLASS-SLOT-ACCESSOR-CODE CLASS)
     (CL:FUNCTION ACCESS-CHAMELEON-NEURAL-NETWORK-SLOT-VALUE)))
   (CL:LET*
    ((CLASS
      (DEFINE-CLASS-FROM-STRINGIFIED-SOURCE "VECTOR-NEURAL-NETWORK"
       "(DEFCLASS VECTOR-NEURAL-NETWORK (NEURAL-NETWORK) :DOCUMENTATION \"Neural network that supports vector input arguments.\" :SLOTS ((N-VECTOR-ARGUMENTS :TYPE INTEGER :INITIALLY -1) (N-VECTOR-ARGUMENT-SPECS :TYPE INTEGER :INITIALLY -1) (N-VECTOR-ARGUMENT-INPUTS :TYPE INTEGER :INITIALLY -1)))")))
    (CL:SETF (%CLASS-CONSTRUCTOR-CODE CLASS)
     (CL:FUNCTION NEW-VECTOR-NEURAL-NETWORK))
    (CL:SETF (%CLASS-SLOT-ACCESSOR-CODE CLASS)
     (CL:FUNCTION ACCESS-VECTOR-NEURAL-NETWORK-SLOT-VALUE)))
   (CL:LET*
    ((CLASS
      (DEFINE-CLASS-FROM-STRINGIFIED-SOURCE "TENSORFLOW-NEURAL-NETWORK"
       "(DEFCLASS TENSORFLOW-NEURAL-NETWORK (VECTOR-NEURAL-NETWORK) :DOCUMENTATION \"Neural network that is implemented by callbacks to TensorFlow.\" :SLOTS ((PROPOSITION :TYPE PROPOSITION) (MODEL :TYPE PYTHON-OBJECT-POINTER)))")))
    (CL:SETF (%CLASS-CONSTRUCTOR-CODE CLASS)
     (CL:FUNCTION NEW-TENSORFLOW-NEURAL-NETWORK))
    (CL:SETF (%CLASS-SLOT-ACCESSOR-CODE CLASS)
     (CL:FUNCTION ACCESS-TENSORFLOW-NEURAL-NETWORK-SLOT-VALUE)))
   (CL:LET*
    ((CLASS
      (DEFINE-CLASS-FROM-STRINGIFIED-SOURCE
       "CHAMELEON-BATCH-NEURAL-NETWORK"
       "(DEFCLASS CHAMELEON-BATCH-NEURAL-NETWORK (CHAMELEON-NEURAL-NETWORK) :DOCUMENTATION \"Chameleon neural network that supports batch operations via emulation.\" :SLOTS ((INPUT-BATCH :TYPE (VECTOR-SEQUENCE OF OBJECT) :DOCUMENTATION \"Each element is a set of values that may be legally passed to `set-input-values'.\") (KEY-BATCH :TYPE (VECTOR-SEQUENCE OF OBJECT) :DOCUMENTATION \"Each element is a key to identify a specific set of input values.\") (TARGET-BATCH :TYPE (VECTOR-SEQUENCE OF FLOAT-WRAPPER) :DOCUMENTATION \"Each element is a target output value for the respective set of input values.\") (OUTPUT-BATCH :TYPE FLOAT-ARRAY) (INPUT-ERROR-BATCH :TYPE (VECTOR-SEQUENCE OF FLOAT-ARRAY) :DOCUMENTATION \"Copies of `input-error' but without the bias unit, thus shifted by 1.\")))")))
    (CL:SETF (%CLASS-CONSTRUCTOR-CODE CLASS)
     (CL:FUNCTION NEW-CHAMELEON-BATCH-NEURAL-NETWORK))
    (CL:SETF (%CLASS-SLOT-ACCESSOR-CODE CLASS)
     (CL:FUNCTION ACCESS-CHAMELEON-BATCH-NEURAL-NETWORK-SLOT-VALUE)))
   (CL:LET*
    ((CLASS
      (DEFINE-CLASS-FROM-STRINGIFIED-SOURCE "2D-LONG-ARRAY"
       "(DEFCLASS 2D-LONG-ARRAY (ABSTRACT-DIMENSIONAL-ARRAY 2-DIMENSIONAL-ARRAY-MIXIN) :DOCUMENTATION \"2-dimensional array with long integer values.\" :PUBLIC? TRUE :PARAMETERS ((ANY-VALUE :TYPE LONG-INTEGER)))")))
    (CL:SETF (%CLASS-CONSTRUCTOR-CODE CLASS)
     (CL:FUNCTION NEW-2D-LONG-ARRAY)))
   (CL:LET*
    ((CLASS
      (DEFINE-CLASS-FROM-STRINGIFIED-SOURCE
       "TENSORFLOW-BATCH-NEURAL-NETWORK"
       "(DEFCLASS TENSORFLOW-BATCH-NEURAL-NETWORK (TENSORFLOW-NEURAL-NETWORK) :DOCUMENTATION \"Tensorflow neural network that supports batch operations.  We implement input and result
batches as 1-D and 2-D float arrays to enable fast back-and-forth copying in a single shot instead of having
multiple method calls.  For this reason, we maintain the input and target sequences manually.\" :SLOTS ((INPUT-MODIFIED? :TYPE BOOLEAN :INITIALLY TRUE :DOCUMENTATION \"Cleared by Python/Tensorflow side, used to avoid unnecessary copying.\") (INPUT-BATCH :TYPE 2D-FLOAT-ARRAY :DOCUMENTATION \"Each row is a set of inputs for the input units of the network, including the bias.\") (INPUT-BATCH-LENGTH :TYPE INTEGER :INITIALLY 0) (KEY-BATCH :TYPE (VECTOR-SEQUENCE OF OBJECT) :DOCUMENTATION \"Each element is a key to identify a specific set of input values.\") (VECTOR-BATCH :TYPE 2D-LONG-ARRAY :DOCUMENTATION \"Each row is a set of vector argument specs for the inputs of the network.\") (VECTOR-BATCH-LENGTH :TYPE INTEGER :INITIALLY 0) (TARGET-BATCH :TYPE FLOAT-ARRAY :DOCUMENTATION \"Each element is a target output value for the respective set of input values.\") (TARGET-BATCH-LENGTH :TYPE INTEGER :INITIALLY 0) (OUTPUT-BATCH :TYPE FLOAT-ARRAY) (INPUT-ERROR-BATCH :TYPE 2D-FLOAT-ARRAY :DOCUMENTATION \"Each row is a set of errors the respective inputs including the bias.\")))")))
    (CL:SETF (%CLASS-CONSTRUCTOR-CODE CLASS)
     (CL:FUNCTION NEW-TENSORFLOW-BATCH-NEURAL-NETWORK))
    (CL:SETF (%CLASS-SLOT-ACCESSOR-CODE CLASS)
     (CL:FUNCTION ACCESS-TENSORFLOW-BATCH-NEURAL-NETWORK-SLOT-VALUE)))
   (CL:LET*
    ((CLASS
      (DEFINE-CLASS-FROM-STRINGIFIED-SOURCE "NETWORK-PROOF-QUEUE"
       "(DEFCLASS NETWORK-PROOF-QUEUE (STANDARD-OBJECT) :SLOTS ((DEPENDENTS :TYPE (KEY-VALUE-MAP OF JUSTIFICATION (CONS OF JUSTIFICATION)) :INITIALLY (NEW KEY-VALUE-MAP) :DOCUMENTATION \"Map from computation prerequisites to their dependents.\") (PREREQUISITES :TYPE (KEY-VALUE-MAP OF JUSTIFICATION (CONS OF JUSTIFICATION)) :INITIALLY (NEW KEY-VALUE-MAP) :DOCUMENTATION \"Map from dependents to their computation prerequisites.\") (ACTIVE-NETWORKS :TYPE (HASH-SET OF NEURAL-NETWORK NEURAL-NETWORK) :INITIALLY (NEW HASH-SET)) (MIN-BATCH-SIZE :TYPE INTEGER :INITIALLY (FLOOR (* *NEURAL-NETWORK-BATCH-SIZE* 0.8))) (N-QUEUED :TYPE INTEGER :INITIALLY 0)))")))
    (CL:SETF (%CLASS-CONSTRUCTOR-CODE CLASS)
     (CL:FUNCTION NEW-NETWORK-PROOF-QUEUE))
    (CL:SETF (%CLASS-SLOT-ACCESSOR-CODE CLASS)
     (CL:FUNCTION ACCESS-NETWORK-PROOF-QUEUE-SLOT-VALUE)))
   (CL:LET*
    ((CLASS
      (DEFINE-CLASS-FROM-STRINGIFIED-SOURCE
       "NETWORK-PROOF-FORWARD-QUEUE"
       "(DEFCLASS NETWORK-PROOF-FORWARD-QUEUE (NETWORK-PROOF-QUEUE))")))
    (CL:SETF (%CLASS-CONSTRUCTOR-CODE CLASS)
     (CL:FUNCTION NEW-NETWORK-PROOF-FORWARD-QUEUE)))
   (CL:LET*
    ((CLASS
      (DEFINE-CLASS-FROM-STRINGIFIED-SOURCE
       "NETWORK-PROOF-BACKWARD-QUEUE"
       "(DEFCLASS NETWORK-PROOF-BACKWARD-QUEUE (NETWORK-PROOF-QUEUE))")))
    (CL:SETF (%CLASS-CONSTRUCTOR-CODE CLASS)
     (CL:FUNCTION NEW-NETWORK-PROOF-BACKWARD-QUEUE)))
   (CL:LET*
    ((CLASS
      (DEFINE-CLASS-FROM-STRINGIFIED-SOURCE
       "NETWORK-PROOF-UPDATE-QUEUE"
       "(DEFCLASS NETWORK-PROOF-UPDATE-QUEUE (NETWORK-PROOF-QUEUE))")))
    (CL:SETF (%CLASS-CONSTRUCTOR-CODE CLASS)
     (CL:FUNCTION NEW-NETWORK-PROOF-UPDATE-QUEUE)))
   (CL:LET*
    ((CLASS
      (DEFINE-CLASS-FROM-STRINGIFIED-SOURCE
       "SCORED-QUERY-PROOF-ADJUNCT"
       "(DEFCLASS SCORED-QUERY-PROOF-ADJUNCT (PROOF-ADJUNCT) :SLOTS ((PARTIAL-MATCH-STRATEGY :TYPE PARTIAL-MATCH-FRAME) (DOWN-FRAME :TYPE CONTROL-FRAME)))")))
    (CL:SETF (%CLASS-CONSTRUCTOR-CODE CLASS)
     (CL:FUNCTION NEW-SCORED-QUERY-PROOF-ADJUNCT))
    (CL:SETF (%CLASS-SLOT-ACCESSOR-CODE CLASS)
     (CL:FUNCTION ACCESS-SCORED-QUERY-PROOF-ADJUNCT-SLOT-VALUE)))))

(CL:DEFUN HELP-STARTUP-CHAMELEON5 ()
  (CL:PROGN
   (DEFINE-FUNCTION-OBJECT "ENSURE-CHAMELEON-ONTOLOGY"
    "(DEFUN ENSURE-CHAMELEON-ONTOLOGY () :DOCUMENTATION \"Ensure the chameleon.plm ontology file has been loaded (assumes it exists in the current load path).\" :PUBLIC? TRUE :COMMAND? TRUE)"
    (CL:FUNCTION ENSURE-CHAMELEON-ONTOLOGY) NULL)
   (DEFINE-FUNCTION-OBJECT "GET-CHAMELEON-MODULE"
    "(DEFUN (GET-CHAMELEON-MODULE MODULE) () :DOCUMENTATION \"Return the namespace module for Chameleon relations\" :PUBLIC? TRUE)"
    (CL:FUNCTION GET-CHAMELEON-MODULE) NULL)
   (DEFINE-FUNCTION-OBJECT "CHAMELEON-VECTOR-RELATION?"
    "(DEFUN (CHAMELEON-VECTOR-RELATION? BOOLEAN) ((X OBJECT)) :DOCUMENTATION \"Return TRUE if `x' is an explicitly marked vector relation.\" :PUBLIC? TRUE :GLOBALLY-INLINE? TRUE (RETURN (TEST-PROPERTY? X /CHAMELEON/@VECTOR-RELATION)))"
    (CL:FUNCTION CHAMELEON-VECTOR-RELATION?) NULL)
   (DEFINE-FUNCTION-OBJECT "CHAMELEON-IGNORED-VALUE-RELATION?"
    "(DEFUN (CHAMELEON-IGNORED-VALUE-RELATION? BOOLEAN) ((X OBJECT)) :DOCUMENTATION \"Return TRUE if `x' is an explicitly marked as ignored or a vector relation
that is not also marked as a truth value relation.\" :PUBLIC? TRUE :GLOBALLY-INLINE? TRUE (RETURN (OR (TEST-PROPERTY? X /CHAMELEON/@IGNORED-VALUE-RELATION) (AND (TEST-PROPERTY? X /CHAMELEON/@VECTOR-RELATION) (NOT (TEST-PROPERTY? X /CHAMELEON/@TRUTH-VALUE-RELATION))))))"
    (CL:FUNCTION CHAMELEON-IGNORED-VALUE-RELATION?) NULL)
   (DEFINE-FUNCTION-OBJECT "CHAMELEON-TRUTH-VALUE-RELATION?"
    "(DEFUN (CHAMELEON-TRUTH-VALUE-RELATION? BOOLEAN) ((X OBJECT)) :DOCUMENTATION \"Return TRUE if `x' is an explicitly marked truth value relation or
otherwise not known to be ignored.\" :PUBLIC? TRUE :GLOBALLY-INLINE? TRUE (RETURN (OR (TEST-PROPERTY? X /CHAMELEON/@TRUTH-VALUE-RELATION) (NOT (CHAMELEON-IGNORED-VALUE-RELATION? X)))))"
    (CL:FUNCTION CHAMELEON-TRUTH-VALUE-RELATION?) NULL)
   (DEFINE-FUNCTION-OBJECT "CHAMELEON-PRIMITIVE-VALUE-RELATION?"
    "(DEFUN (CHAMELEON-PRIMITIVE-VALUE-RELATION? BOOLEAN) ((X OBJECT)) :DOCUMENTATION \"Return TRUE if `x' is an explicitly marked primitive value relation.\" :PUBLIC? TRUE :GLOBALLY-INLINE? TRUE (RETURN (TEST-PROPERTY? X /CHAMELEON/@PRIMITIVE-VALUE-RELATION)))"
    (CL:FUNCTION CHAMELEON-PRIMITIVE-VALUE-RELATION?) NULL)
   (DEFINE-FUNCTION-OBJECT "CHAMELEON-PARTIAL-MATCH-MODE?"
    "(DEFUN (CHAMELEON-PARTIAL-MATCH-MODE? BOOLEAN) () :DOCUMENTATION \"Return TRUE if a query is computing Chameleon partial matches.\" :GLOBALLY-INLINE? TRUE (RETURN (AND (PARTIAL-MATCH-MODE?) (ISA? (PARTIAL-MATCH-STRATEGY *QUERYITERATOR*) @CHAMELEON-PARTIAL-MATCH))))"
    (CL:FUNCTION CHAMELEON-PARTIAL-MATCH-MODE?) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (CREATE-PARTIAL-MATCH-FRAME CHAMELEON-PARTIAL-MATCH) ((SELF CHAMELEON-PARTIAL-MATCH) (FRAME CONTROL-FRAME) (KIND KEYWORD)))"
    (WRAP-METHOD-CODE (CL:FUNCTION CREATE-PARTIAL-MATCH-FRAME)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (COMPUTE-DYNAMIC-CUTOFF PARTIAL-MATCH-SCORE) ((SELF CHAMELEON-PARTIAL-MATCH)))"
    (WRAP-METHOD-CODE (CL:FUNCTION COMPUTE-DYNAMIC-CUTOFF)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (CUTOFF-PARTIAL-MATCH? BOOLEAN) ((SELF CHAMELEON-PARTIAL-MATCH) (TRACE? BOOLEAN)))"
    (WRAP-METHOD-CODE (CL:FUNCTION CUTOFF-PARTIAL-MATCH?)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (TRUTH-VALUE-SCORE PARTIAL-MATCH-SCORE) ((SELF CHAMELEON-PARTIAL-MATCH) (TRUTHVALUE TRUTH-VALUE)))"
    (WRAP-METHOD-CODE (CL:FUNCTION TRUTH-VALUE-SCORE)) NULL)
   (DEFINE-FUNCTION-OBJECT "INVERT-CHAMELEON-MATCH-SCORE"
    "(DEFUN (INVERT-CHAMELEON-MATCH-SCORE PARTIAL-MATCH-SCORE) ((SCORE PARTIAL-MATCH-SCORE)))"
    (CL:FUNCTION INVERT-CHAMELEON-MATCH-SCORE) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (INVERT-MATCH-SCORE PARTIAL-MATCH-SCORE) ((SELF CHAMELEON-PARTIAL-MATCH) (SCORE PARTIAL-MATCH-SCORE)))"
    (WRAP-METHOD-CODE (CL:FUNCTION INVERT-MATCH-SCORE)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (PROPOSITION-WEIGHT FLOAT) ((SELF CHAMELEON-PARTIAL-MATCH) (PROPOSITION PROPOSITION)))"
    (WRAP-METHOD-CODE (CL:FUNCTION PROPOSITION-WEIGHT)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD PUSH-AND-PARTIAL-MATCH-SCORE ((SELF CHAMELEON-PARTIAL-MATCH) (SCORE PARTIAL-MATCH-SCORE) (WEIGHT FLOAT)))"
    (WRAP-METHOD-CODE (CL:FUNCTION PUSH-AND-PARTIAL-MATCH-SCORE)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD POP-AND-PARTIAL-MATCH-SCORE ((SELF CHAMELEON-PARTIAL-MATCH)))"
    (WRAP-METHOD-CODE (CL:FUNCTION POP-AND-PARTIAL-MATCH-SCORE)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD PUSH-OR-PARTIAL-MATCH-SCORE ((SELF CHAMELEON-PARTIAL-MATCH) (SCORE PARTIAL-MATCH-SCORE) (WEIGHT FLOAT)))"
    (WRAP-METHOD-CODE (CL:FUNCTION PUSH-OR-PARTIAL-MATCH-SCORE)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD POP-OR-PARTIAL-MATCH-SCORE ((SELF CHAMELEON-PARTIAL-MATCH)))"
    (WRAP-METHOD-CODE (CL:FUNCTION POP-OR-PARTIAL-MATCH-SCORE)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (ALLOW-UNBOUND-VARIABLES? BOOLEAN) ((SELF CHAMELEON-PARTIAL-MATCH)))"
    (WRAP-METHOD-CODE (CL:FUNCTION ALLOW-UNBOUND-VARIABLES?)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (COMPUTE-AND-SCORE PARTIAL-MATCH-SCORE) ((SELF CHAMELEON-PARTIAL-MATCH)))"
    (WRAP-METHOD-CODE (CL:FUNCTION COMPUTE-AND-SCORE)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (CONTINUE-PARTIAL-AND-PROOF KEYWORD) ((SELF CHAMELEON-PARTIAL-MATCH) (FRAME CONTROL-FRAME) (LASTMOVE KEYWORD)))"
    (WRAP-METHOD-CODE (CL:FUNCTION CONTINUE-PARTIAL-AND-PROOF)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (COMPUTE-OR-SCORE PARTIAL-MATCH-SCORE) ((SELF CHAMELEON-PARTIAL-MATCH)))"
    (WRAP-METHOD-CODE (CL:FUNCTION COMPUTE-OR-SCORE)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (CONTINUE-PARTIAL-OR-PROOF KEYWORD) ((SELF CHAMELEON-PARTIAL-MATCH) (LASTMOVE KEYWORD)))"
    (WRAP-METHOD-CODE (CL:FUNCTION CONTINUE-PARTIAL-OR-PROOF)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (COMPUTE-NOT-SCORE PARTIAL-MATCH-SCORE) ((SELF CHAMELEON-PARTIAL-MATCH)))"
    (WRAP-METHOD-CODE (CL:FUNCTION COMPUTE-NOT-SCORE)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (CONTINUE-PARTIAL-NOT-PROOF KEYWORD) ((SELF CHAMELEON-PARTIAL-MATCH) (LASTMOVE KEYWORD)))"
    (WRAP-METHOD-CODE (CL:FUNCTION CONTINUE-PARTIAL-NOT-PROOF)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (CONTINUE-PARTIAL-FAIL-PROOF KEYWORD) ((SELF CHAMELEON-PARTIAL-MATCH) (LASTMOVE KEYWORD)))"
    (WRAP-METHOD-CODE (CL:FUNCTION CONTINUE-PARTIAL-FAIL-PROOF)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (COMPUTE-GOAL-SCORE PARTIAL-MATCH-SCORE) ((SELF CHAMELEON-PARTIAL-MATCH)))"
    (WRAP-METHOD-CODE (CL:FUNCTION COMPUTE-GOAL-SCORE)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (CONTINUE-PARTIAL-STRATEGIES-PROOFS KEYWORD) ((SELF CHAMELEON-PARTIAL-MATCH) (LASTMOVE KEYWORD)))"
    (WRAP-METHOD-CODE (CL:FUNCTION CONTINUE-PARTIAL-STRATEGIES-PROOFS))
    NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (CONTINUE-PARTIAL-ANTECEDENTS-PROOF KEYWORD) ((SELF CHAMELEON-PARTIAL-MATCH) (LASTMOVE KEYWORD)))"
    (WRAP-METHOD-CODE (CL:FUNCTION CONTINUE-PARTIAL-ANTECEDENTS-PROOF))
    NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (COMPUTE-PARTIAL-TRUTH FLOAT) ((SELF CHAMELEON-PARTIAL-MATCH) (QUERY QUERY-ITERATOR)))"
    (WRAP-METHOD-CODE (CL:FUNCTION COMPUTE-PARTIAL-TRUTH)) NULL)
   (DEFINE-FUNCTION-OBJECT "REGISTER-NEURAL-NETWORK"
    "(DEFUN REGISTER-NEURAL-NETWORK ((SELF NEURAL-NETWORK)) :DOCUMENTATION \"Register the network `self' on the global networks list (assumes `self' has been linked).\" :PUBLIC? TRUE)"
    (CL:FUNCTION REGISTER-NEURAL-NETWORK) NULL)
   (DEFINE-FUNCTION-OBJECT "UNREGISTER-NEURAL-NETWORK"
    "(DEFUN UNREGISTER-NEURAL-NETWORK ((SELF NEURAL-NETWORK)) :DOCUMENTATION \"Unregister the network `self' on the global networks list.\" :PUBLIC? TRUE)"
    (CL:FUNCTION UNREGISTER-NEURAL-NETWORK) NULL)
   (DEFINE-FUNCTION-OBJECT "LOOKUP-PROPOSITION-NEURAL-NETWORK"
    "(DEFUN (LOOKUP-PROPOSITION-NEURAL-NETWORK NEURAL-NETWORK) ((PROP PROPOSITION)) :DOCUMENTATION \"Lookup the neural network for `prop' in the global networks list.\" :PUBLIC? TRUE)"
    (CL:FUNCTION LOOKUP-PROPOSITION-NEURAL-NETWORK) NULL)
   (DEFINE-FUNCTION-OBJECT "DELETE-NEURAL-NETWORKS"
    "(DEFUN DELETE-NEURAL-NETWORKS () :DOCUMENTATION \"Eliminate all neural networks and remove any connections
to propositions and training examples.\" :COMMAND? TRUE :PUBLIC? TRUE)"
    (CL:FUNCTION DELETE-NEURAL-NETWORKS) NULL)
   (DEFINE-FUNCTION-OBJECT "RANDOMIZE-NEURAL-NETWORKS"
    "(DEFUN RANDOMIZE-NEURAL-NETWORKS () :DOCUMENTATION \"Undo all training and randomize weights in all neural networks.\" :COMMAND? TRUE :PUBLIC? TRUE)"
    (CL:FUNCTION RANDOMIZE-NEURAL-NETWORKS) NULL)
   (DEFINE-FUNCTION-OBJECT "CREATE-AND-LINK-NEURAL-NETWORK"
    "(DEFUN CREATE-AND-LINK-NEURAL-NETWORK ((PROP PROPOSITION)))"
    (CL:FUNCTION CREATE-AND-LINK-NEURAL-NETWORK) NULL)
   (DEFINE-FUNCTION-OBJECT "GET-PROPOSITION-NEURAL-NETWORK"
    "(DEFUN (GET-PROPOSITION-NEURAL-NETWORK NEURAL-NETWORK) ((PROP PROPOSITION) (ERROR? BOOLEAN)) :DOCUMENTATION \"Return the neural network associated with `prop'.  If `error?', raise an
exception if it cannot be found, otherwise, simply return NULL.\" :PUBLIC? TRUE)"
    (CL:FUNCTION GET-PROPOSITION-NEURAL-NETWORK) NULL)
   (DEFINE-FUNCTION-OBJECT "GET-JUSTIFICATION-NEURAL-NETWORK"
    "(DEFUN (GET-JUSTIFICATION-NEURAL-NETWORK NEURAL-NETWORK) ((JUST JUSTIFICATION)) :DOCUMENTATION \"Return the neural network associated with an :AND or :OR justification.
Raise an error if the associated proposition is not linked to a neural network.\")"
    (CL:FUNCTION GET-JUSTIFICATION-NEURAL-NETWORK) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD LINK-NEURAL-NETWORK ((SELF NEURAL-NETWORK) (PROP PROPOSITION)) :DOCUMENTATION \"Link the network `self' to its associated proposition `prop'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION LINK-NEURAL-NETWORK)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD UNLINK-NEURAL-NETWORK ((SELF NEURAL-NETWORK)) :DOCUMENTATION \"Unlink the network `self' from its associated proposition.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION UNLINK-NEURAL-NETWORK)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (GET-NEURAL-NETWORK-PROPOSITION PROPOSITION) ((SELF NEURAL-NETWORK)) :DOCUMENTATION \"Return the proposition linked to `self'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION GET-NEURAL-NETWORK-PROPOSITION))
    NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD DELETE-NEURAL-NETWORK ((SELF NEURAL-NETWORK)) :DOCUMENTATION \"Unlink the network `self' from its associated proposition and mark it as deleted.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION DELETE-NEURAL-NETWORK)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (DELETED? BOOLEAN) ((SELF NEURAL-NETWORK)) :DOCUMENTATION \"Return trun if `self' has been deleted.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION DELETED?)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD ALLOCATE-NETWORK-ARRAYS ((SELF NEURAL-NETWORK) (NUM-IN INTEGER) (NUM-HIDDEN INTEGER) (NUM-OUT INTEGER)) :DOCUMENTATION \"Allocates array space for a neural network with given number of input, hidden and output units.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION ALLOCATE-NETWORK-ARRAYS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD RANDOMIZE-NETWORK-WEIGHTS ((SELF NEURAL-NETWORK)) :DOCUMENTATION \"Randomize the weights of the neural network `self'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION RANDOMIZE-NETWORK-WEIGHTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD BUILD-PROPOSITION-NETWORK ((SELF NEURAL-NETWORK) (PROP PROPOSITION)) :DOCUMENTATION \"Build a neural network for the proposition `prop' and link them.  This builds
a two-layer perceptron network whose input nodes are activated by the truth of `prop's arguments
and whose output node computes the truth of `prop'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION BUILD-PROPOSITION-NETWORK)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NUMBER-OF-INPUTS INTEGER) ((SELF NEURAL-NETWORK)) :DOCUMENTATION \"Return the number of input values expected by `self' (ignores bias unit).\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION NUMBER-OF-INPUTS)) NULL)
   (DEFINE-FUNCTION-OBJECT "HELP-COMPUTE-ARGUMENT-INDEX"
    "(DEFUN (HELP-COMPUTE-ARGUMENT-INDEX INTEGER) ((SELF NEURAL-NETWORK) (ARG PROPOSITION) (KIND KEYWORD)) :DOCUMENTATION \"Memoizable helper function for `truth-value-argument-index' and friends.\" :PUBLIC? TRUE)"
    (CL:FUNCTION HELP-COMPUTE-ARGUMENT-INDEX) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (TRUTH-VALUE-ARGUMENT? BOOLEAN) ((SELF NEURAL-NETWORK) (ARG PROPOSITION)) :DOCUMENTATION \"Return TRUE if the partial truth value of `arg' will be considered for `self's inputs.
This top-level method only looks at `arg' and ignores `self'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION TRUTH-VALUE-ARGUMENT?)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NUMBER-OF-TRUTH-VALUE-ARGUMENTS INTEGER) ((SELF NEURAL-NETWORK) (PROP PROPOSITION)) :DOCUMENTATION \"Return the number of arguments of `prop' whose partial truth value will be considered
for `self's inputs.  This top-level method only looks at `prop' and ignores `self'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION NUMBER-OF-TRUTH-VALUE-ARGUMENTS))
    NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (TRUTH-VALUE-ARGUMENT-INDEX INTEGER) ((SELF NEURAL-NETWORK) (ARG PROPOSITION)) :DOCUMENTATION \"Return the 0-based input position of truth value argument `arg'.  Ignores bias unit which
is a network-implementation-specific detail.  Generates indices in the order expected by `set-input-values'.
If `arg' is not a truth value argument, returns -1.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION TRUTH-VALUE-ARGUMENT-INDEX)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (IGNORED-VALUE-ARGUMENT? BOOLEAN) ((SELF NEURAL-NETWORK) (ARG PROPOSITION)) :DOCUMENTATION \"Return TRUE if the partial truth value of `arg' will be ignored for `self's inputs.
This top-level method only looks at `arg' and ignores `self'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION IGNORED-VALUE-ARGUMENT?)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NUMBER-OF-IGNORED-VALUE-ARGUMENTS INTEGER) ((SELF NEURAL-NETWORK) (PROP PROPOSITION)) :DOCUMENTATION \"Return the number of arguments of `prop' whose partial truth value will be ignored
for `self's inputs.  This top-level method only looks at `prop' and ignores `self'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION NUMBER-OF-IGNORED-VALUE-ARGUMENTS))
    NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (VECTOR-ARGUMENT? BOOLEAN) ((SELF NEURAL-NETWORK) (ARG PROPOSITION)) :DOCUMENTATION \"Return TRUE if `arg' yields one or more vectors for `self's inputs.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION VECTOR-ARGUMENT?)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (HAS-VECTOR-ARGUMENTS? BOOLEAN) ((SELF NEURAL-NETWORK)) :DOCUMENTATION \"Return TRUE if `self' has at least one vector input argument.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION HAS-VECTOR-ARGUMENTS?)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NUMBER-OF-VECTOR-ARGUMENTS INTEGER) ((SELF NEURAL-NETWORK) (PROP PROPOSITION)) :DOCUMENTATION \"Return the number of arguments of `prop' that yield one or more vectors
for `self's inputs.  `prop' can be NULL in which case the linked proposition will be used.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION NUMBER-OF-VECTOR-ARGUMENTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (VECTOR-ARGUMENT-INDEX INTEGER) ((SELF NEURAL-NETWORK) (ARG PROPOSITION)) :DOCUMENTATION \"Return the 0-based input position of vector argument `arg'.  Ignores bias unit which
is a network-implementation-specific detail.  If `arg' is not a vector argument, returns -1.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION VECTOR-ARGUMENT-INDEX)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NTH-INPUT FLOAT) ((SELF NEURAL-NETWORK) (N INTEGER)) :DOCUMENTATION \"Return the 0-based `n'-th proposition input of `self' (ignores bias unit).\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION NTH-INPUT)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NTH-INPUT-ERROR FLOAT) ((SELF NEURAL-NETWORK) (N INTEGER)) :DOCUMENTATION \"Return the 0-based `n'-th proposition input error of `self' (ignores bias unit).\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION NTH-INPUT-ERROR)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD SET-INPUT-VALUES ((SELF NEURAL-NETWORK) (VALUES OBJECT)) :DOCUMENTATION \"Set the current truth-value inputs of the network `self' to float `values' in sequence.
Missing inputs will be set to 0.0, extra values will be ignored.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION SET-INPUT-VALUES)) NULL)))

(CL:DEFUN HELP-STARTUP-CHAMELEON6 ()
  (CL:PROGN
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD SET-VECTOR-INPUT-VALUES ((SELF NEURAL-NETWORK) (VECTORSPECS OBJECT)) :DOCUMENTATION \"Set the current vector inputs of the network `self' to the vectors described by `vectorSpecs'.
Each vector spec describes a vector-generating proposition that produces one or more vectors.  How those specs
are translated into actual numeric vectors such as embeddings is specific to the particular neural network type.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION SET-VECTOR-INPUT-VALUES)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (GET-VECTOR-ARGUMENT-SPEC OBJECT) ((SELF NEURAL-NETWORK) (ARG OBJECT)) :DOCUMENTATION \"Generate a single argument spec for `arg' that can be used for `set-vector-input-values'.
`arg' can either be a proposition or justification.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION GET-VECTOR-ARGUMENT-SPEC)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (FORWARD-PROPAGATE-INPUTS FLOAT) ((SELF NEURAL-NETWORK)) :DOCUMENTATION \"Activates the current inputs of the network `self' to compute its output.
Sets `self's `output' slot and returns the computed value.  Reads input activations and
weights and updates hidden and output activations.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION FORWARD-PROPAGATE-INPUTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD BACKWARD-PROPAGATE-ERROR ((SELF NEURAL-NETWORK) (ERROR FLOAT)) :DOCUMENTATION \"Given a properly forward activated network `self' for the current set of inputs,
and a training `error' between the current output and the goal value, backpropagate the error and
update `self's vector of input errors.  Reads output, hidden activations and weights and updates
hidden errors and input errors.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION BACKWARD-PROPAGATE-ERROR)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD UPDATE-NETWORK-WEIGHTS ((SELF NEURAL-NETWORK) (ERROR FLOAT)) :DOCUMENTATION \"Given a properly forward activated and backpropagated network `self' for the current
inputs and training `error', update the network's weights according to current gradients, learning rate
and momentum terms to reduce the error for the given inputs.  Reads output, hidden and input activations,
hidden error, weights and weight deltas, and updates weights and weight deltas.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION UPDATE-NETWORK-WEIGHTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD LINK-NEURAL-NETWORK ((SELF PROPOSITION-NEURAL-NETWORK) (PROP PROPOSITION)) :DOCUMENTATION \"Link the network `self' to its associated proposition `prop'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION LINK-NEURAL-NETWORK)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD UNLINK-NEURAL-NETWORK ((SELF PROPOSITION-NEURAL-NETWORK)) :DOCUMENTATION \"Unlink the network `self' from its associated proposition.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION UNLINK-NEURAL-NETWORK)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (GET-NEURAL-NETWORK-PROPOSITION PROPOSITION) ((SELF PROPOSITION-NEURAL-NETWORK)) :DOCUMENTATION \"Return the proposition linked to `self'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION GET-NEURAL-NETWORK-PROPOSITION))
    NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD DELETE-NEURAL-NETWORK ((SELF PROPOSITION-NEURAL-NETWORK)) :DOCUMENTATION \"Unlink the network `self' from its associated proposition and mark it as deleted.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION DELETE-NEURAL-NETWORK)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (DELETED? BOOLEAN) ((SELF PROPOSITION-NEURAL-NETWORK)) :DOCUMENTATION \"Return trun if `self' has been deleted.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION DELETED?)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD ALLOCATE-NETWORK-ARRAYS ((SELF PROPOSITION-NEURAL-NETWORK) (NUM-IN INTEGER) (NUM-HIDDEN INTEGER) (NUM-OUT INTEGER)) :DOCUMENTATION \"Allocates array space for a neural network with given number of input, hidden and output units.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION ALLOCATE-NETWORK-ARRAYS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD RANDOMIZE-NETWORK-WEIGHTS ((SELF PROPOSITION-NEURAL-NETWORK)) :DOCUMENTATION \"Randomize the weights of the neural network `self'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION RANDOMIZE-NETWORK-WEIGHTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD BUILD-PROPOSITION-NETWORK ((SELF PROPOSITION-NEURAL-NETWORK) (PROP PROPOSITION)) :DOCUMENTATION \"Build a neural network for the proposition `prop'.  This builds a two-layer
perceptron network whose input nodes are activated by the truth of `prop's arguments and whose
output node computes the truth of `prop'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION BUILD-PROPOSITION-NETWORK)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NUMBER-OF-INPUTS INTEGER) ((SELF PROPOSITION-NEURAL-NETWORK)) :DOCUMENTATION \"Return the number of input values expected by `self' (ignores bias unit).\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION NUMBER-OF-INPUTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NTH-INPUT FLOAT) ((SELF PROPOSITION-NEURAL-NETWORK) (N INTEGER)) :DOCUMENTATION \"Return the 0-based `n'-th proposition input of `self' (ignores bias unit).\" :PUBLIC? TRUE :GLOBALLY-INLINE? TRUE (RETURN (NTH (INPUT SELF) (1+ N))))"
    (WRAP-METHOD-CODE (CL:FUNCTION NTH-INPUT)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NTH-INPUT-ERROR FLOAT) ((SELF PROPOSITION-NEURAL-NETWORK) (N INTEGER)) :DOCUMENTATION \"Return the 0-based `n'-th proposition input error of `self' (ignores bias unit).\" :PUBLIC? TRUE :GLOBALLY-INLINE? TRUE (RETURN (NTH (INPUT-ERROR SELF) (1+ N))))"
    (WRAP-METHOD-CODE (CL:FUNCTION NTH-INPUT-ERROR)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD SET-INPUT-VALUES ((SELF PROPOSITION-NEURAL-NETWORK) (VALUES OBJECT)) :DOCUMENTATION \"Set the current truth-value inputs of the network `self' to float `values' in sequence.
Missing inputs will be set to 0.0, extra values will be ignored.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION SET-INPUT-VALUES)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (FORWARD-PROPAGATE-INPUTS FLOAT) ((SELF PROPOSITION-NEURAL-NETWORK)) :DOCUMENTATION \"Activates the current inputs of the network `self' to compute its output.
Sets `self's `output' slot and returns the computed value.  Reads input activations and
weights and updates hidden and output activations.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION FORWARD-PROPAGATE-INPUTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD BACKWARD-PROPAGATE-ERROR ((SELF PROPOSITION-NEURAL-NETWORK) (ERROR FLOAT)) :DOCUMENTATION \"Given a properly forward activated network `self' for the current set of inputs,
and a training `error' between the current output and the goal value, backpropagate the error and
update `self's vector of input errors.  Reads output, hidden activations and weights and updates
hidden errors and input errors.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION BACKWARD-PROPAGATE-ERROR)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD UPDATE-NETWORK-WEIGHTS ((SELF PROPOSITION-NEURAL-NETWORK) (ERROR FLOAT)) :DOCUMENTATION \"Given a properly forward activated and backpropagated network `self' for the current
inputs and training `error', update the network's weights according to current gradients, learning rate
and momentum terms to reduce the error for the given inputs.  Reads output, hidden and input activations,
hidden error, weights and weight deltas, and updates weights and weight deltas.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION UPDATE-NETWORK-WEIGHTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD LINK-NEURAL-NETWORK ((SELF CHAMELEON-NEURAL-NETWORK) (PROP PROPOSITION)) :DOCUMENTATION \"Link the network `self' to its associated proposition `prop'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION LINK-NEURAL-NETWORK)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD UNLINK-NEURAL-NETWORK ((SELF CHAMELEON-NEURAL-NETWORK)) :DOCUMENTATION \"Unlink the network `self' from its associated proposition.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION UNLINK-NEURAL-NETWORK)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (GET-NEURAL-NETWORK-PROPOSITION PROPOSITION) ((SELF CHAMELEON-NEURAL-NETWORK)) :DOCUMENTATION \"Return the proposition linked to `self'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION GET-NEURAL-NETWORK-PROPOSITION))
    NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD DELETE-NEURAL-NETWORK ((SELF CHAMELEON-NEURAL-NETWORK)) :DOCUMENTATION \"Unlink the network `self' from its associated proposition and mark it as deleted.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION DELETE-NEURAL-NETWORK)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (DELETED? BOOLEAN) ((SELF CHAMELEON-NEURAL-NETWORK)) :DOCUMENTATION \"Return trun if `self' has been deleted.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION DELETED?)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD ALLOCATE-NETWORK-ARRAYS ((SELF CHAMELEON-NEURAL-NETWORK) (NUM-IN INTEGER) (NUM-HIDDEN INTEGER) (NUM-OUT INTEGER)) :DOCUMENTATION \"Allocates array space for a neural network with given number of input, hidden and output units.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION ALLOCATE-NETWORK-ARRAYS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD RANDOMIZE-NETWORK-WEIGHTS ((SELF CHAMELEON-NEURAL-NETWORK)) :DOCUMENTATION \"Randomize the weights of the neural network `self'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION RANDOMIZE-NETWORK-WEIGHTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD BUILD-PROPOSITION-NETWORK ((SELF CHAMELEON-NEURAL-NETWORK) (PROP PROPOSITION)) :DOCUMENTATION \"Build a neural network for the proposition `prop'.  This builds a two-layer
perceptron network whose input nodes are activated by the truth of `prop's arguments and whose
output node computes the truth of `prop'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION BUILD-PROPOSITION-NETWORK)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NUMBER-OF-INPUTS INTEGER) ((SELF CHAMELEON-NEURAL-NETWORK)) :DOCUMENTATION \"Return the number of input values expected by `self' (ignores bias unit).\" :PUBLIC? TRUE :GLOBALLY-INLINE? TRUE (RETURN (1- (DIM1 (INPUT SELF)))))"
    (WRAP-METHOD-CODE (CL:FUNCTION NUMBER-OF-INPUTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NTH-INPUT FLOAT) ((SELF CHAMELEON-NEURAL-NETWORK) (N INTEGER)) :DOCUMENTATION \"Return the 0-based `n'-th proposition input of `self' (ignores bias unit).\" :PUBLIC? TRUE :GLOBALLY-INLINE? TRUE (RETURN (1D-AREF (INPUT SELF) (1+ N))))"
    (WRAP-METHOD-CODE (CL:FUNCTION NTH-INPUT)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NTH-INPUT-ERROR FLOAT) ((SELF CHAMELEON-NEURAL-NETWORK) (N INTEGER)) :DOCUMENTATION \"Return the 0-based `n'-th proposition input error of `self' (ignores bias unit).\" :PUBLIC? TRUE :GLOBALLY-INLINE? TRUE (RETURN (1D-AREF (INPUT-ERROR SELF) (1+ N))))"
    (WRAP-METHOD-CODE (CL:FUNCTION NTH-INPUT-ERROR)) NULL)
   (DEFINE-FUNCTION-OBJECT "COPY-FLOAT-VALUES-TO-BUFFER"
    "(DEFUN COPY-FLOAT-VALUES-TO-BUFFER ((VALUES OBJECT) (BUFFER (ARRAY () OF FLOAT)) (START INTEGER) (END INTEGER)) :DOCUMENTATION \"Copy the float `values' in sequence to `buffer' between `start' and `end'.
Missing values will be set to 0.0, extra values will be ignored.\" :PUBLIC? TRUE)"
    (CL:FUNCTION COPY-FLOAT-VALUES-TO-BUFFER) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD SET-INPUT-VALUES ((SELF CHAMELEON-NEURAL-NETWORK) (VALUES OBJECT)) :DOCUMENTATION \"Set the current truth-value inputs of the network `self' to float `values' in sequence.
Missing inputs will be set to 0.0, extra values will be ignored.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION SET-INPUT-VALUES)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD SET-VECTOR-INPUT-VALUES ((SELF CHAMELEON-NEURAL-NETWORK) (VECTORSPECS OBJECT)) :DOCUMENTATION \"Set the current vector inputs of the network `self' to the vectors described by `vectorSpecs'.
Each vector spec describes a vector-generating proposition that produces one or more vectors.  How those specs
are translated into actual numeric vectors such as embeddings is specific to the particular neural network type.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION SET-VECTOR-INPUT-VALUES)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (FORWARD-PROPAGATE-INPUTS FLOAT) ((SELF CHAMELEON-NEURAL-NETWORK)) :DOCUMENTATION \"Activates the current inputs of the network `self' to compute its output.
Sets `self's `output' slot and returns the computed value.  Reads input activations and
weights and updates hidden and output activations.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION FORWARD-PROPAGATE-INPUTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD BACKWARD-PROPAGATE-ERROR ((SELF CHAMELEON-NEURAL-NETWORK) (ERROR FLOAT)) :DOCUMENTATION \"Given a properly forward activated network `self' for the current set of inputs,
and a training `error' between the current output and the goal value, backpropagate the error and
update `self's vector of input errors.  Reads output, hidden activations and weights and updates
hidden errors and input errors.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION BACKWARD-PROPAGATE-ERROR)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD UPDATE-NETWORK-WEIGHTS ((SELF CHAMELEON-NEURAL-NETWORK) (ERROR FLOAT)) :DOCUMENTATION \"Given a properly forward activated and backpropagated network `self' for the current
inputs and training `error', update the network's weights according to current gradients, learning rate
and momentum terms to reduce the error for the given inputs.  Reads output, hidden and input activations,
hidden error, weights and weight deltas, and updates weights and weight deltas.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION UPDATE-NETWORK-WEIGHTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (VECTOR-ARGUMENT? BOOLEAN) ((SELF VECTOR-NEURAL-NETWORK) (ARG PROPOSITION)) :DOCUMENTATION \"Return TRUE if `arg' yields one or more vectors for `self's inputs.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION VECTOR-ARGUMENT?)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (HAS-VECTOR-ARGUMENTS? BOOLEAN) ((SELF VECTOR-NEURAL-NETWORK)) :DOCUMENTATION \"Return TRUE if `self' has at least one vector input argument.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION HAS-VECTOR-ARGUMENTS?)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NUMBER-OF-VECTOR-ARGUMENTS INTEGER) ((SELF VECTOR-NEURAL-NETWORK) (PROP PROPOSITION)) :DOCUMENTATION \"Return the number of arguments of `prop' that yield one or more vectors
for `self's inputs.  `prop' can be NULL in which case the linked proposition will be used.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION NUMBER-OF-VECTOR-ARGUMENTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (VECTOR-ARGUMENT-INDEX INTEGER) ((SELF VECTOR-NEURAL-NETWORK) (ARG PROPOSITION)) :DOCUMENTATION \"Return the 0-based input position of vector argument `arg'.  Ignores bias unit which
is a network-implementation-specific detail.  If `arg' is not a vector argument, returns -1.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION VECTOR-ARGUMENT-INDEX)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NUMBER-OF-VECTOR-ARGUMENT-SPECS INTEGER) ((SELF VECTOR-NEURAL-NETWORK) (PROP PROPOSITION)) :DOCUMENTATION \"Return the total number of argument specs generated by vector arguments of `prop'.
This is only different than `number-of-vector-arguments' if at least one of `prop's vector argument
relations has arity > 1.  `prop' can be NULL in which case the linked proposition will be used.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION NUMBER-OF-VECTOR-ARGUMENT-SPECS))
    NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NUMBER-OF-VECTOR-ARGUMENT-INPUTS INTEGER) ((SELF VECTOR-NEURAL-NETWORK) (PROP PROPOSITION)) :DOCUMENTATION \"Return the total number of input positions to store all elements of all vector
arguments of `prop'.  `prop' can be NULL in which case the linked proposition will be used.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION NUMBER-OF-VECTOR-ARGUMENT-INPUTS))
    NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD SET-VECTOR-INPUT-VALUES ((SELF VECTOR-NEURAL-NETWORK) (VECTORSPECS OBJECT)) :DOCUMENTATION \"Set the current vector inputs of the network `self' to the vectors described by `vectorSpecs'.
Each vector spec describes a vector-generating proposition that produces one or more vectors.  How those specs
are translated into actual numeric vectors such as embeddings is specific to the particular neural network type.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION SET-VECTOR-INPUT-VALUES)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (GET-VECTOR-ARGUMENT-SPEC OBJECT) ((SELF VECTOR-NEURAL-NETWORK) (ARG OBJECT)) :DOCUMENTATION \"Generate a single argument spec for `arg' that can be used for `set-vector-input-values'.
`arg' can either be a proposition or justification.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION GET-VECTOR-ARGUMENT-SPEC)) NULL)
   (DEFINE-FUNCTION-OBJECT "REGISTER-TENSORFLOW-CALLBACK"
    "(DEFUN REGISTER-TENSORFLOW-CALLBACK ((NAME STRING) (CODE FUNCTION-CODE)) :DOCUMENTATION \"Special-purpose callback support that registers `code' under the logic symbol with `name',
which by convention we make the qualified method name of the method we are using this for.  This is a
special-purpose hack which eventually we might want to generalize so others can use it too.\" :PUBLIC? TRUE)"
    (CL:FUNCTION REGISTER-TENSORFLOW-CALLBACK) NULL)
   (DEFINE-FUNCTION-OBJECT "GET-TENSORFLOW-CALLBACK"
    "(DEFUN (GET-TENSORFLOW-CALLBACK FUNCTION-CODE) ((NAME SYMBOL)) :DOCUMENTATION \"Access the TensorFlow callback code registered under `name'.\" :PUBLIC? TRUE :GLOBALLY-INLINE? TRUE (RETURN (SYMBOL-VALUE NAME)))"
    (CL:FUNCTION GET-TENSORFLOW-CALLBACK) NULL)
   (DEFINE-FUNCTION-OBJECT "TENSORFLOW-BACKEND-AVAILABLE?"
    "(DEFUN (TENSORFLOW-BACKEND-AVAILABLE? BOOLEAN) () :DOCUMENTATION \"Return TRUE if TensorFlow callbacks have been properly registered.\" :PUBLIC? TRUE)"
    (CL:FUNCTION TENSORFLOW-BACKEND-AVAILABLE?) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD LINK-NEURAL-NETWORK ((SELF TENSORFLOW-NEURAL-NETWORK) (PROP PROPOSITION)) :DOCUMENTATION \"Link the network `self' to its associated proposition `prop'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION LINK-NEURAL-NETWORK)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD UNLINK-NEURAL-NETWORK ((SELF TENSORFLOW-NEURAL-NETWORK)) :DOCUMENTATION \"Unlink the network `self' from its associated proposition.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION UNLINK-NEURAL-NETWORK)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (GET-NEURAL-NETWORK-PROPOSITION PROPOSITION) ((SELF TENSORFLOW-NEURAL-NETWORK)) :DOCUMENTATION \"Return the proposition linked to `self'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION GET-NEURAL-NETWORK-PROPOSITION))
    NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD DELETE-NEURAL-NETWORK ((SELF TENSORFLOW-NEURAL-NETWORK)) :DOCUMENTATION \"Unlink the network `self' from its associated proposition and mark it as deleted.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION DELETE-NEURAL-NETWORK)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (DELETED? BOOLEAN) ((SELF TENSORFLOW-NEURAL-NETWORK)) :DOCUMENTATION \"Return trun if `self' has been deleted.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION DELETED?)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD ALLOCATE-NETWORK-ARRAYS ((SELF TENSORFLOW-NEURAL-NETWORK) (NUM-IN INTEGER) (NUM-HIDDEN INTEGER) (NUM-OUT INTEGER)) :DOCUMENTATION \"Allocates array space for a neural network with given number of input, hidden and output units.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION ALLOCATE-NETWORK-ARRAYS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD RANDOMIZE-NETWORK-WEIGHTS ((SELF TENSORFLOW-NEURAL-NETWORK)) :DOCUMENTATION \"Randomize the weights of the neural network `self'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION RANDOMIZE-NETWORK-WEIGHTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD INITIALIZE-NETWORK-WEIGHTS ((SELF TENSORFLOW-NEURAL-NETWORK)) :DOCUMENTATION \"Initialize the weights of the neural network `self' - eiher randomly or from a saved state.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION INITIALIZE-NETWORK-WEIGHTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD BUILD-PROPOSITION-NETWORK ((SELF TENSORFLOW-NEURAL-NETWORK) (PROP PROPOSITION)) :DOCUMENTATION \"Build a neural network for the proposition `prop'.  This builds a two-layer
perceptron network whose input nodes are activated by the truth of `prop's arguments and whose
output node computes the truth of `prop'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION BUILD-PROPOSITION-NETWORK)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NUMBER-OF-INPUTS INTEGER) ((SELF TENSORFLOW-NEURAL-NETWORK)) :DOCUMENTATION \"Return the number of input values expected by `self' (ignores bias unit).\" :PUBLIC? TRUE :GLOBALLY-INLINE? TRUE (RETURN (FUNCALL (GET-TENSORFLOW-CALLBACK (QUOTE TENSORFLOW-NEURAL-NETWORK.NUMBER-OF-INPUTS)) SELF)))"
    (WRAP-METHOD-CODE (CL:FUNCTION NUMBER-OF-INPUTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NTH-INPUT FLOAT) ((SELF TENSORFLOW-NEURAL-NETWORK) (N INTEGER)) :DOCUMENTATION \"Return the 0-based `n'-th proposition input of `self' (ignores bias unit).\" :PUBLIC? TRUE :GLOBALLY-INLINE? TRUE (RETURN (FUNCALL (GET-TENSORFLOW-CALLBACK (QUOTE TENSORFLOW-NEURAL-NETWORK.NTH-INPUT)) SELF N)))"
    (WRAP-METHOD-CODE (CL:FUNCTION NTH-INPUT)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NTH-INPUT-ERROR FLOAT) ((SELF TENSORFLOW-NEURAL-NETWORK) (N INTEGER)) :DOCUMENTATION \"Return the 0-based `n'-th proposition input error of `self' (ignores bias unit).\" :PUBLIC? TRUE :GLOBALLY-INLINE? TRUE (RETURN (FUNCALL (GET-TENSORFLOW-CALLBACK (QUOTE TENSORFLOW-NEURAL-NETWORK.NTH-INPUT-ERROR)) SELF N)))"
    (WRAP-METHOD-CODE (CL:FUNCTION NTH-INPUT-ERROR)) NULL)))

(CL:DEFUN HELP-STARTUP-CHAMELEON7 ()
  (CL:PROGN
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD SET-INPUT-VALUES ((SELF TENSORFLOW-NEURAL-NETWORK) (VALUES OBJECT)) :DOCUMENTATION \"Set the current truth-value inputs of the network `self' to float `values' in sequence.
Missing inputs will be set to 0.0, extra values will be ignored.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION SET-INPUT-VALUES)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (GET-VECTOR-ARGUMENT-SPEC OBJECT) ((SELF TENSORFLOW-NEURAL-NETWORK) (ARG OBJECT)) :DOCUMENTATION \"Generate a single argument spec for `arg' that can be used for `set-vector-input-values'.
`arg' can either be a proposition or justification.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION GET-VECTOR-ARGUMENT-SPEC)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD SET-VECTOR-INPUT-VALUES ((SELF TENSORFLOW-NEURAL-NETWORK) (VECTORSPECS OBJECT)) :DOCUMENTATION \"Set the current vector inputs of the network `self' to the vectors described by `vectorSpecs'.
Each vector spec describes a vector-generating proposition that produces one or more vectors.  How those specs
are translated into actual numeric vectors such as embeddings is specific to the particular neural network type.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION SET-VECTOR-INPUT-VALUES)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (FORWARD-PROPAGATE-INPUTS FLOAT) ((SELF TENSORFLOW-NEURAL-NETWORK)) :DOCUMENTATION \"Activates the current inputs of the network `self' to compute its output.
Sets `self's `output' slot and returns the computed value.  Reads input activations and
weights and updates hidden and output activations.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION FORWARD-PROPAGATE-INPUTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD BACKWARD-PROPAGATE-ERROR ((SELF TENSORFLOW-NEURAL-NETWORK) (ERROR FLOAT)) :DOCUMENTATION \"Given a properly forward activated network `self' for the current set of inputs,
and a training `error' between the current output and the goal value, backpropagate the error and
update `self's vector of input errors.  Reads output, hidden activations and weights and updates
hidden errors and input errors.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION BACKWARD-PROPAGATE-ERROR)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD UPDATE-NETWORK-WEIGHTS ((SELF TENSORFLOW-NEURAL-NETWORK) (ERROR FLOAT)) :DOCUMENTATION \"Given a properly forward activated and backpropagated network `self' for the current
inputs and training `error', update the network's weights according to current gradients, learning rate
and momentum terms to reduce the error for the given inputs.  Reads output, hidden and input activations,
hidden error, weights and weight deltas, and updates weights and weight deltas.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION UPDATE-NETWORK-WEIGHTS)) NULL)
   (DEFINE-FUNCTION-OBJECT "GET-CACHED-NETWORK-PROOF"
    "(DEFUN (GET-CACHED-NETWORK-PROOF JUSTIFICATION) ((EXAMPLE TRAINING-EXAMPLE)) :DOCUMENTATION \"Variant of `create-cached-network' that takes a training `example',
runs its cons query, and stores a compacted version of the associated proof tree
as the `example's cached solution which will also be returned.  If a cached and
up-to-date solution already exists, it will be returned instead.\" :PUBLIC? TRUE)"
    (CL:FUNCTION GET-CACHED-NETWORK-PROOF) NULL)
   (DEFINE-FUNCTION-OBJECT "COMPACT-PARTIAL-PROOF-TO-NETWORK-PROOF"
    "(DEFUN (COMPACT-PARTIAL-PROOF-TO-NETWORK-PROOF JUSTIFICATION) ((PROOF JUSTIFICATION)) :DOCUMENTATION \"Convert `proof' into a compacted network tree form that only contains
:AND, :OR, :MULTI and :PRIMITIVE nodes (some of which such as `instance-of' might contain
further antecedents if they were computed by specialists, for example).\" :PUBLIC? TRUE)"
    (CL:FUNCTION COMPACT-PARTIAL-PROOF-TO-NETWORK-PROOF) NULL)
   (DEFINE-FUNCTION-OBJECT "COMBINE-MULTIPLE-MATCH-SCORES"
    "(DEFUN (COMBINE-MULTIPLE-MATCH-SCORES FLOAT) ((SCORES (CONS OF FLOAT-WRAPPER))) :DOCUMENTATION \"Combine partial match scores from alternative :multiple-proofs `scores'
according to the current `*rule-combination*' strategy.\" :PUBLIC? TRUE)"
    (CL:FUNCTION COMBINE-MULTIPLE-MATCH-SCORES) NULL)
   (DEFINE-FUNCTION-OBJECT "FORWARD-PROPAGATE-CACHED-NETWORK-PROOF"
    "(DEFUN (FORWARD-PROPAGATE-CACHED-NETWORK-PROOF FLOAT) ((PROOF JUSTIFICATION)) :DOCUMENTATION \"Compute the same partial match score as the call to `compute-partial-truth'
that generated `proof' (which is assumed to have been compacted with a call to
`compact-partial-proof-to-network-proof'.  The score will only be identical of course, if
the various networks and their weights have not yet been updated during learning.\" :PUBLIC? TRUE)"
    (CL:FUNCTION FORWARD-PROPAGATE-CACHED-NETWORK-PROOF) NULL)
   (DEFINE-FUNCTION-OBJECT
    "FORWARD-PROPAGATE-CACHED-NETWORK-FROM-JUSTIFICATION"
    "(DEFUN (FORWARD-PROPAGATE-CACHED-NETWORK-FROM-JUSTIFICATION FLOAT) ((JUST JUSTIFICATION)) :DOCUMENTATION \"Locally forward-propagate the network associated with `just' based on
previously cached `positive-score's of antecedents.\" :PUBLIC? TRUE)"
    (CL:FUNCTION FORWARD-PROPAGATE-CACHED-NETWORK-FROM-JUSTIFICATION)
    NULL)
   (DEFINE-FUNCTION-OBJECT "BACKWARD-PROPAGATE-CACHED-NETWORK-PROOF"
    "(DEFUN BACKWARD-PROPAGATE-CACHED-NETWORK-PROOF ((PROOF JUSTIFICATION) (ERROR FLOAT)) :DOCUMENTATION \"Propagate the `error' between `proof's conclusion and the desired target value
through `proof's network and its antecedents, and adjust weights to decrease the error.  Multiple
iterations through `forward/backward-propagate-cached-network-proof' with updated top-level
errors will train the involved networks to minimize the error as much as possible.\" :PUBLIC? TRUE)"
    (CL:FUNCTION BACKWARD-PROPAGATE-CACHED-NETWORK-PROOF) NULL)
   (DEFINE-FUNCTION-OBJECT
    "BACKWARD-PROPAGATE-CACHED-NETWORK-MULTI-PROOF"
    "(DEFUN BACKWARD-PROPAGATE-CACHED-NETWORK-MULTI-PROOF ((PROOF JUSTIFICATION) (ERROR FLOAT)) :DOCUMENTATION \"Recurse through :multiple-proofs antecedents guided by the current rule combination scheme.\" :PUBLIC? TRUE)"
    (CL:FUNCTION BACKWARD-PROPAGATE-CACHED-NETWORK-MULTI-PROOF) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD CLEAR-BATCH-ARRAYS ((SELF NEURAL-NETWORK)) :DOCUMENTATION \"Clear all currently batched inputs (with keys) and associated target values.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION CLEAR-BATCH-ARRAYS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (CURRENT-BATCH-SIZE INTEGER) ((SELF NEURAL-NETWORK)) :DOCUMENTATION \"Return the number of currently batched inputs.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION CURRENT-BATCH-SIZE)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (BATCH-IS-FULL? BOOLEAN) ((SELF NEURAL-NETWORK)) :DOCUMENTATION \"Return true if input batch arrays have been filled to capacity.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION BATCH-IS-FULL?)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD PUSH-INPUT-VALUES ((SELF NEURAL-NETWORK) (KEY OBJECT) (VALUES OBJECT)) :DOCUMENTATION \"Push input `values' onto the input batch array and associate them with `key' (which can be NULL).
Associating a key lets us easily map inputs/outputs to some processing object of interest (e.g., a justification).\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION PUSH-INPUT-VALUES)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD PUSH-VECTOR-INPUT-VALUES ((SELF NEURAL-NETWORK) (VECTORSPECS OBJECT)) :DOCUMENTATION \"Push `vectorSpecs' onto the vector argument batch array which is assumed to correspond to the input
values at the same respective position in the batch.  Truth-valued and vector-valued inputs are associated by position
in the batch, they can be pushed independently, as long as they are fully synchronized when processing of the batch starts.
If `self' has no vector-valued argument, the associated batch array can be left undefined.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION PUSH-VECTOR-INPUT-VALUES)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD PUSH-TARGET-VALUE ((SELF NEURAL-NETWORK) (VALUE FLOAT)) :DOCUMENTATION \"Push a target `value' onto the target batch array which is assumed to correspond to the input
values at the same respective position in the batch.  Inputs and targets are associated by position in the batch,
they can be pushed independently, as long as they are fully synchronized when processing of the batch starts.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION PUSH-TARGET-VALUE)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NTH-BATCH-KEY OBJECT) ((SELF NEURAL-NETWORK) (N INTEGER)) :DOCUMENTATION \"Return the key associated with the `n'-th set of inputs in the input batch.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION NTH-BATCH-KEY)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NTH-KTH-BATCH-INPUT-ERROR FLOAT) ((SELF NEURAL-NETWORK) (N INTEGER) (K INTEGER)) :DOCUMENTATION \"Return error of the `k'-th input in the `n'-th set of inputs in the input batch.
`k' ignores the bias unit.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION NTH-KTH-BATCH-INPUT-ERROR)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NTH-BATCH-OUTPUT FLOAT) ((SELF NEURAL-NETWORK) (N INTEGER)) :DOCUMENTATION \"Return the output value for the `n'-th set of inputs in the input batch.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION NTH-BATCH-OUTPUT)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (BATCH-FORWARD-PROPAGATE-INPUTS FLOAT-ARRAY) ((SELF NEURAL-NETWORK)) :DOCUMENTATION \"Run forward propagation on the current input batch and store outputs in the output batch.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION BATCH-FORWARD-PROPAGATE-INPUTS))
    NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD BATCH-BACKWARD-PROPAGATE-ERROR ((SELF NEURAL-NETWORK)) :DOCUMENTATION \"Run backward propagation on the current input and target batch and store back-propagated
errors in the input error batch.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION BATCH-BACKWARD-PROPAGATE-ERROR))
    NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD BATCH-UPDATE-NETWORK-WEIGHTS ((SELF NEURAL-NETWORK)) :DOCUMENTATION \"Run weight updates for the current input and target batches.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION BATCH-UPDATE-NETWORK-WEIGHTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD ALLOCATE-NETWORK-ARRAYS ((SELF CHAMELEON-BATCH-NEURAL-NETWORK) (NUM-IN INTEGER) (NUM-HIDDEN INTEGER) (NUM-OUT INTEGER)) :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION ALLOCATE-NETWORK-ARRAYS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD CLEAR-BATCH-ARRAYS ((SELF CHAMELEON-BATCH-NEURAL-NETWORK)))"
    (WRAP-METHOD-CODE (CL:FUNCTION CLEAR-BATCH-ARRAYS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (CURRENT-BATCH-SIZE INTEGER) ((SELF CHAMELEON-BATCH-NEURAL-NETWORK)))"
    (WRAP-METHOD-CODE (CL:FUNCTION CURRENT-BATCH-SIZE)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (BATCH-IS-FULL? BOOLEAN) ((SELF CHAMELEON-BATCH-NEURAL-NETWORK)))"
    (WRAP-METHOD-CODE (CL:FUNCTION BATCH-IS-FULL?)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD PUSH-INPUT-VALUES ((SELF CHAMELEON-BATCH-NEURAL-NETWORK) (KEY OBJECT) (VALUES OBJECT)))"
    (WRAP-METHOD-CODE (CL:FUNCTION PUSH-INPUT-VALUES)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD PUSH-TARGET-VALUE ((SELF CHAMELEON-BATCH-NEURAL-NETWORK) (VALUE FLOAT)))"
    (WRAP-METHOD-CODE (CL:FUNCTION PUSH-TARGET-VALUE)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NTH-BATCH-KEY OBJECT) ((SELF CHAMELEON-BATCH-NEURAL-NETWORK) (N INTEGER)))"
    (WRAP-METHOD-CODE (CL:FUNCTION NTH-BATCH-KEY)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NTH-KTH-BATCH-INPUT-ERROR FLOAT) ((SELF CHAMELEON-BATCH-NEURAL-NETWORK) (N INTEGER) (K INTEGER)))"
    (WRAP-METHOD-CODE (CL:FUNCTION NTH-KTH-BATCH-INPUT-ERROR)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NTH-BATCH-OUTPUT FLOAT) ((SELF CHAMELEON-BATCH-NEURAL-NETWORK) (N INTEGER)))"
    (WRAP-METHOD-CODE (CL:FUNCTION NTH-BATCH-OUTPUT)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (BATCH-FORWARD-PROPAGATE-INPUTS FLOAT-ARRAY) ((SELF CHAMELEON-BATCH-NEURAL-NETWORK)) :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION BATCH-FORWARD-PROPAGATE-INPUTS))
    NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (COPY-INPUT-ERROR FLOAT-ARRAY) ((SELF CHAMELEON-BATCH-NEURAL-NETWORK)))"
    (WRAP-METHOD-CODE (CL:FUNCTION COPY-INPUT-ERROR)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD BATCH-BACKWARD-PROPAGATE-ERROR ((SELF CHAMELEON-BATCH-NEURAL-NETWORK)) :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION BATCH-BACKWARD-PROPAGATE-ERROR))
    NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD BATCH-UPDATE-NETWORK-WEIGHTS ((SELF CHAMELEON-BATCH-NEURAL-NETWORK)) :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION BATCH-UPDATE-NETWORK-WEIGHTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (THE-ARRAY-READER (ARRAY () OF (LIKE (ANY-VALUE SELF)))) ((SELF 2D-LONG-ARRAY)) :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION THE-ARRAY-READER)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD PRINT-NETWORK-ARRAYS ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK)))"
    (WRAP-METHOD-CODE (CL:FUNCTION PRINT-NETWORK-ARRAYS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD ALLOCATE-NETWORK-ARRAYS ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) (NUM-IN INTEGER) (NUM-HIDDEN INTEGER) (NUM-OUT INTEGER)) :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION ALLOCATE-NETWORK-ARRAYS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD BUILD-PROPOSITION-NETWORK ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) (PROP PROPOSITION)) :DOCUMENTATION \"Build a neural network for the proposition `prop'.  This builds a two-layer
perceptron network whose input nodes are activated by the truth of `prop's arguments and whose
output node computes the truth of `prop'.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION BUILD-PROPOSITION-NETWORK)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NUMBER-OF-INPUTS INTEGER) ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK)) :DOCUMENTATION \"Return the number of input values expected by `self' (ignores bias unit).\" :PUBLIC? TRUE :GLOBALLY-INLINE? TRUE (RETURN (1- (DIM2 (INPUT-BATCH SELF)))))"
    (WRAP-METHOD-CODE (CL:FUNCTION NUMBER-OF-INPUTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NTH-INPUT FLOAT) ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) (N INTEGER)) :DOCUMENTATION \"Return the 0-based `n'-th proposition input of `self' (ignores bias unit).\" :PUBLIC? TRUE :GLOBALLY-INLINE? TRUE (IGNORE N) (ERROR \"nth-input: not supported on: \" SELF))"
    (WRAP-METHOD-CODE (CL:FUNCTION NTH-INPUT)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NTH-INPUT-ERROR FLOAT) ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) (N INTEGER)) :DOCUMENTATION \"Return the 0-based `n'-th proposition input error of `self' (ignores bias unit).\" :PUBLIC? TRUE :GLOBALLY-INLINE? TRUE (IGNORE N) (ERROR \"nth-input-error: not supported on: \" SELF))"
    (WRAP-METHOD-CODE (CL:FUNCTION NTH-INPUT-ERROR)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD SET-INPUT-VALUES ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) (VALUES OBJECT)) :DOCUMENTATION \"Set the current truth-value inputs of the network `self' to float `values' in sequence.
Missing inputs will be set to 0.0, extra values will be ignored.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION SET-INPUT-VALUES)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (GET-VECTOR-ARGUMENT-SPEC OBJECT) ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) (ARG OBJECT)) :DOCUMENTATION \"Generate a single argument spec for `arg' that can be used for `set-vector-input-values'.
`arg' can either be a proposition or justification.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION GET-VECTOR-ARGUMENT-SPEC)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD SET-VECTOR-INPUT-VALUES ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) (VECTORSPECS OBJECT)) :DOCUMENTATION \"Set the current vector inputs of the network `self' to the vectors described by `vectorSpecs'.
Each vector spec describes a vector-generating proposition that produces one or more vectors.  How those specs
are translated into actual numeric vectors such as embeddings is specific to the particular neural network type.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION SET-VECTOR-INPUT-VALUES)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (FORWARD-PROPAGATE-INPUTS FLOAT) ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK)) :DOCUMENTATION \"Activates the current inputs of the network `self' to compute its output.
Sets `self's `output' slot and returns the computed value.  Reads input activations and
weights and updates hidden and output activations.\" :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION FORWARD-PROPAGATE-INPUTS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD CLEAR-BATCH-ARRAYS ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK)))"
    (WRAP-METHOD-CODE (CL:FUNCTION CLEAR-BATCH-ARRAYS)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (CURRENT-BATCH-SIZE INTEGER) ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK)))"
    (WRAP-METHOD-CODE (CL:FUNCTION CURRENT-BATCH-SIZE)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (BATCH-IS-FULL? BOOLEAN) ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK)))"
    (WRAP-METHOD-CODE (CL:FUNCTION BATCH-IS-FULL?)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD PUSH-INPUT-VALUES ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) (KEY OBJECT) (VALUES OBJECT)))"
    (WRAP-METHOD-CODE (CL:FUNCTION PUSH-INPUT-VALUES)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD PUSH-VECTOR-INPUT-VALUES ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) (VECTORSPECS OBJECT)))"
    (WRAP-METHOD-CODE (CL:FUNCTION PUSH-VECTOR-INPUT-VALUES)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD PUSH-TARGET-VALUE ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) (VALUE FLOAT)))"
    (WRAP-METHOD-CODE (CL:FUNCTION PUSH-TARGET-VALUE)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NTH-BATCH-KEY OBJECT) ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) (N INTEGER)))"
    (WRAP-METHOD-CODE (CL:FUNCTION NTH-BATCH-KEY)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NTH-KTH-BATCH-INPUT-ERROR FLOAT) ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) (N INTEGER) (K INTEGER)))"
    (WRAP-METHOD-CODE (CL:FUNCTION NTH-KTH-BATCH-INPUT-ERROR)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (NTH-BATCH-OUTPUT FLOAT) ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK) (N INTEGER)))"
    (WRAP-METHOD-CODE (CL:FUNCTION NTH-BATCH-OUTPUT)) NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD (BATCH-FORWARD-PROPAGATE-INPUTS FLOAT-ARRAY) ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK)) :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION BATCH-FORWARD-PROPAGATE-INPUTS))
    NULL)
   (DEFINE-METHOD-OBJECT
    "(DEFMETHOD BATCH-BACKWARD-PROPAGATE-ERROR ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK)) :PUBLIC? TRUE)"
    (WRAP-METHOD-CODE (CL:FUNCTION BATCH-BACKWARD-PROPAGATE-ERROR))
    NULL)))

(CL:DEFUN STARTUP-CHAMELEON ()
  (CL:LET*
   ((*MODULE* (GET-STELLA-MODULE "/LOGIC" (> *STARTUP-TIME-PHASE* 1)))
    (*CONTEXT* *MODULE*))
   (CL:DECLARE (CL:SPECIAL *MODULE* *CONTEXT*))
   (CL:WHEN (CURRENT-STARTUP-TIME-PHASE? 2) (HELP-STARTUP-CHAMELEON1)
    (HELP-STARTUP-CHAMELEON2) (HELP-STARTUP-CHAMELEON3))
   (CL:WHEN (CURRENT-STARTUP-TIME-PHASE? 4)
    (CL:SETQ *ALL-NEURAL-NETWORKS* (NEW-KEY-VALUE-MAP))
    (CL:SETQ *CHAMELEON-NEURAL-NETWORK-IMPLEMENTATION*
     KWD-CHAMELEON-ORIGINAL)
    (CL:SETQ *WRAPPED-CHAMELEON-DEFAULT-INPUT-VALUE*
     (WRAP-FLOAT *CHAMELEON-DEFAULT-INPUT-VALUE*)))
   (CL:WHEN (CURRENT-STARTUP-TIME-PHASE? 5) (HELP-STARTUP-CHAMELEON4))
   (CL:WHEN (CURRENT-STARTUP-TIME-PHASE? 6) (FINALIZE-CLASSES))
   (CL:WHEN (CURRENT-STARTUP-TIME-PHASE? 7) (HELP-STARTUP-CHAMELEON5)
    (HELP-STARTUP-CHAMELEON6) (HELP-STARTUP-CHAMELEON7)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD BATCH-UPDATE-NETWORK-WEIGHTS ((SELF TENSORFLOW-BATCH-NEURAL-NETWORK)) :PUBLIC? TRUE)"
     (WRAP-METHOD-CODE (CL:FUNCTION BATCH-UPDATE-NETWORK-WEIGHTS))
     NULL)
    (DEFINE-FUNCTION-OBJECT "ADD-NETWORK-PROOF-DEPENDENCY-LINK"
     "(DEFUN ADD-NETWORK-PROOF-DEPENDENCY-LINK ((TABLE KEY-VALUE-MAP) (SUBJECT JUSTIFICATION) (OBJECT JUSTIFICATION)))"
     (CL:FUNCTION ADD-NETWORK-PROOF-DEPENDENCY-LINK) NULL)
    (DEFINE-FUNCTION-OBJECT "REMOVE-NETWORK-PROOF-DEPENDENCY-LINK"
     "(DEFUN REMOVE-NETWORK-PROOF-DEPENDENCY-LINK ((TABLE KEY-VALUE-MAP) (SUBJECT JUSTIFICATION) (OBJECT JUSTIFICATION)))"
     (CL:FUNCTION REMOVE-NETWORK-PROOF-DEPENDENCY-LINK) NULL)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD ADD-DEPENDENT ((QUEUE NETWORK-PROOF-QUEUE) (PREREQUISITE JUSTIFICATION) (DEPENDENT JUSTIFICATION)))"
     (WRAP-METHOD-CODE (CL:FUNCTION ADD-DEPENDENT)) NULL)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD REMOVE-DEPENDENT ((QUEUE NETWORK-PROOF-QUEUE) (PREREQUISITE JUSTIFICATION) (DEPENDENT JUSTIFICATION)))"
     (WRAP-METHOD-CODE (CL:FUNCTION REMOVE-DEPENDENT)) NULL)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD (GET-DEPENDENTS (CONS OF JUSTIFICATION)) ((QUEUE NETWORK-PROOF-QUEUE) (PREREQUISITE JUSTIFICATION)))"
     (WRAP-METHOD-CODE (CL:FUNCTION GET-DEPENDENTS)) NULL)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD (HAS-DEPENDENT? BOOLEAN) ((QUEUE NETWORK-PROOF-QUEUE) (PREREQUISITE JUSTIFICATION) (DEPENDENT JUSTIFICATION)))"
     (WRAP-METHOD-CODE (CL:FUNCTION HAS-DEPENDENT?)) NULL)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD (GET-PREREQUISITES (CONS OF JUSTIFICATION)) ((QUEUE NETWORK-PROOF-QUEUE) (DEPENDENT JUSTIFICATION)))"
     (WRAP-METHOD-CODE (CL:FUNCTION GET-PREREQUISITES)) NULL)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD (HAS-PREREQUISITE? BOOLEAN) ((QUEUE NETWORK-PROOF-QUEUE) (DEPENDENT JUSTIFICATION) (PREREQUISITE JUSTIFICATION)))"
     (WRAP-METHOD-CODE (CL:FUNCTION HAS-PREREQUISITE?)) NULL)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD BATCH-PROCESS-CACHED-NETWORK-PROOF ((QUEUE NETWORK-PROOF-QUEUE) (PROOF JUSTIFICATION)))"
     (WRAP-METHOD-CODE
      (CL:FUNCTION BATCH-PROCESS-CACHED-NETWORK-PROOF))
     NULL)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD QUEUE-NETWORK-OPERATION ((QUEUE NETWORK-PROOF-QUEUE) (PROOF JUSTIFICATION)))"
     (WRAP-METHOD-CODE (CL:FUNCTION QUEUE-NETWORK-OPERATION)) NULL)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD EXECUTE-NETWORK-OPERATION ((QUEUE NETWORK-PROOF-QUEUE) (NET NEURAL-NETWORK) (FORCE? BOOLEAN)))"
     (WRAP-METHOD-CODE (CL:FUNCTION EXECUTE-NETWORK-OPERATION)) NULL)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD BATCH-PROCESS-CACHED-NETWORK-PROOF ((QUEUE NETWORK-PROOF-FORWARD-QUEUE) (PROOF JUSTIFICATION)) :DOCUMENTATION \"Compute the same partial match score as the call to `compute-partial-truth'
that generated `proof' (which is assumed to have been compacted with a call to
`compact-partial-proof-to-network-proof'.  The score will only be identical of course, if
the various networks and their weights have not yet been updated during learning.\" :PUBLIC? TRUE)"
     (WRAP-METHOD-CODE
      (CL:FUNCTION BATCH-PROCESS-CACHED-NETWORK-PROOF))
     NULL)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD NOTIFY-OF-COMPLETION ((QUEUE NETWORK-PROOF-QUEUE) (PROOF JUSTIFICATION) (PREREQUISITE JUSTIFICATION)) :DOCUMENTATION \"Notify `proof' that one of its `prerequisite's had its computation completed.\" :PUBLIC? TRUE)"
     (WRAP-METHOD-CODE (CL:FUNCTION NOTIFY-OF-COMPLETION)) NULL)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD QUEUE-INPUT-VALUES ((QUEUE NETWORK-PROOF-QUEUE) (NET NEURAL-NETWORK) (PROOF JUSTIFICATION) (INPUTS OBJECT) (VECTORSPECS OBJECT)) :DOCUMENTATION \"Queue `inputs' in `net's input batch.  Execute the current batch if we are full.\" :PUBLIC? TRUE)"
     (WRAP-METHOD-CODE (CL:FUNCTION QUEUE-INPUT-VALUES)) NULL)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD QUEUE-NETWORK-OPERATION ((QUEUE NETWORK-PROOF-FORWARD-QUEUE) (PROOF JUSTIFICATION)) :PUBLIC? TRUE)"
     (WRAP-METHOD-CODE (CL:FUNCTION QUEUE-NETWORK-OPERATION)) NULL)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD EXECUTE-NETWORK-OPERATION ((QUEUE NETWORK-PROOF-FORWARD-QUEUE) (NET NEURAL-NETWORK) (FORCE? BOOLEAN)) :PUBLIC? TRUE)"
     (WRAP-METHOD-CODE (CL:FUNCTION EXECUTE-NETWORK-OPERATION)) NULL)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD EXECUTE-ALL ((QUEUE NETWORK-PROOF-QUEUE)) :DOCUMENTATION \"Execute queued ops in `queue' until there is nothing more to do.\" :PUBLIC? TRUE)"
     (WRAP-METHOD-CODE (CL:FUNCTION EXECUTE-ALL)) NULL)
    (DEFINE-EXTERNAL-SLOT-FROM-STRINGIFIED-SOURCE
     "(DEFSLOT JUSTIFICATION TRAINING-ERROR :RENAMES ERROR-SCORE :DOCUMENTATION \"More suggestive name for this slot which is used to store and propagate errors during training.\")")
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD BATCH-PROCESS-CACHED-NETWORK-PROOF ((QUEUE NETWORK-PROOF-BACKWARD-QUEUE) (PROOF JUSTIFICATION)) :DOCUMENTATION \"Queue and process operations for `update-network-weights' for `proof'.\" :PUBLIC? TRUE)"
     (WRAP-METHOD-CODE
      (CL:FUNCTION BATCH-PROCESS-CACHED-NETWORK-PROOF))
     NULL)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD QUEUE-NETWORK-OPERATION ((QUEUE NETWORK-PROOF-BACKWARD-QUEUE) (PROOF JUSTIFICATION)) :PUBLIC? TRUE)"
     (WRAP-METHOD-CODE (CL:FUNCTION QUEUE-NETWORK-OPERATION)) NULL)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD EXECUTE-NETWORK-OPERATION ((QUEUE NETWORK-PROOF-BACKWARD-QUEUE) (NET NEURAL-NETWORK) (FORCE? BOOLEAN)) :PUBLIC? TRUE)"
     (WRAP-METHOD-CODE (CL:FUNCTION EXECUTE-NETWORK-OPERATION)) NULL)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD BATCH-PROCESS-CACHED-NETWORK-PROOF ((QUEUE NETWORK-PROOF-UPDATE-QUEUE) (PROOF JUSTIFICATION)) :DOCUMENTATION \"Queue and process operations for `update-network-weights' for `proof'.\" :PUBLIC? TRUE)"
     (WRAP-METHOD-CODE
      (CL:FUNCTION BATCH-PROCESS-CACHED-NETWORK-PROOF))
     NULL)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD QUEUE-NETWORK-OPERATION ((QUEUE NETWORK-PROOF-UPDATE-QUEUE) (PROOF JUSTIFICATION)) :PUBLIC? TRUE)"
     (WRAP-METHOD-CODE (CL:FUNCTION QUEUE-NETWORK-OPERATION)) NULL)
    (DEFINE-METHOD-OBJECT
     "(DEFMETHOD EXECUTE-NETWORK-OPERATION ((QUEUE NETWORK-PROOF-UPDATE-QUEUE) (NET NEURAL-NETWORK) (FORCE? BOOLEAN)) :PUBLIC? TRUE)"
     (WRAP-METHOD-CODE (CL:FUNCTION EXECUTE-NETWORK-OPERATION)) NULL)
    (DEFINE-FUNCTION-OBJECT "RETRIEVE-TRAINING-EXAMPLES"
     "(DEFUN (RETRIEVE-TRAINING-EXAMPLES (LIST OF TRAINING-EXAMPLE)) (|&REST| (OPTIONS OBJECT)) :DOCUMENTATION \"Retrieve a subset of current training examples defined via `cham/training-example'.\" :PUBLIC? TRUE :COMMAND? TRUE)"
     (CL:FUNCTION %RETRIEVE-TRAINING-EXAMPLES)
     (CL:FUNCTION RETRIEVE-TRAINING-EXAMPLES-EVALUATOR-WRAPPER))
    (DEFINE-FUNCTION-OBJECT "SELECT-TRAINING-EXAMPLES"
     "(DEFUN (SELECT-TRAINING-EXAMPLES (VECTOR OF TRAINING-EXAMPLE)) (|&REST| (OPTIONS OBJECT)) :DOCUMENTATION \"Select a subset of currently defined training examples.  Currently the selection
is purely based on module and/or number.  Results will be shuffled if :shuffle? is TRUE (default).\" :PUBLIC? TRUE :COMMAND? TRUE)"
     (CL:FUNCTION %SELECT-TRAINING-EXAMPLES)
     (CL:FUNCTION SELECT-TRAINING-EXAMPLES-EVALUATOR-WRAPPER))
    (DEFINE-FUNCTION-OBJECT "NORMALIZE-CHAMELEON-TRAINING-OPTIONS"
     "(DEFUN (NORMALIZE-CHAMELEON-TRAINING-OPTIONS PROPERTY-LIST) ((OPTIONS OBJECT)) :DOCUMENTATION \"Normalize and provide defaults for `options' supplied
to `train-chameleon-neural-networks'.\" :PUBLIC? TRUE)"
     (CL:FUNCTION NORMALIZE-CHAMELEON-TRAINING-OPTIONS) NULL)
    (DEFINE-FUNCTION-OBJECT "TRAIN-CHAMELEON-NEURAL-NETWORKS"
     "(DEFUN TRAIN-CHAMELEON-NEURAL-NETWORKS (|&REST| (OPTIONS OBJECT)) :DOCUMENTATION \"Train rule neural networks based on :n-train (or all) training examples looked
up in :module/:local?.  Train for :epochs (defaults to 20) or until :error-cutoff is reached.
Print every :print-cycle epochs or not at all.  If :shuffle? (the default) randomly shuffle the
selected training examples before every epoch.  If :batch?, use batch training mechanism (which
will fail if the current network implementation does not support it).\" :PUBLIC? TRUE :COMMAND? TRUE)"
     (CL:FUNCTION %TRAIN-CHAMELEON-NEURAL-NETWORKS)
     (CL:FUNCTION TRAIN-CHAMELEON-NEURAL-NETWORKS-EVALUATOR-WRAPPER))
    (DEFINE-FUNCTION-OBJECT "SCORED-QUERY-SPECIALIST"
     "(DEFUN (SCORED-QUERY-SPECIALIST KEYWORD) ((FRAME CONTROL-FRAME) (LASTMOVE KEYWORD)))"
     (CL:FUNCTION SCORED-QUERY-SPECIALIST) NULL)
    (DEFINE-FUNCTION-OBJECT "MATCH-SCORE-SPECIALIST"
     "(DEFUN (MATCH-SCORE-SPECIALIST KEYWORD) ((FRAME CONTROL-FRAME) (LASTMOVE KEYWORD)))"
     (CL:FUNCTION MATCH-SCORE-SPECIALIST) NULL)
    (DEFINE-FUNCTION-OBJECT "STARTUP-CHAMELEON"
     "(DEFUN STARTUP-CHAMELEON () :PUBLIC? TRUE)"
     (CL:FUNCTION STARTUP-CHAMELEON) NULL)
    (CL:LET*
     ((FUNCTION
       (LOOKUP-FUNCTION SYM-CHAMELEON-LOGIC-STARTUP-CHAMELEON)))
     (SET-DYNAMIC-SLOT-VALUE (%DYNAMIC-SLOTS FUNCTION)
      SYM-CHAMELEON-STELLA-METHOD-STARTUP-CLASSNAME
      (WRAP-STRING "_StartupChameleon") NULL-STRING-WRAPPER)))
   (CL:WHEN (CURRENT-STARTUP-TIME-PHASE? 8) (FINALIZE-SLOTS)
    (CLEANUP-UNFINALIZED-CLASSES))
   (CL:WHEN (CURRENT-STARTUP-TIME-PHASE? 9)
    (%IN-MODULE (COPY-CONS-TREE (WRAP-STRING "LOGIC")))
    (DEFINE-GLOBAL-VARIABLE-OBJECT
     "(DEFGLOBAL *CHAMELEON-MODULE* MODULE NULL :DOCUMENTATION \"Namespace module for Chameleon relations\")"
     NULL)
    (DEFINE-GLOBAL-VARIABLE-OBJECT
     "(DEFGLOBAL *CHAMELEON-DEFAULT-DEFAULT-SCORE* FLOAT 0.01 :DOCUMENTATION \"Default weight to use for unknown propositions that don't have a relation-specific value specified.\" :DEMON-PROPERTY \"powerloom.chameleon.defaultDefaultScore\" :PUBLIC? TRUE)"
     NULL)
    (DEFINE-EXPLANATION-PHRASE KWD-CHAMELEON-MULTIPLE-PROOFS
     KWD-CHAMELEON-TECHNICAL "from multiple proofs")
    (DEFINE-EXPLANATION-PHRASE KWD-CHAMELEON-MULTIPLE-PROOFS
     KWD-CHAMELEON-LAY "from multiple proofs")
    (DEFINE-GLOBAL-VARIABLE-OBJECT
     "(DEFGLOBAL *ALL-NEURAL-NETWORKS* (KEY-VALUE-MAP OF INTEGER-WRAPPER (CONS OF NEURAL-NETWORK)) (NEW KEY-VALUE-MAP))"
     NULL)
    (DEFINE-GLOBAL-VARIABLE-OBJECT
     "(DEFGLOBAL *CHAMELEON-NEURAL-NETWORK-IMPLEMENTATION* KEYWORD :ORIGINAL :DEMON-PROPERTY \"powerloom.chameleon.neuralNetworkImplementation\" :PUBLIC? TRUE)"
     NULL)
    (DEFINE-GLOBAL-VARIABLE-OBJECT
     "(DEFGLOBAL *CHAMELEON-DEFAULT-INPUT-VALUE* FLOAT 0.0)" NULL)
    (DEFINE-GLOBAL-VARIABLE-OBJECT
     "(DEFGLOBAL *WRAPPED-CHAMELEON-DEFAULT-INPUT-VALUE* FLOAT-WRAPPER (WRAP-FLOAT *CHAMELEON-DEFAULT-INPUT-VALUE*))"
     NULL)
    (DEFINE-GLOBAL-VARIABLE-OBJECT
     "(DEFGLOBAL *NEURAL-NETWORK-BATCH-SIZE* INTEGER 128 :DEMON-PROPERTY \"powerloom.chameleon.neuralNetworkBatchSize\" :PUBLIC? TRUE)"
     NULL)
    (DEFINE-GLOBAL-VARIABLE-OBJECT
     "(DEFGLOBAL *BATCH-OPERATION-COUNT* INTEGER 0)" NULL)
    (DEFINE-GLOBAL-VARIABLE-OBJECT
     "(DEFGLOBAL *BATCH-TOTAL-COUNT* INTEGER 0)" NULL)
    (REGISTER-NATIVE-NAME
     SYM-CHAMELEON-LOGIC-RETRIEVE-TRAINING-EXAMPLES
     KWD-CHAMELEON-COMMON-LISP KWD-CHAMELEON-FUNCTION)
    (REGISTER-NATIVE-NAME SYM-CHAMELEON-LOGIC-SELECT-TRAINING-EXAMPLES
     KWD-CHAMELEON-COMMON-LISP KWD-CHAMELEON-FUNCTION)
    (REGISTER-NATIVE-NAME
     SYM-CHAMELEON-LOGIC-TRAIN-CHAMELEON-NEURAL-NETWORKS
     KWD-CHAMELEON-COMMON-LISP KWD-CHAMELEON-FUNCTION))))
